- en: '[**26        Parallel Algorithms**](toc.xhtml#chap-26)'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '[**26        并行算法**](toc.xhtml#chap-26)'
- en: The vast majority of algorithms in this book are ***serial algorithms*** suitable
    for running on a uniprocessor computer that executes only one instruction at a
    time. This chapter extends our algorithmic model to encompass ***parallel algorithms***,
    where multiple instructions can execute simultaneously. Specifically, we’ll explore
    the elegant model of task-parallel algorithms, which are amenable to algorithmic
    design and analysis. Our study focuses on fork-join parallel algorithms, the most
    basic and best understood kind of task-parallel algorithm. Fork-join parallel
    algorithms can be expressed cleanly using simple linguistic extensions to ordinary
    serial code. Moreover, they can be implemented efficiently in practice.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中绝大多数算法都是适用于在一次只执行一条指令的单处理器计算机上运行的***串行算法***。本章将我们的算法模型扩展到包括***并行算法***，其中多条指令可以同时执行。具体来说，我们将探讨任务并行算法的优雅模型，这种算法适合于算法设计和分析。我们的研究重点是分叉-合并并行算法，这是最基本且最易理解的任务并行算法。分叉-合并并行算法可以使用简单的语言扩展来清晰地表达，而且在实践中可以高效实现。
- en: Parallel computers—computers with multiple processing units—are ubiquitous.
    Handheld, laptop, desktop, and cloud machines are all ***multicore computers***,
    or simply, ***multicores***, containing multiple processing “cores.” Each processing
    core is a full-fledged processor that can directly access any location in a common
    ***shared memory***. Multicores can be aggregated into larger systems, such as
    clusters, by using a network to interconnect them. These multicore clusters usually
    have a ***distributed memory***, where one multicore’s memory cannot be accessed
    directly by a processor in another multicore. Instead, the processor must explicitly
    send a message over the cluster network to a processor in the remote multicore
    to request any data it requires. The most powerful clusters are supercomputers,
    comprising many thousands of multicores. But since shared-memory programming tends
    to be conceptually easier than distributed-memory programming, and multicore machines
    are widely available, this chapter focuses on parallel algorithms for multicores.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 并行计算机——具有多个处理单元的计算机——是无处不在的。手持设备、笔记本电脑、台式机和云计算机都是***多核计算机***，或简单地说，***多核***，包含多个处理“核心”。每个处理核心都是一个完整的处理器，可以直接访问共享内存中的任何位置。多核可以通过网络相互���接，聚合成更大的系统，如集群。这些多核集群通常具有***分布式内存***，其中一个多核的内存不能直接被另一个多核的处理器访问。相反，处理器必须通过集群网络向远程多核的处理器发送消息，以请求所需的任何数据。最强大的集群是超级计算机，包含许多成千上万的多核。但由于共享内存编程往往在概念上比分布式内存编程更容易，而且多核计算机广泛可用，本章重点介绍了多核计算机的并行算法。
- en: One approach to programming multicores is ***thread parallelism***. This processor-centric
    parallel-programming model employs a software abstraction of “virtual processors,”
    or ***threads*** that share a common memory. Each thread maintains its own program
    counter and can execute code independently of the other threads. The operating
    system loads a thread onto a processing core for execution and switches it out
    when another thread needs to run.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编程多核的一种方法是***线程并行***。这种以处理器为中心的并行编程模型采用了“虚拟处理器”或***线程***的软件抽象，这些线程共享一个公共内存。每个线程都保持自己的程序计数器，并且可以独立于其他线程执行代码。操作系统将一个线程加载到处理核心上进行执行，并在需要运行另一个线程时将其切换出去。
- en: Unfortunately, programming a shared-memory parallel computer using threads tends
    to be difficult and error-prone. One reason is that it can be complicated to dynamically
    partition the work among the threads so that each thread receives approximately
    the same load. For any but the simplest of applications, the programmer must use
    complex communication protocols to implement a scheduler that load-balances the
    work.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，使用线程编程共享内存的并行计算机往往是困难且容易出错的。其中一个原因是动态地将工作分配给线程，使得每个线程接收大致相同的负载可能会很复杂。对于除了最简单的应用程序之外，程序员必须使用复杂的通信协议来实现一个负载平衡的调度器。
- en: '**Task-parallel programming**'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**任务并行编程**'
- en: The difficulty of thread programming has led to the creation of ***task-parallel
    platforms***, which provide a layer of software on top of threads to coordinate,
    schedule, and manage the processors of a multicore. Some task-parallel platforms
    are built as runtime libraries, but others provide full-fledged parallel languages
    with compiler and runtime support.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 线程编程的困难导致了***任务并行平台***的创建，这些平台在线程之上提供了一层软件来协调、调度和管理多核处理器。一些任务并行平台是作为运行时库构建的，但其他提供了具有编译器和运行时支持的完整并行语言。
- en: '***Task-parallel programming*** allows parallelism to be specified in a “processor-oblivious”
    fashion, where the programmer identifies what computational tasks may run in parallel
    but does not indicate which thread or processor performs the task. Thus, the programmer
    is freed from worrying about communication protocols, load balancing, and other
    vagaries of thread programming. The task-parallel platform contains a scheduler,
    which automatically load-balances the tasks across the processors, thereby greatly
    simplifying the programmer’s chore. ***Task-parallel algorithms*** provide a natural
    extension to ordinary serial algorithms, allowing performance to be reasoned about
    mathematically using “work/span analysis.”'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '***任务并行编程***允许以“处理器无关”的方式指定并行性，程序员可以确定哪些计算任务可以并行运行，但不指示哪个线程或处理器执行任务。因此，程序员不必担心通信协议、负载平衡和线程编程的其他问题。任务并行平台包含一个调度器，它会自动将任务在处理器之间进行负载平衡，从而极大地简化了程序员的工作。***任务并行算法***提供了普通串行算法的自然扩展，允许通过“工作/跨度分析”进行数学推理性能。'
- en: '**Fork-join parallelism**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**分叉-合并并行性**'
- en: 'Although the functionality of task-parallel environments is still evolving
    and increasing, almost all support ***fork-join parallelism***, which is typically
    embodied in two linguistic features: ***spawning*** and ***parallel loops***.
    Spawning allows a subroutine to be “forked”: executed like a subroutine call,
    except that the caller can continue to execute while the spawned subroutine computes
    its result. A parallel loop is like an ordinary **for** loop, except that multiple
    iterations of the loop can execute at the same time.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管任务并行环境的功能仍在不断发展和增强，几乎所有支持 ***分支-合并并行性***，这通常体现在两种语言特性中：***生成*** 和 ***并行循环***。生成允许子例程被“分叉”：像子例程调用一样执行，只是调用者可以继续执行，而生成的子例程计算其结果。并行循环类似于普通的
    **for** 循环，只是循环的多个迭代可以同时执行。
- en: '***Fork-join*** parallel algorithms employ spawning and parallel loops to describe
    parallelism. A key aspect of this parallel model, inherited from the task-parallel
    model but different from the thread model, is that the programmer does not specify
    which tasks in a computation *must* run in parallel, only which tasks *may* run
    in parallel. The underlying runtime system uses threads to load-balance the tasks
    across the processors. This chapter investigates parallel algorithms described
    in the fork-join model, as well as how the underlying runtime system can schedule
    task-parallel computations (which include fork-join computations) efficiently.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '***分支-合并*** 并行算法采用生成和并行循环来描述并行性。这种并行模型的一个关键方面，继承自任务并行模型但与线程模型不同的地方在于，程序员不指定计算中必须并行运行的任务，只指定哪些任务
    *可以* 并行运行。底层运行时系统使用线程来在处理器之间平衡任务。本章研究了在分支-合并模型中描述的并行算法，以及底层运行时系统如何高效地调度任务并行计算（包括分支-合并计算）。'
- en: 'Fork-join parallelism offers several important advantages:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分支-合并并行性提供了几个重要优势：
- en: 'The fork-join programming model is a simple extension of the familiar serial
    programming model used in most of this book. To describe a fork-join parallel
    algorithm, the pseudocode in this book needs just three added keywords: **parallel**,
    **spawn**, and **sync**. Deleting these parallel keywords from the parallel pseudocode
    results in ordinary serial pseudocode for the same problem, which we call the
    “serial projection” of the parallel algorithm.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分支-合并编程模型是本书大部分内容中使用的熟悉串行编程模型的简单扩展。要描述一个分支-合并并行算法，本书中的伪代码只需要增加三个关键字：**parallel**、**spawn**
    和 **sync**。从并行伪代码中删除这些并行关键字会导致相同问题的普通串行伪代码，我们称之为并行算法的“串行投影”。
- en: The underlying task-parallel model provides a theoretically clean way to quantify
    parallelism based on the notions of “work” and “span.”
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 底层任务并行模型提供了一种基于“工作”和“跨度”概念来量化并行性的理论上干净的方法。
- en: Spawning allows many divide-and-conquer algorithms to be parallelized naturally.
    Moreover, just as serial divide-and-conquer algorithms lend themselves to analysis
    using recurrences, so do parallel algorithms in the fork-join model.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成允许许多分治算法自然地并行化。此外，正如串行分治算法适合使用递归进行分析一样，分支-合并模型中的并行算法也适合。
- en: The fork-join programming model is faithful to how multicore programming has
    been evolving in practice. A growing number of multicore environments support
    one variant or another of fork-join parallel programming, including Cilk [[290](bibliography001.xhtml#endnote_290),
    [291](bibliography001.xhtml#endnote_291), [383](bibliography001.xhtml#endnote_383),
    [396](bibliography001.xhtml#endnote_396)], Habanero-Java [[466](bibliography001.xhtml#endnote_466)],
    the Java Fork-Join Framework [[279](bibliography001.xhtml#endnote_279)], OpenMP
    [[81](bibliography001.xhtml#endnote_81)], Task Parallel Library [[289](bibliography001.xhtml#endnote_289)],
    Threading Building Blocks [[376](bibliography001.xhtml#endnote_376)], and X10
    [[82](bibliography001.xhtml#endnote_82)].
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分支-合并编程模型忠实于多核编程在实践中的演变。越来越多的多核环境支持分支-合并并行编程的一个或另一个变体，包括 Cilk [[290](bibliography001.xhtml#endnote_290),
    [291](bibliography001.xhtml#endnote_291), [383](bibliography001.xhtml#endnote_383),
    [396](bibliography001.xhtml#endnote_396)], Habanero-Java [[466](bibliography001.xhtml#endnote_466)],
    Java Fork-Join Framework [[279](bibliography001.xhtml#endnote_279)], OpenMP [[81](bibliography001.xhtml#endnote_81)],
    Task Parallel Library [[289](bibliography001.xhtml#endnote_289)], Threading Building
    Blocks [[376](bibliography001.xhtml#endnote_376)], 和 X10 [[82](bibliography001.xhtml#endnote_82)]。
- en: '[Section 26.1](chapter026.xhtml#Sec_26.1) introduces parallel pseudocode, shows
    how the execution of a task-parallel computation can be modeled as a directed
    acyclic graph, and presents the metrics of work, span, and parallelism, which
    you can use to analyze parallel algorithms. [Section 26.2](chapter026.xhtml#Sec_26.2)
    investigates how to multiply matrices in parallel, and [Section 26.3](chapter026.xhtml#Sec_26.3)
    tackles the tougher problem of designing an efficient parallel merge sort.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第26.1节](chapter026.xhtml#Sec_26.1)介绍了并行伪代码，展示了如何将任务并行计算的执行建模为有向无环图，并呈现了工作、跨度和并行性的度量，您可以使用这些度量来分析并行算法。[第26.2节](chapter026.xhtml#Sec_26.2)研究了如何并行相乘矩阵，[第26.3节](chapter026.xhtml#Sec_26.3)解决了设计高效并行归并排序的更困难的问题。'
- en: '[**26.1    The basics of fork-join parallelism**](toc.xhtml#Rh1-152)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[**26.1    分支-合并并行性的基础**](toc.xhtml#Rh1-152)'
- en: Our exploration of parallel programming begins with the problem of computing
    Fibonacci numbers recursively in parallel. We’ll look at a straightforward serial
    Fibonacci calculation, which, although inefficient, serves as a good illustration
    of how to express parallelism in pseudocode.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对并行编程的探索始于在并行计算斐波那契数的问题上进行递归计算。我们将看一下一个直接的串行斐波那契计算，虽然效率低下，但作为如何在伪代码中表达并行性的良好示例。
- en: 'Recall that the Fibonacci numbers are defined by equation (3.31) on page 69:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请回想一下，斐波那契数由第69页的方程式（3.31）定义：
- en: '![art](images/Art_P824.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P824.jpg)'
- en: To calculate the *n*th Fibonacci number recursively, you could use the ordinary
    serial algorithm in the procedure FIB on the facing page. You would not really
    want to compute large Fibonacci numbers this way, because this computation does
    needless repeated work, but parallelizing it can be instructive.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要递归计算第 *n* 个斐波那契数，您可以使用对面页面上的FIB过程中的普通串行算法。您实际上不想以这种方式计算大的斐波那契数，因为这种计算会做不必要的重复工作，但并行化可以很有启发性。
- en: FIB (*n*)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: FIB (*n*)
- en: '| 1 | **if** *n* ≤ 1 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **if** *n* ≤ 1 |'
- en: '| 2 | **return** *n* |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **return** *n* |'
- en: '| 3 | **else** *x* = FIB (*n* − 1) |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **else** *x* = FIB (*n* − 1) |'
- en: '| 4 | *y* = FIB (*n* − 2) |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 4 | *y* = FIB (*n* − 2) |'
- en: '| 5 | **return** *x* + *y* |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 5 | **return** *x* + *y* |'
- en: To analyze this algorithm, let *T* (*n*) denote the running time of FIB (*n*).
    Since FIB (*n*) contains two recursive calls plus a constant amount of extra work,
    we obtain the recurrence
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要分析这个算法，让 *T* (*n*) 表示FIB (*n*)的运行时间。由于FIB (*n*) 包含两个递归调用以及一定量的额外工作，我们得到递归关系
- en: '*T* (*n*) = *T* (*n* − 1) + *T* (*n* − 2) + Θ(1).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*T* (*n*) = *T* (*n* − 1) + *T* (*n* − 2) + Θ(1).'
- en: This recurrence has solution *T* (*n*) = Θ(*F*[*n*]), which we can establish
    by using the substitution method (see [Section 4.3](chapter004.xhtml#Sec_4.3)).
    To show that *T* (*n*) = *O*(*F*[*n*]), we’ll adopt the inductive hypothesis that
    *T* (*n*) ≤ *aF*[*n*] − *b*, where *a* > 1 and *b* > 0 are constants. Substituting,
    we obtain
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个递归的解法 *T* (*n*) = Θ(*F*[*n*])，我们可以通过使用替换法（见[第4.3节](chapter004.xhtml#Sec_4.3)）来建立。为了证明
    *T* (*n*) = *O*(*F*[*n*]), 我们采用归纳假设 *T* (*n*) ≤ *aF*[*n*] − *b*，其中 *a* > 1 且 *b*
    > 0 是常数。代入后，我们得到
- en: '| *T* (*n*) | ≤ | (*aF*[*n*−*1*] − *b*) + (*aF*[*n*−*2*] − *b*) + Θ(1) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| *T* (*n*) | ≤ | (*aF*[*n*−*1*] − *b*) + (*aF*[*n*−*2*] − *b*) + Θ(1) |'
- en: '|  | = | *a*(*F*[*n*−1] + *F*[*n*−2]) − 2*b* + Θ(1) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | = | *a*(*F*[*n*−1] + *F*[*n*−2]) − 2*b* + Θ(1) |'
- en: '|  | ≤ | *aF*[*n*] − *b*, |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  | ≤ | *aF*[*n*] − *b*, |'
- en: if we choose *b* large enough to dominate the upper-bound constant in the Θ(1)
    term. We can then choose *a* large enough to upper-bound the Θ(1) base case for
    small *n*. To show that *T* (*n*) = Ω(*F[n]*), we use the inductive hypothesis
    *T* (*n*) ≥ *aF*[*n*] − *b*. Substituting and following reasoning similar to the
    asymptotic upper-bound argument, we establish this hypothesis by choosing *b*
    smaller than the lower-bound constant in the Θ(1) term and *a* small enough to
    lower-bound the Θ(1) base case for small *n*. Theorem 3.1 on page 56 then establishes
    that *T* (*n*) = Θ(*F*[*n*]), as desired. Since *F*[*n*] = Θ(*ϕ*^(*n*)), where
    ![art](images/Art_P825.jpg) is the golden ratio, by equation (3.34) on page 69,
    it follows that
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择足够大的 *b* 来支配Θ(1)项中的上界常数。然后我们可以选择足够大的 *a* 来上界Θ(1)基本情况对于小 *n*。为了证明 *T* (*n*)
    = Ω(*F[n]*)，我们使用归纳假设 *T* (*n*) ≥ *aF*[*n*] − *b*。代入并按照类似于渐近上界论证的推理，我们通过选择比Θ(1)项中的下界常数更小的
    *b* 和足够小的 *a* 来下界Θ(1)基本情况对于小 *n*。然后第56页的定理3.1建立了 *T* (*n*) = Θ(*F*[*n*])，如所需。由于
    *F*[*n*] = Θ(*ϕ*^(*n*))，其中 ![艺术](images/Art_P825.jpg) 是黄金比率，根据第69页的方程式(3.34)，我们得到
- en: '![art](images/Art_P826.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P826.jpg)'
- en: Thus this procedure is a particularly slow way to compute Fibonacci numbers,
    since it runs in exponential time. (See Problem 31-3 on page 954 for faster ways.)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个过程是计算斐波那契数的一种特别慢的方式，因为它运行时间呈指数增长。（参见第954页的问题31-3以获取更快的方法。）
- en: Let’s see why the algorithm is inefficient. [Figure 26.1](chapter026.xhtml#Fig_26-1)
    shows the tree of recursive procedure instances created when computing *F*[6]
    with the FIB procedure. The call to FIB(6) recursively calls FIB(5) and then FIB(4).
    But, the call to FIB(5) also results in a call to FIB(4). Both instances of FIB(4)
    return the same result (*F*[4] = 3). Since the FIB procedure does not memoize
    (recall the definition of “memoize” from page 368), the second call to FIB(4)
    replicates the work that the first call performs, which is wasteful.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看为什么这个算法是低效的。[图26.1](chapter026.xhtml#Fig_26-1)展示了使用FIB过程计算*F*[6]时创建的递归过程实例树。对FIB(6)的调用递归地调用FIB(5)，然后调用FIB(4)。但是，对FIB(5)的调用也会导致对FIB(4)的调用。FIB(4)的两个实例都返回相同的结果（*F*[4]
    = 3）。由于FIB过程不进行记忆化（回顾第368页对“记忆化”的定义），对FIB(4)的第二次调用复制了第一次执行的工作，这是一种浪费。
- en: '![art](images/Art_P827.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P827.jpg)'
- en: '**Figure 26.1** The invocation tree for FIB(6). Each node in the tree represents
    a procedure instance whose children are the procedure instances it calls during
    its execution. Since each instance of FIB with the same argument does the same
    work to produce the same result, the inefficiency of this algorithm for computing
    the Fibonacci numbers can be seen by the vast number of repeated calls to compute
    the same thing. The portion of the tree shaded blue appears in task-parallel form
    in [Figure 26.2](chapter026.xhtml#Fig_26-2).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**图26.1** FIB(6)的调用树。树中的每个节点代表一个过程实例，其子节点是在执行过程中调用的过程实例。由于具有相同参数的每个FIB实例执行相同的工作以产生相同的结果，因此通过计算相同内容的大量重复调用，可以看出该算法计算斐波那契数的低效性。树的蓝色阴影部分出现在[图26.2](chapter026.xhtml#Fig_26-2)中的任务并行形式中。'
- en: Although the FIB procedure is a poor way to compute Fibonacci numbers, it can
    help us warm up to parallelism concepts. Perhaps the most basic concept is to
    understand is that if two parallel tasks operate on entirely different data, then—absent
    other interference—they each produce the same outcomes when executed at the same
    time as when they run serially one after the other. Within FIB (*n*), for example,
    the two recursive calls in line 3 to FIB (*n* − 1) and in line 4 to FIB (*n* −
    2) can safely execute in parallel because the computation performed by one in
    no way affects the other.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管FIB过程是计算斐波那契数的一种低效方式，但它可以帮助我们熟悉并行概念。也许最基本的概念是要理解，如果两个并行任务操作完全不同的数据，那么在没有其他干扰的情况下，它们在同时执行时产生的结果与它们依次串行运行时产生的结果相同。例如，在FIB
    (*n*)中，第3行对FIB (*n* − 1)的两个递归调用和第4行对FIB (*n* − 2)的递归调用可以安全地并行执行，因为其中一个执行的计算方式不会影响另一个。
- en: '**Parallel keywords**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行关键字**'
- en: The P-FIB procedure on the next page computes Fibonacci numbers, but using the
    ***parallel keywords* spawn** and **sync** to indicate parallelism in the pseudocode.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来一页的P-FIB过程计算斐波那契数，但使用***并行关键字* spawn**和**sync**来指示伪代码中的并行性。
- en: If the keywords **spawn** and **sync** are deleted from P-FIB, the resulting
    pseudocode text is identical to FIB (other than renaming the procedure in the
    header and in the two recursive calls). We define the ***serial projection***^([1](#footnote_1))
    of a parallel algorithm to be the serial algorithm that results from ignoring
    the parallel directives, which in this case can be done by omitting the keywords
    **spawn** and **sync**. For **parallel for** loops, which we’ll see later on,
    we omit the keyword **parallel**. Indeed, our parallel pseudocode possesses the
    elegant property that its serial projection is always ordinary serial pseudocode
    to solve the same problem.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果从P-FIB中删除关键字**spawn**和**sync**，则得到的伪代码文本与FIB相同（除了在标题和两个递归调用中重命名过程）。我们将并行算法的***串行投影***^([1](#footnote_1))定义为忽略并行指令而产生的串行算法，这在这种情况下可以通过省略关键字**spawn**和**sync**来完成。对于**parallel
    for**循环，我们稍后会看到，我们省略关键字**parallel**。事实上，我们的并行伪代码具有优雅的特性，即其串行投影始终是解决相同问题的普通串行伪代码。
- en: P-FIB (*n*)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: P-FIB(*n*)
- en: '| 1 | **if** *n* ≤ 1 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **if** *n* ≤ 1 |'
- en: '| 2 | **return** *n* |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **return** *n* |'
- en: '| 3 | **else** *x* = **spawn** P-FIB (*n* − 1) | **//** don’t wait for subroutine
    to return |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **else** *x* = **spawn** P-FIB(*n*−1) | **//** 不等待子例程返回 |'
- en: '| 4 | *y* = P-FIB (*n* − 2) | **//** in parallel with spawned subroutine |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 4 | *y* = P-FIB(*n*−2) | **//** 与生成的子例程并行执行 |'
- en: '| 5 | **sync** | **//** wait for spawned subroutine to finish |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 5 | **sync** | **//** 等待生成的子例程完成 |'
- en: '| 6 | **return** *x* + *y* |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 6 | **return** *x* + *y* |'
- en: '**Semantics of parallel keywords**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行关键字的语义**'
- en: '***Spawning*** occurs when the keyword **spawn** precedes a procedure call,
    as in line 3 of P-FIB. The semantics of a spawn differs from an ordinary procedure
    call in that the procedure instance that executes the spawn—the ***parent***—may
    continue to execute in parallel with the spawned subroutine—its ***child***—instead
    of waiting for the child to finish, as would happen in a serial execution. In
    this case, while the spawned child is computing P-FIB (*n* − 1), the parent may
    go on to compute P-FIB (*n*−2) in line 4 in parallel with the spawned child. Since
    the P-FIB procedure is recursive, these two subroutine calls themselves create
    nested parallelism, as do their children, thereby creating a potentially vast
    tree of subcomputations, all executing in parallel.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '***生成***发生在关键字**spawn**在过程调用之前，如P-FIB的第3行。生成的语义与普通过程调用不同，执行生成的过程实例——***父进程***—可以继续与生成的子例程——***子进程***—并行执行，而不是等待子进程完成，这在串行执行中会发生。在这种情况下，当生成的子进程计算P-FIB(*n*−1)时，父进程可以继续在第4行并行计算P-FIB(*n*−2)。由于P-FIB过程是递归的，这两个子例程调用本身会创建嵌套并行性，就像它们的子进程一样，从而创建一个潜在的庞大的子计算树，所有这些子计算都在并行执行。'
- en: The keyword **spawn** does not say, however, that a procedure *must* execute
    in parallel with its spawned children, only that it *may*. The parallel keywords
    express the ***logical parallelism*** of the computation, indicating which parts
    of the computation may proceed in parallel. At runtime, it is up to a ***scheduler***
    to determine which subcomputations actually run in parallel by assigning them
    to available processors as the computation unfolds. We’ll discuss the theory behind
    task-parallel schedulers shortly (on page 759).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关键字**spawn**并不表示一个过程*必须*与其生成的子进程并行执行，只是表示它*可以*。并行关键字表达了计算的***逻辑并���性***，指示计算的哪些部分可以并行进行。在运行时，由一个***调度器***决定哪些子计算实际上并行运行，通过将它们分配给可用处理器来随着计算的展开。我们将很快讨论任务并行调度器背后的理论（在第759页）。
- en: A procedure cannot safely use the values returned by its spawned children until
    after it executes a **sync** statement, as in line 5\. The keyword **sync** indicates
    that the procedure must wait as necessary for all its spawned children to finish
    before proceeding to the statement after the **sync**—the “join” of a fork-join
    parallel computation. The P-FIB procedure requires a **sync** before the **return**
    statement in line 6 to avoid the anomaly that would occur if *x* and *y* were
    summed before P-FIB (*n* − 1) had finished and its return value had been assigned
    to *x*. In addition to explicit join synchronization provided by the **sync**
    statement, it is convenient to assume that every procedure executes a **sync**
    implicitly before it returns, thus ensuring that all children finish before their
    parent finishes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 程序在执行**sync**语句之后（如第5行）不能安全地使用其生成的子进程返回的值。关键字**sync**表示程序必须等待其所有生成的子进程完成后才能继续执行**sync**之后的语句——这是分支-合并并行计算的“合并”。在第6行的**return**语句之前，P-FIB过程需要一个**sync**，以避免在P-FIB(*n*−1)完成并将其返回值分配给*x*之前对*x*和*y*求和会发生的异常。除了**sync**语句提供的显式加入同步外，方便的假设是每个过程在返回之前都会隐式执行一个**sync**，从而确保所有子进程在其父进程完成之前完成。
- en: '**A graph model for parallel execution**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**用于并行执行的图模型**'
- en: It helps to view the execution of a parallel computation—the dynamic stream
    of runtime instructions executed by processors under the direction of a parallel
    program—as a directed acyclic graph *G* = (*V*, *E*), called a ***(parallel) trace***.^([2](#footnote_2))
    Conceptually, the vertices in *V* are executed instructions, and the edges in
    *E* represent dependencies between instructions, where (*u*, *v*) ∈ *E* means
    that the parallel program required instruction *u* to execute before instruction
    *v*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将并行计算的执行视为动态运行时指令流，由处理器在并行程序的指导下执行的有向无环图*G* = (*V*, *E*)，称为***(并行)跟踪)***。^([2](#footnote_2))概念上，*V*中的顶点是执行的指令，*E*中的边表示指令之间的依赖关系，其中(*u*,
    *v*) ∈ *E*表示并行程序要求指令*u*在指令*v*之前执行。
- en: It’s sometimes inconvenient, especially if we want to focus on the parallel
    structure of a computation, for a vertex of a trace to represent only one executed
    instruction. Consequently, if a chain of instructions contains no parallel or
    procedural control (no **spawn**, **sync**, procedure call, or **return**—via
    either an explicit **return** statement or the return that happens implicitly
    upon reaching the end of a procedure), we group the entire chain into a single
    ***strand***. As an example, [Figure 26.2](chapter026.xhtml#Fig_26-2) shows the
    trace that results from computing P-FIB(4) in the portion of [Figure 26.1](chapter026.xhtml#Fig_26-1)
    shaded blue. Strands do not include instructions that involve parallel or procedural
    control. These control dependencies must be represented as edges in the trace.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，如果我们想要关注计算的并行结构，让跟踪的一个顶点仅代表一个执行的指令可能会有些不方便。因此，如果一系列指令不包含任何并行或过程控制（没有**spawn**、**sync**、过程调用或**return**—无论是通过显式的**return**语句还是隐式地在到达过程末尾时发生的返回），我们将整个链组合成一个单独的***链***。例如，[图26.2](chapter026.xhtml#Fig_26-2)展示了在[图26.1](chapter026.xhtml#Fig_26-1)中蓝色阴影部分计算P-FIB(4)得到的跟踪。链不包括涉及并行或过程控制的指令。这些控制依赖必须在跟踪中表示为边。
- en: When a parent procedure calls a child, the trace contains an edge (*u*, *v*)
    from the strand *u* in the parent that executes the call to the first strand *v*
    of the spawned child, as illustrated in [Figure 26.2](chapter026.xhtml#Fig_26-2)
    by the edge from the orange strand in P-FIB(4) to the blue strand in P-FIB(2).
    When the last strand *v*′ in the child returns, the trace contains an edge (*v*′,
    *u*′) to the strand *u*′, where *u*′ is the successor strand of *u* in the parent,
    as with the edge from the white strand in P-FIB(2) to the white strand in P-FIB(4).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当父过程调用子过程时，跟踪中包含一条边（*u*, *v*），从父过程中执行调用的链 *u* 到生成的子过程中的第一个链 *v*，如[图26.2](chapter026.xhtml#Fig_26-2)所示，从P-FIB(4)中的橙色链到P-FIB(2)中的蓝色链。当子过程中的最后一个链
    *v*′ 返回时，跟踪中包含一条边（*v*′, *u*′）指向链 *u*′，其中 *u*′ 是父过程中 *u* 的后继链，就像从P-FIB(2)中的白色链到P-FIB(4)中的白色链的边一样。
- en: '![art](images/Art_P828.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![art](images/Art_P828.jpg)'
- en: '**Figure 26.2** The trace of P-FIB(4) corresponding to the shaded portion of
    [Figure 26.1](chapter026.xhtml#Fig_26-1). Each circle represents one strand, with
    blue circles representing any instructions executed in the part of the procedure
    (instance) up to the spawn of P-FIB (*n* − 1) in line 3; orange circles representing
    the instructions executed in the part of the procedure that calls P-FIB (*n* −
    2) in line 4 up to the **sync** in line 5, where it suspends until the spawn of
    P-FIB (*n* − 1) returns; and white circles representing the instructions executed
    in the part of the procedure after the **sync**, where it sums *x* and *y*, up
    to the point where it returns the result. Strands belonging to the same procedure
    are grouped into a rounded rectangle, blue for spawned procedures and tan for
    called procedures. Assuming that each strand takes unit time, the work is 17 time
    units, since there are 17 strands, and the span is 8 time units, since the critical
    path—shown with blue edges—contains 8 strands.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**图26.2** P-FIB(4)的跟踪对应于[图26.1](chapter026.xhtml#Fig_26-1)中阴影部分。每个圆代表一个链，蓝色圆代表在过程（实例）中执行到第3行生成P-FIB(*n*
    − 1)之前的任何指令；橙色圆代表在第4行调用P-FIB(*n* − 2)直到第5行**sync**之前执行的��何指令，然后在**sync**之后暂停，直到P-FIB(*n*
    − 1)返回；白色圆代表在**sync**之后执行的任何指令，计算*x*和*y*，直到返回结果的点。属于同一过程的链被分组到一个圆角矩形中，蓝色表示生成的过程，棕色表示调用的过程。假设每个链需要单位时间，工作时间为17个时间单位，因为有17个链，关键路径的时间为8个时间单位，因为关键路径—用蓝色边表示—包含8个链。'
- en: When the parent spawns a child, however, the trace is a little different. The
    edge (*u*, *v*) goes from parent to child as with a call, such as the edge from
    the blue strand in P-FIB(4) to the blue strand in P-FIB(3), but the trace contains
    another edge (*u*, *u*′) as well, indicating that *u*’s successor strand *u*′
    can continue to execute while *v* is executing. The edge from the blue strand
    in P-FIB(4) to the orange strand in P-FIB(4) illustrates one such edge. As with
    a call, there is an edge from the last strand *v*′ in the child, but with a spawn,
    it no longer goes to *u*’s successor. Instead, the edge is (*v*′, *x*), where
    *x* is the strand immediately following the **sync** in the parent that ensures
    that the child has finished, as with the edge from the white strand in P-FIB(3)
    to the white strand in P-FIB(4).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当父过程生成子过程时，跟踪会有些不同。边（*u*, *v*）从父过程到子过程，就像调用一样，例如从P-FIB(4)中的蓝色链到P-FIB(3)中的蓝色链的边，但跟踪还包含另一条边（*u*,
    *u*′），表示 *u* 的后继链 *u*′ 可以在 *v* 执行时继续执行。从P-FIB(4)中的蓝色链到P-FIB(4)中的橙色链的边说明了这样的一条边。与调用一样，子过程中的最后一个链
    *v*′ 也有一条边，但是对于生成，它不再指向 *u* 的后继。相反，边是（*v*′, *x*），其中 *x* 是父过程中确保子过程已完成的**sync**后紧随的链，就像从P-FIB(3)中的白色链到P-FIB(4)中的白色链的边一样。
- en: You can figure out what parallel control created a particular trace. If a strand
    has two successors, one of them must have been spawned, and if a strand has multiple
    predecessors, the predecessors joined because of a **sync** statement. Thus, in
    the general case, the set *V* forms the set of strands, and the set *E* of directed
    edges represents dependencies between strands induced by parallel and procedural
    control. If *G* contains a directed path from strand *u* to strand *v*, we say
    that the two strands are ***(logically) in series***. If there is no path in *G*
    either from *u* to *v* or from *v* to *u*, the strands are ***(logically) in parallel***.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以确定哪个并行控制创建了特定的跟踪。如果一个链有两个后继，其中一个必定是生成的，如果一个链有多个前驱，前驱是因为**sync**语句而加入。因此，在一般情况下，集合
    *V* 形成链的集合，有向边的集合 *E* 表示由并行和过程控制引起的链之间的依赖关系。如果 *G* 包含从链 *u* 到链 *v* 的有向路径，我们说这两个链是***(逻辑上)串行***的。如果在
    *G* 中从 *u* 到 *v* 或从 *v* 到 *u* 都没有路径，那么这些链是***(逻辑上)并行***的。
- en: A fork-join parallel trace can be pictured as a dag of strands embedded in an
    ***invocation tree*** of procedure instances. For example, [Figure 26.1](chapter026.xhtml#Fig_26-1)
    shows the invocation tree for FIB(6), which also serves as the invocation tree
    for P-FIB(6), the edges between procedure instances now representing either calls
    or spawns. [Figure 26.2](chapter026.xhtml#Fig_26-2) zooms in on the subtree that
    is shaded blue, showing the strands that constitute each procedure instance in
    P-FIB(4). All directed edges connecting strands run either within a procedure
    or along undirected edges of the invocation tree in [Figure 26.1](chapter026.xhtml#Fig_26-1).
    (More general task-parallel traces that are not fork-join traces may contain some
    directed edges that do not run along the undirected tree edges.)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 fork-join 并行迹线可以被描绘为嵌入在过程实例的***调用树***中的一组线程的有向无环图。例如，[图26.1](chapter026.xhtml#Fig_26-1)展示了
    FIB(6) 的调用树，这也是 P-FIB(6) 的调用树，现在过程实例之间的边代表调用或生成。[图26.2](chapter026.xhtml#Fig_26-2)放大了被蓝色阴影覆盖的子树，展示了构成
    P-FIB(4) 中每个过程实例的线程。连接线程的所有有向边要么在一���过程内运行，要么沿着[图26.1](chapter026.xhtml#Fig_26-1)中的调用树的无向边运行。（不是
    fork-join 迹线的更一般的任务并行迹线可能包含一些不沿着无向树边运行的有向边。）
- en: Our analyses generally assume that parallel algorithms execute on an ***ideal
    parallel computer***, which consists of a set of processors and a ***sequentially
    consistent*** shared memory. To understand sequential consistency, you first need
    to know that memory is accessed by ***load instructions***, which copy data from
    a location in the memory to a register within a processor, and by ***store instructions***,
    which copy data from a processor register to a location in the memory. A single
    line of pseudocode can entail several such instructions. For example, the line
    *x* = *y* + *z* could result in load instructions to fetch each of *y* and *z*
    from memory into a processor, an instruction to add them together inside the processor,
    and a store instruction to place the result *x* back into memory. In a parallel
    computer, several processors might need to load or store at the same time. Sequential
    consistency means that even if multiple processors attempt to access the memory
    simultaneously, the shared memory behaves as if exactly one instruction from one
    of the processors is executed at a time, even though the actual transfer of data
    may happen at the same time. It is as if the instructions were executed one at
    a time sequentially according to some global linear order among all the processors
    that preserves the individual orders in which each processor executes its own
    instructions.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析通常假设并行算法在一个***理想的并行计算机***上执行，该计算机由一组处理器和一个***顺序一致***的共享内存组成。要理解顺序一致性，首先需要知道内存是通过***加载指令***访问的，这些指令将数据从内存中的一个位置复制到处理器内的寄存器，并通过***存储指令***访问，这些指令将数据从处理器寄存器复制到内存中的位置。一行伪代码可能包含几个这样的指令。例如，行
    *x* = *y* + *z* 可能导致从内存中获取 *y* 和 *z* 的加载指令到处理器中，一个在处理器内将它们相加的指令，以及一个将结果 *x* 放回内存的存储指令。在并行计算机中，多个处理器可能需要同时加载或存储。顺序一致性意味着即使多个处理器尝试同时访问内存，共享内存的行为就好像来自其中一个处理器的一条指令一次执行一次，即使实际的数据传输可能同时发生。就好像指令按照保持每个处理器执行自己指令的顺序的全局线性顺序依次执行一样。
- en: For task-parallel computations, which are scheduled onto processors automatically
    by a runtime system, the sequentially consistent shared memory behaves as if a
    parallel computation’s executed instructions were executed one by one in the order
    of a topological sort (see [Section 20.4](chapter020.xhtml#Sec_20.4)) of its trace.
    That is, you can reason about the execution by imagining that the individual instructions
    (not generally the strands, which may aggregate many instructions) are interleaved
    in some linear order that preserves the partial order of the trace. Depending
    on scheduling, the linear order could vary from one run of the program to the
    next, but the behavior of any execution is always as if the instructions executed
    serially in a linear order consistent with the dependencies within the trace.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任务并行计算，这些计算会自动由运行时系统调度到处理器上，顺序一致的共享内存的行为就好像并行计算的执行指令按照其迹线的拓扑排序顺序（参见[第20.4节](chapter020.xhtml#Sec_20.4)）一次执行一条一样。也就是说，你可以通过想象单个指令（通常不是线程，可能会聚合许多指令）以保持迹线的偏序的某种线性顺序交错来推理执行。根据调度，线性顺序可能会在程序的每次运行中有所变化，但任何执行的行为总是好像指令按照迹线内的依赖关系在一致的线性顺序中串行执行。
- en: In addition to making assumptions about semantics, the ideal parallel-computer
    model makes some performance assumptions. Specifically, it assumes that each processor
    in the machine has equal computing power, and it ignores the cost of scheduling.
    Although this last assumption may sound optimistic, it turns out that for algorithms
    with sufficient “parallelism” (a term we’ll define precisely a little later),
    the overhead of scheduling is generally minimal in practice.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对语义做出假设外，理想的并行计算机模型还假设了一些性能假设。具体来说，它假设机器中的每个处理器具有相同的计算能力，并且忽略了调度的成本。尽管这最后一个假设听起来很乐观，但事实证明，对于具有足够“并行性”（稍后我们将精确定义的一个术语）的算法来说，调度的开销在实践中通常是最小的。
- en: '**Performance measures**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能指标**'
- en: 'We can gauge the theoretical efficiency of a task-parallel algorithm using
    ***work/span analysis***, which is based on two metrics: “work” and “span.” The
    ***work*** of a task-parallel computation is the total time to execute the entire
    computation on one processor. In other words, the work is the sum of the times
    taken by each of the strands. If each strand takes unit time, the work is just
    the number of vertices in the trace. The ***span*** is the fastest possible time
    to execute the computation on an unlimited number of processors, which corresponds
    to the sum of the times taken by the strands along a longest path in the trace,
    where “longest” means that each strand is weighted by its execution time. Such
    a longest path is called the ***critical path*** of the trace, and thus the span
    is the weight of the longest (weighted) path in the trace. ([Section 22.2](chapter022.xhtml#Sec_22.2),
    pages 617–619 shows how to find a critical path in a dag *G* = (*V*, *E*) in Θ(*V*
    + *E*) time.) For a trace in which each strand takes unit time, the span equals
    the number of strands on the critical path. For example, the trace of [Figure
    26.2](chapter026.xhtml#Fig_26-2) has 17 vertices in all and 8 vertices on its
    critical path, so that if each strand takes unit time, its work is 17 time units
    and its span is 8 time units.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 通过***工作/跨度分析***，我们可以衡量任务并行算法的理论效率，这基于两个指标：“工作”和“跨度”。任务并行计算的***工作***是在一个处理器上执行整个计算所需的总时间。换句话说，工作是每个线程所花费的时间之和。如果每个线程都花费单位时间，那么工作就是追踪中的顶点数。***跨度***是在无限数量处理器上执行计算的最快时间，对应于追踪中沿最长路径所花费的线程时间之和，其中“最长”意味着每个线程按其执行时间加权。这样的最长路径称为追踪的***关键路径***，因此跨度是追踪中最长（加权）路径的权重。([第22.2节](chapter022.xhtml#Sec_22.2)，页面617-619展示了如何在Θ(*V*
    + *E*)时间内找到dag *G* = (*V*, *E*)中的关键路径。)对于每个线程都花费单位时间的追踪，跨度等于关键路径上的线程数。例如，[图26.2](chapter026.xhtml#Fig_26-2)的追踪总共有17个顶点，关键路径上有8个顶点，因此如果每个线程花费单位时间，其工作是17个时间单位，跨度是8个时间单位。
- en: The actual running time of a task-parallel computation depends not only on its
    work and its span, but also on how many processors are available and how the scheduler
    allocates strands to processors. To denote the running time of a task-parallel
    computation on *P* processors, we subscript by *P*. For example, we might denote
    the running time of an algorithm on *P* processors by *T*[*P*]. The work is the
    running time on a single processor, or *T*[1]. The span is the running time if
    we could run each strand on its own processor—in other words, if we had an unlimited
    number of processors—and so we denote the span by *T*[∞].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 任务并行计算的实际运行时间不仅取决于其工作和跨度，还取决于有多少处理器可用以及调度程序如何将线程分配给处理器。为了表示在*P*个处理器上的任务并行计算的运行时间，我们用*P*作为下标。例如，我们可以用*T*[*P*]表示算法在*P*个处理器上的运行时间。工作是在单个处理器上的运行时间，或者*T*[1]。跨度是如果我们可以让每个线程在自己的处理器上运行的运行时间，换句话说，如果我们有无限数量的处理器，因此我们用*T*[∞]表示跨度。
- en: 'The work and span provide lower bounds on the running time *T*[*P*] of a task-parallel
    computation on *P* processors:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 工作和跨度为任务并行计算在*P*个处理器上的运行时间*T*[*P*]提供了下界：
- en: 'In one step, an ideal parallel computer with *P* processors can do at most
    *P* units of work, and thus in *T*[*P*] time, it can perform at most *P T[P]*
    work. Since the total work to do is *T*[1], we have *P T[P]* ≥ *T*[1]. Dividing
    by *P* yields the ***work law***:'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一步中，具有*P*个处理器的理想并行计算机最多可以执行*P*单位的工作，因此在*T*[*P*]时间内，它最多可以执行*P T[P]*的工作。由于要完成的总工作量为*T*[1]，我们有*P
    T[P]* ≥ *T*[1]。除以*P*得到***工作定律***：
- en: '![art](images/Art_P829.jpg)'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![art](images/Art_P829.jpg)'
- en: 'A *P*-processor ideal parallel computer cannot run any faster than a machine
    with an unlimited number of processors. Looked at another way, a machine with
    an unlimited number of processors can emulate a *P*-processor machine by using
    just *P* of its processors. Thus, the ***span law*** follows:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*P*处理器的理想并行计算机不能比具有无限数量处理器的机器运行得更快。从另一个角度看，具有无限数量处理器的机器可以通过仅使用其中的*P*个处理器来模拟*P*处理器的机器。因此，***跨度定律***成立：
- en: '![art](images/Art_P830.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![art](images/Art_P830.jpg)'
- en: We define the ***speedup*** of a computation on *P* processors by the ratio
    *T*[1]/*T*[*P*], which says how many times faster the computation runs on *P*
    processors than on one processor. By the work law, we have *T*[*P*] ≥ *T*[1]/*P*,
    which implies that *T*[1]/*T*[*P*] ≤ *P*. Thus, the speedup on a *P*-processor
    ideal parallel computer can be at most *P*. When the speedup is linear in the
    number of processors, that is, when *T*[1]/*T*[*P*] = Θ(*P*), the computation
    exhibits ***linear speedup***. ***Perfect linear speedup*** occurs when *T*[1]/*T*[*P*]
    = *P*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过计算在*P*个处理器上的运行时间*T*[1]/*T*[*P*]的比率来定义计算的***加速比***，这表示计算在*P*个处理器上比在一个处理器上运行快多少倍。根据工作定律，我们有*T*[*P*]
    ≥ *T*[1]/*P*，这意味着*T*[1]/*T*[*P*] ≤ *P*。因此，在*P*处理器的理想并行计算机上的加速比最多为*P*。当加速比与处理器数量呈线性关系时，即*T*[1]/*T*[*P*]
    = Θ(*P*)时，计算表现出***线性加速***。***完美的线性加速***发生在*T*[1]/*T*[*P*] = *P*。
- en: The ratio *T*[1]/*T*[∞] of the work to the span gives the ***parallelism***
    of the parallel computation. We can view the parallelism from three perspectives.
    As a ratio, the parallelism denotes the average amount of work that can be performed
    in parallel for each step along the critical path. As an upper bound, the parallelism
    gives the maximum possible speedup that can be achieved on any number of processors.
    Perhaps most important, the parallelism provides a limit on the possibility of
    attaining perfect linear speedup. Specifically, once the number of processors
    exceeds the parallelism, the computation cannot possibly achieve perfect linear
    speedup. To see this last point, suppose that *P* > *T*[1]/*T*[∞], in which case
    the span law implies that the speedup satisfies *T*[1]/*T*[*P*] ≤ *T*[1]/*T*[∞]
    < *P*. Moreover, if the number *P* of processors in the ideal parallel computer
    greatly exceeds the parallelism—that is, if *P* ≫ *T*[1]/*T*[∞]—then *T*[1]/*T*[*P*]
    ≪ *P*, so that the speedup is much less than the number of processors. In other
    words, if the number of processors exceeds the parallelism, adding even more processors
    makes the speedup less perfect.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 工作量与跨度的比值*T*[1]/*T*[∞]给出了并行计算的***并行性***。我们可以从三个角度看待并行性。作为比值，并行性表示沿关键路径每一步可以并行执行的平均工作量。作为一个上限，并行性给出了在任意数量的处理器上可以实现的最大可能加速比。也许最重要的是，并行性为实现完美线性加速提供了一个限制。具体来说，一旦处理器数量超过并行性，计算就不可能实现完美线性加速。为了看到这一点，假设*P*
    > *T*[1]/*T*[∞]，在这种情况下，跨度定律意味着加速比满足*T*[1]/*T*[*P*] ≤ *T*[1]/*T*[∞] < *P*。此外，如果理想并行计算机中的处理器数量*P*远远超过并行性，即如果*P*
    ≫ *T*[1]/*T*[∞]，那么*T*[1]/*T*[*P*] ≪ *P*，因此加速比远远小于处理器数量。换句话说，如果处理器数量超过并行性，即使再增加更多处理器，加速比也会变得不那么完美。
- en: As an example, consider the computation P-FIB(4) in [Figure 26.2](chapter026.xhtml#Fig_26-2),
    and assume that each strand takes unit time. Since the work is *T*[1] = 17 and
    the span is *T*[∞] = 8, the parallelism is *T*[1]/*T*[∞] = 17/8 = 2.125\. Consequently,
    achieving much more than double the performance is impossible, no matter how many
    processors execute the computation. For larger input sizes, however, we’ll see
    that P-FIB (*n*) exhibits substantial parallelism.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，考虑在[图26.2](chapter026.xhtml#Fig_26-2)中计算P-FIB(4)，假设每个线程花费单位时间。由于工作量为*T*[1]
    = 17，跨度为*T*[∞] = 8，因此并行性为*T*[1]/*T*[∞] = 17/8 = 2.125。因此，无论有多少处理器执行计算，都不可能实现远远超过两倍的性能。然而，对于更大的输入大小，我们将看到P-FIB(*n*)表现出相当大的并行性。
- en: We define the ***(parallel) slackness*** of a task-parallel computation executed
    on an ideal parallel computer with *P* processors to be the ratio (*T*[1]/*T*[∞])/*P*
    = *T*[1]/(*P T*[∞]), which is the factor by which the parallelism of the computation
    exceeds the number of processors in the machine. Restating the bounds on speedup,
    if the slackness is less than 1, perfect linear speedup is impossible, because
    *T*[1]/(*P T*[∞]) < 1 and the span law imply that *T*[1]/*T*[*P*] ≤ *T*[1]/*T*[∞]
    < *P*. Indeed, as the slackness decreases from 1 and approaches 0, the speedup
    of the computation diverges further and further from perfect linear speedup. If
    the slackness is less than 1, additional parallelism in an algorithm can have
    a great impact on its execution efficiency. If the slackness is greater than 1,
    however, the work per processor is the limiting constraint. We’ll see that as
    the slackness increases from 1, a good scheduler can achieve closer and closer
    to perfect linear speedup. But once the slackness is much greater than 1, the
    advantage of additional parallelism shows diminishing returns.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义在具有*P*个处理器的理想并行计算机上执行的任务并行计算的***(并行)松弛度***为比值(*T*[1]/*T*[∞])/*P* = *T*[1]/(*P
    T*[∞])，这是计算的并行性超过机器处理器数量的因子。重新陈述关于加速比的界限，如果松弛度小于1，完美线性加速是不可能的，因为*T*[1]/(*P T*[∞])
    < 1，跨度定律意味着*T*[1]/*T*[*P*] ≤ *T*[1]/*T*[∞] < *P*。实际上，随着松弛度从1减小并接近0，计算的加速比与完美线性加速之间的差距进一步扩大。如果松弛度小于1，算法中的额外并行性可以对其执行效率产生巨大影响。然而，如果松弛度大于1，工作量每处理器是限制性约束。我们将看到，随着松弛���从1增加，一个好的调度程序可以实现接近完美线性加速。但是一旦松弛度远远大于1，额外并行性的优势将呈现递减回报。
- en: '**Scheduling**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**调度**'
- en: Good performance depends on more than just minimizing the work and span. The
    strands must also be scheduled efficiently onto the processors of the parallel
    machine. Our fork-join parallel-programming model provides no way for a programmer
    to specify which strands to execute on which processors. Instead, we rely on the
    runtime system’s scheduler to map the dynamically unfolding computation to individual
    processors. In practice, the scheduler maps the strands to static threads, and
    the operating system schedules the threads on the processors themselves. But this
    extra level of indirection is unnecessary for our understanding of scheduling.
    We can just imagine that the scheduler maps strands to processors directly.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 优秀的性能不仅仅取决于最小化工作量和跨度。这些线程还必须有效地安排到并行计算机的处理器上。我们的fork-join并行编程模型不提供程序员指定哪些线程在哪些处理器上执行的方法。相反，我们依赖于运行时系统的调度程序将动态展开的计算映射到各个处理器上。在实践中，调度程序将线程映射到静态线程，操作系统将线程调度到处理器上。但是这种额外的间接层对我们理解调度是不必要的。我们可以想象调度程序直接将线程映射到处理器。
- en: A task-parallel scheduler must schedule the computation without knowing in advance
    when procedures will be spawned or when they will finish—that is, it must operate
    ***online***. Moreover, a good scheduler operates in a distributed fashion, where
    the threads implementing the scheduler cooperate to load-balance the computation.
    Provably good online, distributed schedulers exist, but analyzing them is complicated.
    Instead, to keep our analysis simple, we’ll consider an online ***centralized***
    scheduler that knows the global state of the computation at any moment.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 任务并行调度器必须在不知道何时生成过程或何时完成它们的情况下调度计算 - 也就是说，它必须在***在线***操作。此外，一个好的调度器以分布式方式运行，在其中实现调度器的线程合作以平衡负载计算。可以证明，良好的在线、分布式调度器存在，但分析它们很复杂。为了保持我们的分析简单，我们将考虑一个在线***集中***调度器，它在任何时刻都知道计算的全局状态。
- en: 'In particular, we’ll analyze ***greedy schedulers***, which assign as many
    strands to processors as possible in each time step, never leaving a processor
    idle if there is work that can be done. We’ll classify each step of a greedy scheduler
    as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，我们将分析***贪婪调度器***，它在每个时间步骤中将尽可能多的线索分配给处理器，如果有工作可以完成，则永远不会让处理器空闲。我们将对贪婪调度器的每个步骤进行分类：
- en: '***Complete step***: At least *P* strands are ***ready*** to execute, meaning
    that all strands on which they depend have finished execution. A greedy scheduler
    assigns any *P* of the ready strands to the processors, completely utilizing all
    the processor resources.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***完整步骤***：至少*P*条线索准备好执行，这意味着它们所依赖的所有线索都已执行完毕。贪婪调度器将准备好的任何*P*条线索分配给处理器，完全利用所有处理器资源。'
- en: '***Incomplete step***: Fewer than *P* strands are ready to execute. A greedy
    scheduler assigns each ready strand to its own processor, leaving some processors
    idle for the step, but executing all the ready strands.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***不完整步骤***：少于*P*条线索准备执行。贪婪调度器将每个准备好的线索分配给各自的处理器，导致一些处理器在该步骤中空闲，但执行所有准备好的线索。'
- en: The work law tells us that the fastest running time *T*[*P*] that we can hope
    for on *P* processors must be at least *T*[1]/*P*. The span law tells us that
    the fastest possible running time must be at least *T*[∞]. The following theorem
    shows that greedy scheduling is provably good in that it achieves the sum of these
    two lower bounds as an upper bound.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 工作定律告诉我们，在*P*处理器上我们可以希望的最快运行时间*T*[*P*]必须至少为*T*[1]/*P*。跨度定律告诉我们，最快可能的运行时间必须至少为*T*[∞]。以下定理表明，贪婪调度在达到这两个下界的总和作为上界方面是可以证明的好的。
- en: '***Theorem 26.1***'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '***定理 26.1***'
- en: On an ideal parallel computer with *P* processors, a greedy scheduler executes
    a task-parallel computation with work *T*[1] and span *T*[∞] in time
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有*P*处理器的理想并行计算机上，贪婪调度器在时间内执行任务并行计算的工作*T*[1]和跨度*T*[∞]
- en: '![art](images/Art_P831.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![art](images/Art_P831.jpg)'
- en: '***Proof***   Without loss of generality, assume that each strand takes unit
    time. (If necessary, replace each longer strand by a chain of unit-time strands.)
    We’ll consider complete and incomplete steps separately.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '***证明*** 无损失地假设每个线索花费单位时间。（如有必要，将每个较长的线索替换为一系列单位时间线索。）我们将分别考虑完整和不完整步骤。'
- en: In each complete step, the *P* processors together perform a total of *P* work.
    Thus, if the number of complete steps is *k*, the total work executing all the
    complete steps is *kP*. Since the greedy scheduler doesn’t execute any strand
    more than once and only *T*[1] work needs to be performed, it follows that *kP*
    ≤ *T*[1], from which we can conclude that the number *k* of complete steps is
    at most *T*[1]/*P*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个完整步骤中，*P*个处理器共同执行*P*个工作。因此，如果完整步骤的数量为*k*，则执行所有完整步骤的总工作量为*kP*。由于贪婪调度器不会执行任何线索超过一次，且只需执行*T*[1]的工作，因此得出*kP*≤*T*[1]，从中我们可以得出完整步骤的数量*k*最多为*T*[1]/*P*。
- en: Now, let’s consider an incomplete step. Let *G* be the trace for the entire
    computation, let *G*′ be the subtrace of *G* that has yet to be executed at the
    start of the incomplete step, and let *G*″ be the subtrace remaining to be executed
    after the incomplete step. Consider the set *R* of strands that are ready at the
    beginning of the incomplete step, where |*R*| < *P*. By definition, if a strand
    is ready, all its predecessors in trace *G* have executed. Thus the predecessors
    of strands in *R* do not belong to *G*′. A longest path in *G*′ must necessarily
    start at a strand in *R*, since every other strand in *G*′ has a predecessor and
    thus could not start a longest path. Because the greedy scheduler executes all
    ready strands during the incomplete step, the strands of *G*″ are exactly those
    in *G*′ minus the strands in *R*. Consequently, the length of a longest path in
    *G*″ must be 1 less than the length of a longest path in *G*′. In other words,
    every incomplete step decreases the span of the trace remaining to be executed
    by 1\. Hence, the number of incomplete steps can be at most *T*[∞].
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑一个不完整的步骤。让*G*是整个计算的跟踪，让*G*′是在不完整步骤开始时尚未执行的子跟踪，让*G*″是在不完整步骤后剩余要执行的子跟踪。考虑在不完整步骤开始时准备好的线索集合*R*，其中|*R*|<*P*。根据定义，如果一个线索准备好，那么它的所有前导线索都已执行。因此，*R*中线索的前导线索不属于*G*′。*G*′中的最长路径必须从*R*中的一条线索开始，因为*G*′中的每条其他线索都有一个前导线索，因此不能开始最长路径。由于贪婪调度器在不完整步骤中执行所有准备好的线索，*G*″中的线索正好是*G*′中减去*R*中的线索。因此，*G*″中最长路径的长度必须比*G*′中最长路径的长度少1。换句话说，每个不完整步骤将要执行的跟踪的跨度减少1。因此，不完整步骤的数量最多为*T*[∞]。
- en: Since each step is either complete or incomplete, the theorem follows.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个步骤要么完成，要么不完整，所以定理成立。
- en: ▪
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ▪
- en: The following corollary shows that a greedy scheduler always performs well.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 以下推论表明贪婪调度器始终表现良好。
- en: '***Corollary 26.2***'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '***推论 26.2***'
- en: The running time *T*[*P*] of any task-parallel computation scheduled by a greedy
    scheduler on a *P*-processor ideal parallel computer is within a factor of 2 of
    optimal.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 任何在*P*处理器理想并行计算机上由贪婪调度器调度的任务并行计算的运行时间*T*[*P*]在最优解的范围内。
- en: '***Proof***   Let *T**[*P*] be the running time produced by an optimal scheduler
    on a machine with *P* processors, and let *T*[1] and *T*[∞] be the work and span
    of the computation, respectively. Since the work and span laws—inequalities (26.2)
    and (26.3)—give ![art](images/Art_P831a.jpg), Theorem 26.1 implies that'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '***证明*** 让*T**[*P*]表示在具有*P*个处理器的机器上由最佳调度器产生的运行时间，*T*[1]和*T*[∞]分别表示计算的工作量和跨度。由于工作和跨度定律——不等式（26.2）和（26.3）给出了![艺术](images/Art_P831a.jpg)，定理26.1暗示着'
- en: '![art](images/Art_P831b.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P831b.jpg)'
- en: ▪
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ▪
- en: The next corollary shows that, in fact, a greedy scheduler achieves near-perfect
    linear speedup on any task-parallel computation as the slackness grows.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个推论表明，实际上，随着松弛度的增加，贪婪调度器在任何任务并行计算上实现了接近完美的线性加速。
- en: '***Corollary 26.3***'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '***推论26.3***'
- en: Let *T*[*P*] be the running time of a task-parallel computation produced by
    a greedy scheduler on an ideal parallel computer with *P* processors, and let
    *T*[1] and *T*[∞]be the work and span of the computation, respectively. Then,
    if *P* ≪ *T*[1]/*T*[∞], or equivalently, the parallel slackness is much greater
    than 1, we have *T*[*P*] ≈ *T*[1]/*P*, a speedup of approximately *P*.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让*T*[*P*]表示贪婪调度器在理想并行计算机上使用*P*个处理器产生的任务并行计算的运行时间，*T*[1]和*T*[∞]分别表示计算的工作量和跨度。那么，如果*P*
    ≪ *T*[1]/*T*[∞]，或者等价地，并行松弛度远大于1，我们有*T*[*P*] ≈ *T*[1]/*P*，近似为*P*的加速。
- en: '***Proof***   If we suppose that *P* ≪ *T*[1]/*T*[∞], then it follows that
    *T*[∞] ≪ *T*[1]/*P*, and hence Theorem 26.1 gives *T*[*P*] ≤ *T*[1]/*P* + *T*[∞]
    ≈ *T*[1]/*P*. Since the work law (26.2) dictates that *T*[*P*] ≥ *T*[1]/*P*, we
    conclude that *T*[*P*] ≈ *T*[1]/*P*, which is a speedup of *T*[1]/*T*[*P*] ≈ *P*.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '***证明*** 如果我们假设*P* ≪ *T*[1]/*T*[∞]，那么可以得出*T*[∞] ≪ *T*[1]/*P*，因此根据定理26.1，有*T*[*P*]
    ≤ *T*[1]/*P* + *T*[∞] ≈ *T*[1]/*P*。由于工作定律（26.2）规定*T*[*P*] ≥ *T*[1]/*P*，我们得出*T*[*P*]
    ≈ *T*[1]/*P*，这是*T*[1]/*T*[*P*] ≈ *P*的加速。'
- en: ▪
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ▪
- en: The ≪ symbol denotes “much less,” but how much is “much less”? As a rule of
    thumb, a slackness of at least 10—that is, 10 times more parallelism than processors—generally
    suffices to achieve good speedup. Then, the span term in the greedy bound, inequality
    (26.4), is less than 10% of the work-per-processor term, which is good enough
    for most engineering situations. For example, if a computation runs on only 10
    or 100 processors, it doesn’t make sense to value parallelism of, say 1,000,000,
    over parallelism of 10,000, even with the factor of 100 difference. As Problem
    26-2 shows, sometimes reducing extreme parallelism yields algorithms that are
    better with respect to other concerns and which still scale up well on reasonable
    numbers of processors.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ≪符号表示“远小于”���但“远小于”是多少呢？一般来说，至少有10倍于处理器数量的并行度，通常足以实现良好的加速。然后，贪婪界限中的跨度项，不等式（26.4），小于每处理器工作量项的10%，对于大多数工程情况来说已经足够好。例如，如果一个计算仅在10或100个处理器上运行，那么将并行度从1,000,000降低到10,000是没有意义的，即使有100倍的差异。正如问题26-2所示，有时减少极端并行度会产生在其他方面更好的算法，并且在合理数量的处理器上仍然能够良好扩展。
- en: '**Analyzing parallel algorithms**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**分析并行算法**'
- en: We now have all the tools we need to analyze parallel algorithms using work/span
    analysis, allowing us to bound an algorithm’s running time on any number of processors.
    Analyzing the work is relatively straightforward, since it amounts to nothing
    more than analyzing the running time of an ordinary serial algorithm, namely,
    the serial projection of the parallel algorithm. You should already be familiar
    with analyzing work, since that is what most of this textbook is about! Analyzing
    the span is the new thing that parallelism engenders, but it’s generally no harder
    once you get the hang of it. Let’s investigate the basic ideas using the P-FIB
    program.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有分析并行算法所需的所有工具，使用工作/跨度分析，我们可以限制算法在任意数量的处理器上的运行时间。分析工作相对简单，因为它实际上就是分析普通串行算法的运行时间，即并行算法的串行投影。你应该已经熟悉分析工作，因为这本教材的大部分内容都是关于这个的！分析跨度是并行性带来的新事物，但一旦掌握了，通常并不难。让我们使用P-FIB程序探讨基本思想。
- en: Analyzing the work *T*[1](*n*) of P-FIB (*n*) poses no hurdles, because we’ve
    already done it. The serial projection of P-FIB is effectively the original FIB
    procedure, and hence, we have *T*[1](*n*) = *T* (*n*) = Θ(*ϕ*^(*n*)) from equation
    (26.1).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 分析P-FIB(*n*)的工作量*T*[1](*n*)并不困难，因为我们已经做过了。P-FIB的串行投影实际上就是原始的FIB过程，因此根据方程（26.1），我们有*T*[1](*n*)
    = *T*(*n*) = Θ(*ϕ*^(*n*))。
- en: '[Figure 26.3](chapter026.xhtml#Fig_26-3) illustrates how to analyze the span.
    If two traces are joined in series, their spans add to form the span of their
    composition, whereas if they are joined in parallel, the span of their composition
    is the maximum of the spans of the two traces. As it turns out, the trace of any
    fork-join parallel computation can be built up from single strands by series-parallel
    composition.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[图26.3](chapter026.xhtml#Fig_26-3)说明了如何分析跨度。如果两个轨迹串联，它们的跨度相加形成组合的跨度，而如果它们并联，组合的跨度是两个轨迹跨度的最大值。事实证明，任何分叉-合并并行计算的轨迹都可以通过串并联组合从单根线构建起来。'
- en: '![art](images/Art_P832.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P832.jpg)'
- en: '**Figure 26.3** Series-parallel composition of parallel traces. **(a)** When
    two traces are joined in series, the work of the composition is the sum of their
    work, and the span of the composition is the sum of their spans. **(b)** When
    two traces are joined in parallel, the work of the composition remains the sum
    of their work, but the span of the composition is only the maximum of their spans.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**图26.3** 并行轨迹的串并联组合。**(a)** 当两个轨迹串联时，组合的工作量是它们工作量的总和，组合的跨度是它们跨度的总和。**(b)**
    当两个轨迹并联时，组合的工作量仍然是它们工作量的总和，但组合的跨度只是它们跨度的最大值。'
- en: Armed with an understanding of series-parallel composition, we can analyze the
    span of P-FIB (*n*). The spawned call to P-FIB (*n* − 1) in line 3 runs in parallel
    with the call to P-FIB (*n* − 2) in line 4\. Hence, we can express the span of
    P-FIB (*n*) as the recurrence
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 有了对串行-并行组合的理解，我们可以分析 P-FIB (*n*) 的跨度。第 3 行中对 P-FIB (*n* − 1) 的生成调用与第 4 行中对 P-FIB
    (*n* − 2) 的调用并行运行。因此，我们可以将 P-FIB (*n*) 的跨度表示为递归关系
- en: '| *T*[∞](*n*) | = | max {*T*[∞](*n* − 1), *T*[∞](*n* − 2)} + Θ(1) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| *T*[∞](*n*) | = | max {*T*[∞](*n* − 1), *T*[∞](*n* − 2)} + Θ(1) |'
- en: '|  | = | *T*[∞](*n* − 1) + Θ(1), |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  | = | *T*[∞](*n* − 1) + Θ(1), |'
- en: which has solution *T*[∞](*n*) = Θ(*n*). (The second equality above follows
    from the first because P-FIB (*n* − 1) uses P-FIB (*n* − 2) in its computation,
    so that the span of P-FIB (*n* − 1) must be at least as large as the span of P-FIB
    (*n* − 2).)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 其中解为 *T*[∞](*n*) = Θ(*n*)。（上述第二个等式来自于第一个，因为 P-FIB (*n* − 1) 在计算中使用了 P-FIB (*n*
    − 2)，所以 P-FIB (*n* − 1) 的跨度至少与 P-FIB (*n* − 2) 的跨度一样大。）
- en: The parallelism of P-FIB (*n*) is *T*[1](*n*)/*T*[∞](*n*) = Θ(*ϕ*^(*n*)/*n*),
    which grows dramatically as *n* gets large. Thus, Corollary 26.3 tells us that
    on even the largest parallel computers, a modest value for *n* suffices to achieve
    near perfect linear speedup for P-FIB (*n*), because this procedure exhibits considerable
    parallel slackness.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: P-FIB (*n*) 的并行性为 *T*[1](*n*)/*T*[∞](*n*) = Θ(*ϕ*^(*n*)/*n*)，随着 *n* 的增大而急剧增长。因此，推论
    26.3 告诉我们，即使在最大的并行计算机上，对于 P-FIB (*n*)，一个适度的 *n* 值就足以实现接近完美的线性加速，因为该过程表现出相当大的并行松弛度。
- en: '**Parallel loops**'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行循环**'
- en: Many algorithms contain loops for which all the iterations can operate in parallel.
    Although the **spawn** and **sync** keywords can be used to parallelize such loops,
    it is more convenient to specify directly that the iterations of such loops can
    run in parallel. Our pseudocode provides this functionality via the **parallel**
    keyword, which precedes the **for** keyword in a **for** loop statement.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 许多算法包含循环，其中所有迭代都可以并行操作。虽然 **spawn** 和 **sync** 关键字可以用于并行化这样的循环，但更方便的是直接指定这样的循环的迭代可以并行运行。我们的伪代码通过
    **parallel** 关键字提供了这种功能，该关键字在 **for** 循环语句的 **for** 关键字之前。
- en: As an example, consider the problem of multiplying a square *n* × *n* matrix
    *A* = (*a[ij]*) by an *n*-vector *x* = (*x*[*j*]). The resulting *n*-vector *y*
    = (*y*[*i*]) is given by the equation
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，考虑将一个 *n* × *n* 方阵 *A* = (*a[ij]*) 乘以一个 *n* 向量 *x* = (*x*[*j*]) 的问题。得到的
    *n* 向量 *y* = (*y*[*i*]) 由方程给出
- en: '![art](images/Art_P833.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![art](images/Art_P833.jpg)'
- en: for *i* = 1, 2, … , *n*. The P-MAT-VEC procedure performs matrix-vector multiplication
    (actually, *y* = *y* + *Ax*) by computing all the entries of *y* in parallel.
    The **parallel for** keywords in line 1 of P-MAT-VEC indicate that the *n* iterations
    of the loop body, which includes a serial **for** loop, may be run in parallel.
    The initialization *y* = 0, if desired, should be performed before calling the
    procedure (and can be done with a **parallel for** loop).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *i* = 1, 2, … , *n*。P-MAT-VEC 过程通过并行计算 *y* 的所有条目来执行矩阵-向量乘法（实际上，*y* = *y*
    + *Ax*）。P-MAT-VEC 中第 1 行的 **parallel for** 关键字表示循环体的 *n* 次迭代（包括一个串行 **for** 循环）可以并行运行。如果需要，初始化
    *y* = 0 应该在调用该过程之前执行（可以使用 **parallel for** 循环完成）。
- en: P-MAT-VEC (*A*, *x*, *y*, *n*)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: P-MAT-VEC (*A*, *x*, *y*, *n*)
- en: '| 1 | **parallel for** *i* = 1 **to** *n* | **//** parallel loop |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **parallel for** *i* = 1 **to** *n* | **//** 并行循环 |'
- en: '| 2 | **for** *j* = 1 **to** *n* | **//** serial loop |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **for** *j* = 1 **to** *n* | **//** 串行循环 |'
- en: '| 3 | *y*[*i*] = *y*[*i*] + *a*[*ij*] *x*[*j*] |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 3 | *y*[*i*] = *y*[*i*] + *a*[*ij*] *x*[*j*] |'
- en: Compilers for fork-join parallel programs can implement **parallel for** loops
    in terms of **spawn** and **sync** by using recursive spawning. For example, for
    the **parallel for** loop in lines 1–3, a compiler can generate the auxiliary
    subroutine P-MAT-VEC-RECURSIVE and call P-MAT-VEC-RECURSIVE (*A*, *x*, *y*, *n*,
    1, *n*) in the place where the loop would be in the compiled code. As [Figure
    26.4](chapter026.xhtml#Fig_26-4) illustrates, this procedure recursively spawns
    the first half of the iterations of the loop to execute in parallel (line 5) with
    the second half of the iterations (line 6) and then executes a **sync** (line
    7), thereby creating a binary tree of parallel execution. Each leaf represents
    a base case, which is the serial **for** loop of lines 2–3.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '用于 fork-join 并行程序的编译器可以通过使用递归生成来实现 **parallel for** 循环，例如，对于第 1–3 行中的 **parallel
    for** 循环，编译器可以生成辅助子程序 P-MAT-VEC-RECURSIVE 并在编译后的代码中的循环位置调用 P-MAT-VEC-RECURSIVE
    (*A*, *x*, *y*, *n*, 1, *n*)。正如 [图 26.4](chapter026.xhtml#Fig_26-4) 所示，该过程递归地生成循环的前一���迭代以并行执行（第
    5 行），与后一半迭代（第 6 行）并行执行，然后执行 **sync**（第 7 行），从而创建一个并行执行的二叉树。每个叶子代表一个基本情况，即第 2–3
    行的串行 **for** 循环。 '
- en: P-MAT-VEC-RECURSIVE (*A*, *x*, *y*, *n*, *i*, *i′*)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: P-MAT-VEC-RECURSIVE (*A*, *x*, *y*, *n*, *i*, *i′*)
- en: '| 1 | **if** *i* == *i*′ | **//** just one iteration to do? |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **if** *i* == *i*′ | **//** 只有一个迭代要执行？ |'
- en: '| 2 | **for** *j* = 1 **to** *n* | **//** mimic P-MAT-VEC serial loop |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **for** *j* = 1 **to** *n* | **//** 模拟 P-MAT-VEC 串行循环 |'
- en: '| 3 | *y*[*i*] = *y*[*i*] + *a*[*ij*] *x*[*j*] |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 3 | *y*[*i*] = *y*[*i*] + *a*[*ij*] *x*[*j*] |'
- en: '| 4 | **else** *mid* = ⌊(*i* + *i*′)/2⌋ | **//** parallel divide-and-conquer
    |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 4 | **else** *mid* = ⌊(*i* + *i*′)/2⌋ | **//** 并行分治 |'
- en: '| 5 | **spawn** P-MAT-VEC-RECURSIVE (*A*, *x*, *y*, *n*, *i*, *mid*) |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 5 | **spawn** P-MAT-VEC-RECURSIVE (*A*, *x*, *y*, *n*, *i*, *mid*) |'
- en: '| 6 | P-MAT-VEC-RECURSIVE (*A*, *x*, *y*, *n*, *mid* + 1, *i′*) |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 6 | P-MAT-VEC-RECURSIVE (*A*, *x*, *y*, *n*, *mid* + 1, *i′*) |'
- en: '| 7 | **sync** |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 7 | **sync** |'
- en: To calculate the work *T*[1](*n*) of P-MAT-VEC on an *n*×*n* matrix, simply
    compute the running time of its serial projection, which comes from replacing
    the **parallel** **for** loop in line 1 with an ordinary **for** loop. The running
    time of the resulting serial pseudocode is Θ(*n*²), which means that *T*[1](*n*)
    = Θ(*n*²). This analysis seems to ignore the overhead for recursive spawning in
    implementing the parallel loops, however. Indeed, the overhead of recursive spawning
    does increase the work of a parallel loop compared with that of its serial projection,
    but not asymptotically. To see why, observe that since the tree of recursive procedure
    instances is a full binary tree, the number of internal nodes is one less than
    the number of leaves (see Exercise B.5-3 on page 1175). Each internal node performs
    constant work to divide the iteration range, and each leaf corresponds to a base
    case, which takes at least constant time (Θ(*n*) time in this case). Thus, by
    amortizing the overhead of recursive spawning over the work of the iterations
    in the leaves, we see that the overall work increases by at most a constant factor.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算 *n*×*n* 矩阵上 P-MAT-VEC 的工作量 *T*[1](*n*)，只需计算其串行投影的运行时间，这是通过将第 1 行中的 **parallel
    for** 循环替换为普通 **for** 循环得到的。结果串行伪代码的运行时间是 Θ(*n*²)，这意味着 *T*[1](*n*) = Θ(*n*²)。然而，这种分析似乎忽略了在实现并行循环中递归生成的开销。实际上，与串行投影相比，递归生成的开销会增加并行循环的工作量，但不是渐近的。要了解原因，观察到由于递归过程实例的树是完全二叉树，内部节点的数量比叶子节点的数量少一个（参见第
    1175 页的练习 B.5-3）。每个内部节点执行常数工作来划分迭代范围，每个叶子对应于一个基本情况，这至少需要常数时间（在这种情况下是 Θ(*n*) 时间）。因此，通过将递归生成的开销摊销到叶子中的迭代工作上，我们看到总体工作量最多增加一个常数因子。
- en: '![art](images/Art_P834.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P834.jpg)'
- en: '**Figure 26.4** A trace for the computation of P-MAT-VEC-RECURSIVE (*A*, *x*,
    *y*, 8, 1, 8). The two numbers within each rounded rectangle give the values of
    the last two parameters (*i* and *i*′ in the procedure header) in the invocation
    (spawn, in blue, or call, in tan) of the procedure. The blue circles represent
    strands corresponding to the part of the procedure up to the spawn of P-MAT-VEC-RECURSIVE
    in line 5\. The orange circles represent strands corresponding to the part of
    the procedure that calls P-MAT-VEC-RECURSIVE in line 6 up to the **sync** in line
    7, where it suspends until the spawned subroutine in line 5 returns. The white
    circles represent strands corresponding to the (negligible) part of the procedure
    after the **sync** up to the point where it returns.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**图26.4** 计算 P-MAT-VEC-RECURSIVE (*A*, *x*, *y*, 8, 1, 8) 的跟踪。每个圆角矩形内的两个数字给出了调用过程（蓝色的生成或棕色的调用）中最后两个参数（过程头部中的
    *i* 和 *i*′）的值。蓝色圆圈代表过程到第 5 行中 P-MAT-VEC-RECURSIVE 生成的部分。橙色圆圈代表过程调用第 6 行中 P-MAT-VEC-RECURSIVE
    到第 7 行中 **sync** 的部分，直到生成的子例程在第 5 行返回。白色圆圈代表过程中 **sync** 后的（可忽略的）部分，直到返回点。'
- en: To reduce the overhead of recursive spawning, task-parallel platforms sometimes
    ***coarsen*** the leaves of the recursion by executing several iterations in a
    single leaf, either automatically or under programmer control. This optimization
    comes at the expense of reducing the parallelism. If the computation has sufficient
    parallel slackness, however, near-perfect linear speedup won’t be sacrificed.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少递归生成的开销，任务并行平台有时会通过在单个叶子节点中执行多个迭代来***粗化***递归的叶子，这可能是自动的，也可能由程序员控制。这种优化是以减少并行性为代价的。然而，如果计算具有足够的并行松弛度，几乎完美的线性加速不会被牺牲。
- en: Although recursive spawning doesn’t affect the work of a parallel loop asymptotically,
    we must take it into account when analyzing the span. Consider a parallel loop
    with *n* iterations in which the *i*th iteration has span *iter*[∞](*i*). Since
    the depth of recursion is logarithmic in the number of iterations, the parallel
    loop’s span is
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管递归生成在渐近情况下不会影响���行循环的工作量，但在分析跨度时必须考虑它。考虑一个具有 *n* 次迭代的并行循环，其中第 *i* 次迭代的跨度为
    *iter*[∞](*i*)。由于递归深度对迭代次数的对数是对数级的，因此并行循环的跨度是
- en: '*T*[∞](*n*) = Θ(lg *n*) + max {*iter*[∞](*i*) : 1 ≤ *i* ≤ *n*}.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '*T*[∞](*n*) = Θ(lg *n*) + max {*iter*[∞](*i*) : 1 ≤ *i* ≤ *n*}.'
- en: For example, let’s compute the span of the doubly nested loops in lines 1–3
    of P-MAT-VEC. The span for the **parallel for** loop control is Θ(lg *n*). For
    each iteration of the outer parallel loop, the inner serial **for** loop contains
    *n* iterations of line 3\. Since each iteration takes constant time, the total
    span for the inner serial **for** loop is Θ(*n*), no matter which iteration of
    the outer **parallel for** loop it’s in. Thus, taking the maximum over all iterations
    of the outer loop and adding in the Θ(lg *n*) for loop control yields an overall
    span of *T*[∞]*n* = Θ(*n*) + Θ(lg *n*) = Θ(*n*) for the procedure. Since the work
    is Θ(*n*²), the parallelism is Θ(*n*²)/Θ(*n*) = Θ(*n*). (Exercise 26.1-7 asks
    you to provide an implementation with even more parallelism.)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们计算 P-MAT-VEC 的第 1-3 行中双重嵌套循环的跨度。**parallel for** 循环控制的跨度是 Θ(lg *n*)。对于外部并行循环的每次迭代，内部串行
    **for** 循环包含第 3 行的 *n* 次迭代。由于每次迭代都需要常数时间，无论它在外部 **parallel for** 循环的哪次迭代中，内部串行
    **for** 循环的总跨度都是 Θ(*n*)。因此，取外部循环的所有迭代中的最大值，并加上循环控制的 Θ(lg *n*)，得到过程的总跨度为 *T*[∞]*n*
    = Θ(*n*) + Θ(lg *n*) = Θ(*n*)。由于工作量是 Θ(*n*²)，并行性是 Θ(*n*²)/Θ(*n*) = Θ(*n*)。（练习
    26.1-7 要求您提供更多并行性的实现。）
- en: '**Race conditions**'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**竞争条件**'
- en: A parallel algorithm is ***deterministic*** if it always does the same thing
    on the same input, no matter how the instructions are scheduled on the multicore
    computer. It is ***nondeterministic*** if its behavior might vary from run to
    run when the input is the same. A parallel algorithm that is intended to be deterministic
    may nevertheless act nondeterministically, however, if it contains a difficult-to-diagnose
    bug called a “determinacy race.”
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果并行算法在多核计算机上调度指令时，无论如何都会在相同的输入上执行相同的操作，则该算法是***确定性***的。如果在相同输入时其行为可能会因运行而异，则该算法是***非确定性***的。即使旨在是确定性的并行算法也可能表现为非确定性，如果其中包含一个难以诊断的错误，称为“确定性竞争”。
- en: Famous race bugs include the Therac-25 radiation therapy machine, which killed
    three people and injured several others, and the Northeast Blackout of 2003, which
    left over 50 million people in the United States without power. These pernicious
    bugs are notoriously hard to find. You can run tests in the lab for days without
    a failure, only to discover that your software sporadically crashes in the field,
    sometimes with dire consequences.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 著名的竞争错误包括Therac-25放射治疗机，导致三人死亡和多人受伤，以及2003年的东北大停电，导致美国超过5000万人断电。这些有害的错误极其难以发现。您可以在实验室中运行测试数天而不出现故障，只能发现您的软件在现场偶尔崩溃，有时后果严重。
- en: A ***determinacy race*** occurs when two logically parallel instructions access
    the same memory location and at least one of the instructions modifies the value
    stored in the location. The toy procedure RACE-EXAMPLE on the following page illustrates
    a determinacy race. After initializing *x* to 0 in line 1, RACE-EXAMPLE creates
    two parallel strands, each of which increments *x* in line 3\. Although it might
    seem that a call of RACE-EXAMPLE should always print the value 2 (its serial projection
    certainly does), it could instead print the value 1\. Let’s see how this anomaly
    might occur.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个逻辑上并行的指令访问相同的内存位置，并且其中至少一个指令修改了该位置存储的值时，就会发生***确定性竞争***。下一页上的玩具过程RACE-EXAMPLE说明了确定性竞争。在第1行将*x*初始化为0后，RACE-EXAMPLE创建了两个并行线程，每个线程在第3行中递增*x*。尽管调用RACE-EXAMPLE似乎应始终打印值2（其串行投影肯定会这样做），但它可能会打印值1。让我们看看这种异常可能发生的情况。
- en: 'When a processor increments *x*, the operation is not indivisible, but is composed
    of a sequence of instructions:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理器递增*x*时，该操作并非不可分割，而是由一系列指令组成：
- en: '![art](images/Art_P835.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P835.jpg)'
- en: '**Figure 26.5** Illustration of the determinacy race in RACE-EXAMPLE. **(a)**
    A trace showing the dependencies among individual instructions. The processor
    registers are *r*[1] and *r*[2]. Instructions unrelated to the race, such as the
    implementation of loop control, are omitted. **(b)** An execution sequence that
    elicits the bug, showing the values of *x* in memory and registers *r*[1] and
    *r*[2] for each step in the execution sequence.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**图26.5** RACE-EXAMPLE中确定性竞争的示例。**(a)** 显示各个指令之间依赖关系的跟踪。处理器寄存器为*r*[1]和*r*[2]。省略了与竞争无关的指令，如循环控制的实现。**(b)**
    引发错误的执行序列，显示了执行序列中每个步骤中*x*在内存和寄存器*r*[1]和*r*[2]中的值。'
- en: RACE-EXAMPLE ( )
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: RACE-EXAMPLE ( )
- en: '| 1 | *x* = 0 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 1 | *x* = 0 |'
- en: '| 2 | **parallel for** *i* = 1 **to** 2 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **并行循环** *i* = 1 **到** 2 |'
- en: '| 3 | *x* = *x* + 1 | **//** determinacy race |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 3 | *x* = *x* + 1 | **//** 确定性竞争 |'
- en: '| 4 | print *x* |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 打印*x* |'
- en: Load *x* from memory into one of the processor’s registers.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从内存中加载*x*到处理器的一个寄存器中。
- en: Increment the value in the register.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 递增寄存器中的值。
- en: Store the value in the register back into *x* in memory.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将寄存器中的值存回内存中的*x*。
- en: '[Figure 26.5(a)](chapter026.xhtml#Fig_26-5) illustrates a trace representing
    the execution of RACE-EXAMPLE, with the strands broken down to individual instructions.
    Recall that since an ideal parallel computer supports sequential consistency,
    you can view the parallel execution of a parallel algorithm as an interleaving
    of instructions that respects the dependencies in the trace. Part (b) of the figure
    shows the values in an execution of the computation that elicits the anomaly.
    The value *x* is kept in memory, and *r*[1] and *r*[2] are processor registers.
    In step 1, one of the processors sets *x* to 0\. In steps 2 and 3, processor 1
    loads *x* from memory into its register *r*[1] and increments it, producing the
    value 1 in *r*[1]. At that point, processor 2 comes into the picture, executing
    instructions 4–6\. Processor 2 loads *x* from memory into register *r*[2]; increments
    it, producing the value 1 in *r*[2]; and then stores this value into *x*, setting
    *x* to 1\. Now, processor 1 resumes with step 7, storing the value 1 in *r*[1]
    into *x*, which leaves the value of *x* unchanged. Therefore, step 8 prints the
    value 1, rather than the value 2 that the serial projection would print.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[图26.5(a)](chapter026.xhtml#Fig_26-5)展示了代表RACE-EXAMPLE执行的跟踪，将各个指令分解为单独的指令。请记住，由于理想的并行计算机支持顺序一致性，您可以将并行算法的并行执行视为在跟踪中尊重依赖关系的指令交错执行。图中的(b)部分显示了引发异常计算的执行中的值。值*x*保留在内存中，*r*[1]和*r*[2]是处理器寄存器。在第1步中，其中一个处理器将*x*设置为0。在第2和第3步中，处理器1将*x*从内存加载到其寄存器*r*[1]中，并对其进行递增，将值1存储在*r*[1]中。此时，处理器2开始执行指令4-6。处理器2将*x*从内存加载到寄存器*r*[2]中；递增它，将值1存储在*r*[2]中；然后将此值存储到*x*中，将*x*设置为1。现在，处理器1在第7步中恢复，将*r*[1]中的值1存储到*x*中，这使*x*的值保持不变。因此，第8步打印值1，而不是串行投影将打印的值2。'
- en: Let’s recap what happened. By sequential consistency, the effect of the parallel
    execution is as if the executed instructions of the two processors are interleaved.
    If processor 1 executes all its instructions before processor 2, a trivial interleaving,
    the value 2 is printed. Conversely, if processor 2 executes all its instructions
    before processor 1, the value 2 is still printed. When the instructions of the
    two processors interleave nontrivially, however, it is possible, as in this example
    execution, that one of the updates to *x* is lost, resulting in the value 1 being
    printed.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下发生了什么。根据顺序一致性，并行执行的效果就好像两个处理器的执行指令交错。如果处理器1在处理器2之前执行所有指令，一个微不足道的交错，值为2被打印出来。相反，如果处理器2在处理器1之前执行所有指令，值2仍然被打印出来。然而，当两个处理器的指令交错得更复杂时，就像这个例子中的执行一样，*x*的更新之一可能会丢失，导致值1被打印出来。
- en: Of course, many executions do not elicit the bug. That’s the problem with determinacy
    races. Generally, most instruction orderings produce correct results, such as
    any where the instructions on the left branch execute before the instructions
    on the right branch, or vice versa. But some orderings generate improper results
    when the instructions interleave. Consequently, races can be extremely hard to
    test for. Your program may fail, but you may be unable to reliably reproduce the
    failure in subsequent tests, confounding your attempts to locate the bug in your
    code and fix it. Task-parallel programming environments often provide race-detection
    productivity tools to help you isolate race bugs.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，许多执行不会引发错误。这就是确定性竞争的问题所在。通常，大多数指令排序会产生正确的结果，比如左分支上的指令在右分支上的指令之前执行，反之亦然。但是，当指令交错时，有些排序会生成不正确的结果。因此，竞争可能非常难以测试。你的程序可能会失败，但你可能无法在后续测试中可靠地重现失败，使你难以定位代码中的错误并修复它。任务并行编程环境通常提供竞争检测工具，帮助你隔离竞争错误。
- en: Many parallel programs in the real world are intentionally nondeterministic.
    They contain determinacy races, but they mitigate the dangers of nondeterminism
    through the use of mutual-exclusion locks and other methods of synchronization.
    For our purposes, however, we’ll insist on an absence of determinacy races in
    the algorithms we develop. Nondeterministic programs are indeed interesting, but
    nondeterministic programming is a more advanced topic and unnecessary for a wide
    swath of interesting parallel algorithms.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界中许多并行程序是有意的非确定性的。它们包含确定性竞争，但通过使用互斥锁和其他同步方法来减轻非确定性的危险。然而，对于我们的目的，我们将坚持在我们开发的算法中没有确定性竞争。非确定性程序确实很有趣，但非确定性编程是一个更高级的主题，对于许多有趣的并行算法来说是不必要的。
- en: 'To ensure that algorithms are deterministic, any two strands that operate in
    parallel should be ***mutually noninterfering***: they only read, and do not modify,
    any memory locations accessed by both of them. Consequently, in a **parallel for**
    construct, such as the outer loop of P-MAT-VEC, we want all the iterations of
    the body, including any code an iteration executes in subroutines, to be mutually
    noninterfering. And between a **spawn** and its corresponding **sync**, we want
    the code executed by the spawned child and the code executed by the parent to
    be mutually noninterfering, once again including invoked subroutines.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保算法是确定性的，任何并行操作的两个线程应该是***相互不干扰的***：它们只读取，而不修改，它们都访问的任何内存位置。因此，在**并行循环**结构中，比如P-MAT-VEC的外部循环，我们希望循环体的��有迭代，包括迭代在子程序中执行的任何代码，都是相互不干扰的。在**spawn**和其对应的**sync**之间，我们希望由生成的子进程执行的代码和父进程执行的代码是相互不干扰的，再次包括调用的子程序。
- en: As an example of how easy it is to write code with unintentional races, the
    P-MAT-VEC-WRONG procedure on the next page is a faulty parallel implementation
    of matrix-vector multiplication that achieves a span of Θ(lg *n*) by parallelizing
    the inner **for** loop. This procedure is incorrect, unfortunately, due to determinacy
    races when updating *y*[*i*] in line 3, which executes in parallel for all *n*
    values of *j*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个写有意外竞争的代码的例子，下一页的P-MAT-VEC-WRONG过程是一个错误的矩阵-向量乘法的并行实现，通过并行化内部**for**循环实现Θ(lg
    *n*)的跨度。不幸的是，这个过程是不正确的，因为在第3行更新*y*[*i*]时存在确定性竞争，它并行执行所有*j*值的*n*。
- en: Index variables of **parallel for** loops, such as *i* in line 1 and *j* in
    line 2, do not cause races between iterations. Conceptually, each iteration of
    the loop creates an independent variable to hold the index of that iteration during
    that iteration’s execution of the loop body. Even if two parallel iterations both
    access the same index variable, they really are accessing different variable instances—hence
    different memory locations—and no race occurs.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行循环**循环的索引变量，比如第1行的*i*和第2行的*j*，不会导致迭代之间的竞争。从概念上讲，循环的每次迭代都会创建一个独立的变量来保存该迭代的索引，而在该迭代执行循环体时。即使两个并行迭代都访问相同的索引变量，它们实际上是在访问不同的变量实例——因此是不同的内存位置——并且不会发生竞争。'
- en: P-MAT-VEC-WRONG (*A*, *x*, *y*, *n*)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: P-MAT-VEC-WRONG (*A*, *x*, *y*, *n*)
- en: '| 1 | **parallel for** *i* = 1 **to** *n* |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **并行循环** *i* = 1 **到** *n* |'
- en: '| 2 | **parallel for** *j* = 1 **to** *n* |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **并行循环** *j* = 1 **到** *n* |'
- en: '| 3 | *y*[*i*] = *y*[*i*] + *a*[*ij*]*x*[*j*] | **//** determinacy race |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 3 | *y*[*i*] = *y*[*i*] + *a*[*ij*]*x*[*j*] | **//** 确定性竞争 |'
- en: A parallel algorithm with races can sometimes be deterministic. As an example,
    two parallel threads might store the same value into a shared variable, and it
    wouldn’t matter which stored the value first. For simplicity, however, we generally
    prefer code without determinacy races, even if the races are benign. And good
    parallel programmers frown on code with determinacy races that cause nondeterministic
    behavior, if deterministic code that performs comparably is an option.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 具有竞争的并行算法有时可能是确定性的。例如，两个并行线程可能将相同的值存储到共享变量中，而无论哪个线程先存储值都无关紧要。然而，为简单起见，我们通常更喜欢没有确定性竞争的代码，即使竞争是良性的。而且，良好的并行程序员会对导致非确定性行为的确定性竞争代码不满意，如果有可比较的确定性代码的话。
- en: But nondeterministic code does have its place. For example, you can’t implement
    a parallel hash table, a highly practical data structure, without writing code
    containing determinacy races. Much research has centered around how to extend
    the fork-join model to incorporate limited “structured” nondeterminism while avoiding
    the full measure of complications that arise when nondeterminism is completely
    unrestricted.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，非确定性代码确实有其存在的理由��例如，你无法实现并行哈希表，这是一种非常实用的数据结构，而不编写包含确定性竞争的代码。许多研究集中在如何扩展分叉-合并模型以包含有限的“结构化”非确定性，同时避免当非确定性完全无限制时出现的各种复杂性。
- en: '**A chess lesson**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**国际象棋课**'
- en: To illustrate the power of work/span analysis, this section closes with a true
    story that occurred during the development of one of the first world-class parallel
    chess-playing programs [[106](bibliography001.xhtml#endnote_106)] many years ago.
    The timings below have been simplified for exposition.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明工作/跨度分析的力量，本节将以许多年前开发的第一个世界级并行国际象棋程序之一[[106](bibliography001.xhtml#endnote_106)]发生的一个真实故事作为结尾。下面的时间已经被简化以便阐述。
- en: The chess program was developed and tested on a 32-processor computer, but it
    was designed to run on a supercomputer with 512 processors. Since the supercomputer
    availability was limited and expensive, the developers ran benchmarks on the small
    computer and extrapolated performance to the large computer.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 国际象棋程序是在一个32处理器计算机上开发和测试的，但它被设计为在一个拥有512个处理器的超级计算机上运行。由于超级计算机的可用性有限且昂贵，开发人员在小型计算机上运行基准测试，并将性能推广到大型计算机。
- en: At one point, the developers incorporated an optimization into the program that
    reduced its running time on an important benchmark on the small machine from *T*[32]
    = 65 seconds to ![art](images/Art_P835a.jpg) seconds. Yet, the developers used
    the work and span performance measures to conclude that the optimized version,
    which was faster on 32 processors, would actually be slower than the original
    version on the 512 processors of the large machine. As a result, they abandoned
    the “optimization.”
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 有一次，开发人员将一个优化引入程序，将其在小型机器上的重要基准测试的运行时间从*T*[32] = 65秒减少到![art](images/Art_P835a.jpg)秒。然而，开发人员使用工作和跨度性能指标得出结论，即在32个处理器上更快的优化版本实际上会比大型机器上的512个处理器上的原始版本更慢。因此，他们放弃了这个“优化”。
- en: Here is their work/span analysis. The original version of the program had work
    *T*[1] = 2048 seconds and span *T*[∞]= 1 second. Let’s treat inequality (26.4)
    on page 760 as the equation *T*[*P*] = *T*[1]/*P* + *T*[∞], which we can use as
    an approximation to the running time on *P* processors. Then indeed we have *T*[32]
    = 2048/32 + 1 = 65\. With the optimization, the work becomes *T*′[1] = 1024 seconds,
    and the span becomes *T*′[∞] = 8 seconds. Our approximation gives *T*′[32] = 1024/32
    + 8 = 40.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这是他们的工作/跨度分析。程序的原始版本的工作量为*T*[1] = 2048秒，跨度为*T*[∞]= 1秒。让我们将第760页上的不等式(26.4)视为方程*T*[*P*]
    = *T*[1]/*P* + *T*[∞]，我们可以将其用作在*P*处理器上的运行时间的近似值。然后，我们确实有*T*[32] = 2048/32 + 1
    = 65。通过优化，工作量变为*T*′[1] = 1024秒，跨度变为*T*′[∞] = 8秒。我们的近似值为*T*′[32] = 1024/32 + 8
    = 40。
- en: The relative speeds of the two versions switch when we estimate their running
    times on 512 processors, however. The first version has a running time of *T*[512]
    = 2048/512+1 = 5 seconds, and the second version runs in ![art](images/Art_P835b.jpg)
    seconds. The optimization that speeds up the program on 32 processors makes the
    program run for twice as long on 512 processors! The optimized version’s span
    of 8, which is not the dominant term in the running time on 32 processors, becomes
    the dominant term on 512 processors, nullifying the advantage from using more
    processors. The optimization does not scale up.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们在512个处理器上估算它们的运行时间时，这两个版本的相对速度会发生变化。第一个版本的运行时间为*T*[512] = 2048/512+1 =
    5秒，而第二个版本在![art](images/Art_P835b.jpg)秒内运行。在32个处理器上加速程序的优化使程序在512个处理器上运行时间加倍！优化版本的跨度为8，在32个处理器上的运行时间中不是主导项，但在512个处理器上成为主导项，抵消了使用更多处理器的优势。优化不能扩展。
- en: The moral of the story is that work/span analysis, and measurements of work
    and span, can be superior to measured running times alone in extrapolating an
    algorithm’s scalability.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 故事的寓意是，工作/跨度分析和工作和跨度的测量，可以比单纯测量运行时间更好地推断算法的可扩展性。
- en: '**Exercises**'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习**'
- en: '***26.1-1***'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-1***'
- en: What does a trace for the execution of a serial algorithm look like?
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 串行算法的执行跟踪是什么样的？
- en: '***26.1-2***'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-2***'
- en: Suppose that line 4 of P-FIB spawns P-FIB (*n* − 2), rather than calling it
    as is done in the pseudocode. How would the trace of P-FIB(4) in [Figure 26.2](chapter026.xhtml#Fig_26-2)
    change? What is the impact on the asymptotic work, span, and parallelism?
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 假设P-FIB的第4行生成P-FIB(*n* − 2)，而不是像伪代码中所做的那样调用它。P-FIB(4)在[图26.2](chapter026.xhtml#Fig_26-2)中的跟踪会如何改变？对渐近工作量、跨度和并行性有什么影响？
- en: '***26.1-3***'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-3***'
- en: Draw the trace that results from executing P-FIB(5). Assuming that each strand
    in the computation takes unit time, what are the work, span, and parallelism of
    the computation? Show how to schedule the trace on 3 processors using greedy scheduling
    by labeling each strand with the time step in which it is executed.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制执行P-FIB(5)所产生的跟踪。假设计算中的每个线程都需要单位时间，计算的工作量、跨度和并行性是多少？展示如何使用贪婪调度在3个处理器上安排跟踪，通过为每个线程标记执行的时间步骤。
- en: '***26.1-4***'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-4***'
- en: 'Prove that a greedy scheduler achieves the following time bound, which is slightly
    stronger than the bound proved in Theorem 26.1:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 证明贪婪调度器实现了以下时间界，这比定理26.1中证明的界稍微更强：
- en: '![art](images/Art_P836.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![art](images/Art_P836.jpg)'
- en: '***26.1-5***'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-5***'
- en: Construct a trace for which one execution by a greedy scheduler can take nearly
    twice the time of another execution by a greedy scheduler on the same number of
    processors. Describe how the two executions would proceed.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个跟踪，其中一个贪婪调度器的执行时间几乎是另一个贪婪调度器在相同数量的处理器上的执行时间的两倍。描述这两个执行将如何进行。
- en: '***26.1-6***'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-6***'
- en: Professor Karan measures her deterministic task-parallel algorithm on 4, 10,
    and 64 processors of an ideal parallel computer using a greedy scheduler. She
    claims that the three runs yielded *T*[4] = 80 seconds, *T*[10] = 42 seconds,
    and *T*[64] = 10 seconds. Argue that the professor is either lying or incompetent.
    (*Hint:* Use the work law (26.2), the span law (26.3), and inequality (26.5) from
    Exercise 26.1-4.)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Karan 教授在理想的并行计算机上使用贪婪调度器在 4、10 和 64 个处理器上测量她的确定性任务并行算法。她声称三次运行分别为 *T*[4] =
    80 秒，*T*[10] = 42 秒和 *T*[64] = 10 秒。证明教授要么在撒谎，要么不称职。(*提示:* 使用工作定律（26.2）、跨度定律（26.3）和
    Exercise 26.1-4 中的不等式（26.5）)
- en: '***26.1-7***'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-7***'
- en: Give a parallel algorithm to multiply an *n* × *n* matrix by an *n*-vector that
    achieves Θ(*n*²/lg *n*) parallelism while maintaining Θ(*n*²) work.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 给出一个并行算法，将一个 *n* × *n* 矩阵乘以一个 *n*-向量，实现 Θ(*n*²/lg *n*) 的并行性，同时保持 Θ(*n*²) 的工作量。
- en: '***26.1-8***'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-8***'
- en: Analyze the work, span, and parallelism of the procedure P-TRANSPOSE, which
    transposes an *n* × *n* matrix *A* in place.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 分析过程 P-TRANSPOSE 的工作量、跨度和并行性，该过程在原地转置一个 *n* × *n* 矩阵 *A*。
- en: P-TRANSPOSE (*A*, *n*)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: P-TRANSPOSE (*A*, *n*)
- en: '| 1 | **parallel for** *j* = 2 **to** *n* |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **并行 for** *j* = 2 **到** *n* |'
- en: '| 2 | **parallel for** *i* = 1 **to** *j* − 1 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **并行 for** *i* = 1 **到** *j* − 1 |'
- en: '| 3 | exchange *a*[*ij*] with *a*[*ji*] |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 交换 *a*[*ij*] 和 *a*[*ji*] |'
- en: '***26.1-9***'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-9***'
- en: Suppose that instead of a **parallel for** loop in line 2, the P-TRANSPOSE procedure
    in Exercise 26.1-8 had an ordinary **for** loop. Analyze the work, span, and parallelism
    of the resulting algorithm.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在第 2 行的 **并行 for** 循环中，Exercise 26.1-8 中的 P-TRANSPOSE 程序有一个普通的 **for** 循环。分析得到的算法的工作量、跨度和并行性。
- en: '***26.1-10***'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.1-10***'
- en: For what number of processors do the two versions of the chess program run equally
    fast, assuming that *T*[*P*] = *T*[1]/*P* + *T*[∞]?
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多少个处理器，两个版本的国际象棋程序运行速度相同，假设 *T*[*P*] = *T*[1]/*P* + *T*[∞]？
- en: '[**26.2    Parallel matrix multiplication**](toc.xhtml#Rh1-153)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[**26.2    并行矩阵乘法**](toc.xhtml#Rh1-153)'
- en: In this section, we’ll explore how to parallelize the three matrix-multiplication
    algorithms from [Sections 4.1](chapter004.xhtml#Sec_4.1) and [4.2](chapter004.xhtml#Sec_4.2).
    We’ll see that each algorithm can be parallelized in a straightforward fashion
    using either parallel loops or recursive spawning. We’ll analyze them using work/span
    analysis, and we’ll see that each parallel algorithm attains the same performance
    on one processor as its corresponding serial algorithm, while scaling up to large
    numbers of processors.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨如何并行化[第 4.1 节](chapter004.xhtml#Sec_4.1)和[第 4.2 节](chapter004.xhtml#Sec_4.2)中的三个矩阵乘法算法。我们将看到每个算法都可以使用并行循环或递归生成直接进行简单并行化。我们将使用工作/跨度分析对它们进行分析，并且我们将看到每个并行算法在一个处理器上达到与其对应的串行算法相同的性能，同时可以扩展到大量处理器。
- en: '**A parallel algorithm for matrix multiplication using parallel loops**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用并行循环进行矩阵乘法的并行算法**'
- en: The first algorithm we’ll study is P-MATRIX-MULTIPLY, which simply parallelizes
    the two outer loops in the procedure MATRIX-MULTIPLY on page 81.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究的第一个算法是 P-MATRIX-MULTIPLY，它简单地将页面 81 上的 MATRIX-MULTIPLY 过程中的两个外部循环并行化。
- en: P-MATRIX-MULTIPLY (*A*, *B*, *C*, *n*)
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: P-MATRIX-MULTIPLY (*A*, *B*, *C*, *n*)
- en: '| 1 | **parallel for** *i* = 1 **to** *n* | **//** compute entries in each
    of *n* rows |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **并行 for** *i* = 1 **到** *n* | **//** 计算每个 *n* 行中的条目 |'
- en: '| 2 | **parallel for** *j* = 1 **to** *n* | **//** compute *n* entries in row
    *i* |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **并行 for** *j* = 1 **到** *n* | **//** 计算第 *i* 行的 *n* 个条目 |'
- en: '| 3 | **for** *k* = 1 **to** *n* |  |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **for** *k* = 1 **到** *n* |  |'
- en: '| 4 | *c*[*ij*] = *c*[*ij*] + *a*[*ik*] · *b*[*kj*] | **//** add in another
    term of equation (4.1) |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 4 | *c*[*ij*] = *c*[*ij*] + *a*[*ik*] · *b*[*kj*] | **//** 添加方程式（4.1）的另一个项
    |'
- en: 'Let’s analyze P-MATRIX-MULTIPLY. Since the serial projection of the algorithm
    is just MATRIX-MULTIPLY, the work is the same as the running time of MATRIX-MULTIPLY:
    *T*[1](*n*) = Θ(*n*³). The span is *T*[∞](*n*) = Θ(*n*), because it follows a
    path down the tree of recursion for the **parallel for** loop starting in line
    1, then down the tree of recursion for the **parallel for** loop starting in line
    2, and then executes all *n* iterations of the ordinary **for** loop starting
    in line 3, resulting in a total span of Θ(lg *n*) + Θ(lg *n*) + Θ(*n*) = Θ(*n*).
    Thus the parallelism is Θ(*n*³)/Θ(*n*) = Θ(*n*²). (Exercise 26.2-3 asks you to
    parallelize the inner loop to obtain a parallelism of Θ(*n*³/lg *n*), which you
    cannot do straightforwardly using **parallel for**, because you would create races.)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析 P-MATRIX-MULTIPLY。由于算法的串行投影只是 MATRIX-MULTIPLY，因此工作量与 MATRIX-MULTIPLY 的运行时间相同：*T*[1](*n*)
    = Θ(*n*³)。跨度为 *T*[∞](*n*) = Θ(*n*)，因为它遵循从第 1 行开始的 **并行 for** 循环的递归树路径，然后遵循从第 2
    行开始的 **并行 for** 循环的递归树路径，然后执行从第 3 行开始的普通 **for** 循环的所有 *n* 次迭代，导致总跨度为 Θ(lg *n*)
    + Θ(lg *n*) + Θ(*n*) = Θ(*n*)。因此，并行性为 Θ(*n*³)/Θ(*n*) = Θ(*n*²)。（Exercise 26.2-3
    要求您并行化内部循环，以获得 Θ(*n*³/lg *n*) 的并行性，但您不能直接使用 **并行 for** 进行，因为这样会产生竞争。）
- en: '**A parallel divide-and-conquer algorithm for matrix multiplication**'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**用于矩阵乘法的并行分治算法**'
- en: '[Section 4.1](chapter004.xhtml#Sec_4.1) shows how to multiply *n* × *n* matrices
    serially in Θ(*n*³) time using a divide-and-conquer strategy. Let’s see how to
    parallelize that algorithm using recursive spawning instead of calls.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 4.1 节](chapter004.xhtml#Sec_4.1) 展示了如何使用分治策略在 Θ(*n*³) 时间内串行相乘 *n* × *n*
    矩阵。让我们看看如何使用递归生成来并行化该算法，而不是调用。'
- en: The serial MATRIX-MULTIPLY-RECURSIVE procedure on page 83 takes as input three
    *n* × *n* matrices *A*, *B*, and *C* and performs the matrix calculation *C* =
    *C* + *A* · *B* by recursively performing eight multiplications of *n*/2 × *n*/2
    submatrices of *A* and *B*. The P-MATRIX-MULTIPLY-RECURSIVE procedure on the following
    page implements the same divide-and-conquer strategy, but it uses spawning to
    perform the eight multiplications in parallel. To avoid determinacy races in updating
    the elements of *C*, it creates a temporary matrix *D* to store four of the submatrix
    products. At the end, it adds *C* and *D* together to produce the final result.
    (Problem 26-2 asks you to eliminate the temporary matrix *D* at the expense of
    some parallelism.)
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在第83页的串行MATRIX-MULTIPLY-RECURSIVE过程以三个*n*×*n*矩阵*A*、*B*和*C*作为输入，并通过递归执行矩阵计算*C*
    = *C* + *A* · *B*，通过递归执行*A*和*B*的*n*/2×*n*/2子矩阵的八次乘法。以下一页的P-MATRIX-MULTIPLY-RECURSIVE过程实现了相同的分治策略，但使用生成并行执行八次乘法。为了避免在更新*C*的元素时出现确定性竞争，它创建一个临时矩阵*D*来存储四个子矩阵乘积。最���，它将*C*和*D*相加以产生最终结果。（问题26-2要求您消除临时矩阵*D*，以牺牲一些并行性。）
- en: Lines 2–3 of P-MATRIX-MULTIPLY-RECURSIVE handle the base case of multiplying
    1 × 1 matrices. The remainder of the procedure deals with the recursive case.
    Line 4 allocates a temporary matrix *D*, and lines 5–7 zero it. Line 8 partitions
    each of the four matrices *A*, *B*, *C*, and *D* into *n*/2 × *n*/2 submatrices.
    (As with MATRIX-MULTIPLY-RECURSIVE on page 83, we’re glossing over the subtle
    issue of how to use index calculations to represent submatrix sections of a matrix.)
    The spawned recursive call in line 9 sets *C*[11] = *C*[11] + *A*[11] · *B*[11],
    so that *C*[11] accumulates the first of the two terms in equation (4.5) on page
    82\. Similarly, lines 10–12 cause each of *C*[12], *C*[21], and *C*[22] in parallel
    to accumulate the first of the two terms in equations (4.6)–(4.8), respectively.
    Line 13 sets the submatrix *D*[11] to the submatrix product *A*[12] · *B*[21],
    so that *D*[11] equals the second of the two terms in equation (4.5). Lines 14–16
    set each of *D*[12], *D*[21], and *D*[22] in parallel to the second of the two
    terms in equations (4.6)–(4.8), respectively. The **sync** statement in line 17
    ensures that all the spawned submatrix products in lines 9–16 have been computed,
    after which the doubly nested **parallel for** loops in lines 18–20 add the elements
    of *D* to the corresponding elements of *C*.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 第2-3行的P-MATRIX-MULTIPLY-RECURSIVE处理了将1×1矩阵相乘的基本情况。该过程的其余部分处理递归情况。第4行分配了一个临时矩阵*D*，第5-7行将其清零。第8行将四个矩阵*A*、*B*、*C*和*D*分成*n*/2×*n*/2的子矩阵。（与第83页的MATRIX-MULTIPLY-RECURSIVE一样，我们忽略了如何使用索引计算来表示矩阵的子矩阵部分的微妙问题。）第9行中的生成递归调用设置*C*[11]
    = *C*[11] + *A*[11] · *B*[11]，使得*C*[11]累积了第一个方程(4.5)第82页中的两项中的第一项。类似地，第10-12行并行地使*C*[12]、*C*[21]和*C*[22]分别累积方程(4.6)-(4.8)中的第一项。第13行将子矩阵*D*[11]设置为子矩阵乘积*A*[12]
    · *B*[21]，使得*D*[11]等于方程(4.5)中的第二项。第14-16行并行地将*D*[12]、*D*[21]和*D*[22]分别设置为方程(4.6)-(4.8)中的第二项。第17行中的**sync**语句确保在第9-16行生成的所有子矩阵乘积计算完毕后，第18-20行的嵌套**parallel
    for**循环将*D*的元素加到相应的*C*元素上。
- en: P-MATRIX-MULTIPLY-RECURSIVE (*A*, *B*, *C*, *n*)
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: P-MATRIX-MULTIPLY-RECURSIVE (*A*, *B*, *C*, *n*)
- en: '|   1 | **if** *n* == 1 | **//** just one element in each matrix? |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '|   1 | **if** *n* == 1 | **//** 每个矩阵只有一个元素？ |'
- en: '|   2 | *c*[11] = *c*[11] + *a*[11] · *b*[11] |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '|   2 | *c*[11] = *c*[11] + *a*[11] · *b*[11] |'
- en: '|   3 | **return** |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|   3 | **return** |'
- en: '|   4 | let *D* be a new *n* × *n* matrix | **//** temporary matrix |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|   4 | let *D* be a new *n* × *n* matrix | **//** 临时矩阵 |'
- en: '|   5 | **parallel for** *i* = 1 **to** *n* | **//** set *D* = 0 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|   5 | **parallel for** *i* = 1 **to** *n* | **//** 设置*D* = 0 |'
- en: '|   6 | **parallel for** *j* = 1 **to** *n* |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '|   6 | **parallel for** *j* = 1 **to** *n* |'
- en: '|   7 | *d*[*ij*] = 0 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '|   7 | *d*[*ij*] = 0 |'
- en: '|   8 | partition *A*, *B*, *C*, and *D* into *n*/2 × *n*/2 submatrices *A*[11],
    *A*[12], *A*[21], *A*[22]; *B*[11], *B*[12], *B*[21], *B*[22]; *C*[11], *C*[12],
    *C*[21], *C*[22]; and *D*[11], *D*[12], *D*[21], *D*[22]; respectively |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|   8 | 将*A*、*B*、*C*和*D*分成*n*/2×*n*/2的子矩阵*A*[11]、*A*[12]、*A*[21]、*A*[22]；*B*[11]、*B*[12]、*B*[21]、*B*[22]；*C*[11]、*C*[12]、*C*[21]、*C*[22]；以及*D*[11]、*D*[12]、*D*[21]、*D*[22]；分别
    |'
- en: '|   9 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[11], *B*[11], *C*[11], *n*/2)
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '|   9 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[11], *B*[11], *C*[11], *n*/2)
    |'
- en: '| 10 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[11], *B*[12], *C*[12], *n*/2)
    |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 10 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[11], *B*[12], *C*[12], *n*/2)
    |'
- en: '| 11 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[21], *B*[11], *C*[21], *n*/2)
    |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 11 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[21], *B*[11], *C*[21], *n*/2)
    |'
- en: '| 12 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[21], *B*[12], *C*[22], *n*/2)
    |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 12 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[21], *B*[12], *C*[22], *n*/2)
    |'
- en: '| 13 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[12], *B*[21], *D*[11], *n*/2)
    |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 13 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[12], *B*[21], *D*[11], *n*/2)
    |'
- en: '| 14 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[12], *B*[22], *D*[12], *n*/2)
    |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 14 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[12], *B*[22], *D*[12], *n*/2)
    |'
- en: '| 15 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[22], *B*[21], *D*[21], *n*/2)
    |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 15 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[22], *B*[21], *D*[21], *n*/2)
    |'
- en: '| 16 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[22], *B*[22], *D*[22], *n*/2)
    |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 16 | **spawn** P-MATRIX-MULTIPLY-RECURSIVE (*A*[22], *B*[22], *D*[22], *n*/2)
    |'
- en: '| 17 | **sync** | **//** wait for spawned submatrix products |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 17 | **sync** | **//** 等待生成的子矩阵乘积 |'
- en: '| 18 | **parallel for** *i* = 1 **to** *n* | **//** update *C* = *C* + D |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 18 | **parallel for** *i* = 1 **to** *n* | **//** 更新*C* = *C* + D |'
- en: '| 19 | **parallel for** *j* = 1 **to** *n* |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 19 | **parallel for** *j* = 1 **to** *n* |'
- en: '| 20 | *c*[*ij*] = *c*[*ij*] + *d*[*ij*] |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 20 | *c*[*ij*] = *c*[*ij*] + *d*[*ij*] |'
- en: Let’s analyze the P-MATRIX-MULTIPLY-RECURSIVE procedure. We start by analyzing
    the work *M*[1](*n*), echoing the serial running-time analysis of its progenitor
    MATRIX-MULTIPLY-RECURSIVE. The recursive case allocates and zeros the temporary
    matrix *D* in Θ(*n*²) time, partitions in Θ(1) time, performs eight recursive
    multiplications of *n*/2 × *n*/2 matrices, and finishes up with the Θ(*n*²) work
    from adding two *n*×*n* matrices. Thus the work outside the spawned recursive
    calls is Θ(*n*²), and the recurrence for the work *M*[1](*n*) becomes
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析P-MATRIX-MULTIPLY-RECURSIVE过程。我们首先分析工作*M*[1](*n*)，回声其前身MATRIX-MULTIPLY-RECURSIVE的串行运行时间分析。递归情况下，在Θ(*n*²)的时间内分配并将临时矩阵*D*清零，以Θ(1)的时间分区，执行*n*/2
    × *n*/2矩阵的八次递归乘法，最后从添加两个*n*×*n*矩阵中得到Θ(*n*²)的工作。因此，在生成的递归调用之外的工作是Θ(*n*²)，工作*M*[1](*n*)的递归变为
- en: '| *M*[1](*n*) | = | 8*M*[1](*n*/2) + Θ(*n*²) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| *M*[1](*n*) | = | 8*M*[1](*n*/2) + Θ(*n*²) |'
- en: '|  | = | Θ(*n*³) |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  | = | Θ(*n*³) |'
- en: by case 1 of the master theorem (Theorem 4.1). Not surprisingly, the work of
    this parallel algorithm is asymptotically the same as the running time of the
    procedure MATRIX-MULTIPLY on page 81, with its triply nested loops.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 通过主定理（定理4.1）的情况1。毫不奇怪，这个并行算法的工作量与第81页的MATRIX-MULTIPLY过程及其三重嵌套循环的运行时间渐进相同。
- en: Let’s determine the span *M*[∞](*n*) of P-MATRIX-MULTIPLY-RECURSIVE. Because
    the eight parallel recursive spawns all execute on matrices of the same size,
    the maximum span for any recursive spawn is just the span of a single one of them,
    or *M*[∞](*n*/2). The span for the doubly nested **parallel for** loops in lines
    5–7 is Θ(lg *n*) because each loop control adds Θ(lg *n*) to the constant span
    of line 7\. Similarly, the doubly nested **parallel for** loops in lines 18–20
    add another Θ(lg *n*). Matrix partitioning by index calculation has Θ(1) span,
    which is dominated by the Θ(lg *n*) span of the nested loops. We obtain the recurrence
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确定P-MATRIX-MULTIPLY-RECURSIVE的跨度*M*[∞](*n*)。因为八个并行递归生成都在相同大小的矩阵上执行，任何递归生成的最大跨度只是单个递归生成的跨度，或*M*[∞](*n*/2)。在第5-7行的双重嵌套**并行for**循环的跨度为Θ(lg
    *n*)，因为每个循环控制将Θ(lg *n*)添加到第7行的常数跨度中。类似地��第18-20行的双重嵌套**并行for**循环添加了另外一个Θ(lg *n*)。通过索引计算的矩阵分区具有Θ(1)的跨度，被嵌套循环的Θ(lg
    *n*)跨度所主导。我们得到递归关系
- en: '![art](images/Art_P837.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![art](images/Art_P837.jpg)'
- en: Since this recurrence falls under case 2 of the master theorem with *k* = 1,
    the solution is *M*[∞](*n*) = Θ(lg² *n*).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个递归属于主定理的情况2，其中*k* = 1，解决方案为*M*[∞](*n*) = Θ(lg² *n*)。
- en: The parallelism of P-MATRIX-MULTIPLY-RECURSIVE is *M*[1](*n*)/*M*[∞](*n*) =
    Θ(*n*³/lg²*n*), which is huge. (Problem 26-2 asks you to simplify this parallel
    algorithm at the expense of just a little less parallelism.)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: P-MATRIX-MULTIPLY-RECURSIVE的并行性为*M*[1](*n*)/*M*[∞](*n*) = Θ(*n*³/lg²*n*)，这是巨大的。（问题26-2要求您简化这个并行算法，以换取稍微少一点的并行性。）
- en: '**Parallelizing Strassen’s method**'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行化Strassen方法**'
- en: To parallelize Strassen’s algorithm, we can follow the same general outline
    as on pages 86–87, but use spawning. You may find it helpful to compare each step
    below with the corresponding step there. We’ll analyze costs as we go along to
    develop recurrences *T*[1](*n*) and *T*[∞](*n*) for the overall work and span,
    respectively.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 要并行化Strassen算法，我们可以按照第86-87页的相同一般概述，但使用生成。您可能会发现将下面的每个步骤与那里的相应步骤进行比较是有帮助的。我们将在进行分析时开发整体工作量和跨度的递归*T*[1](*n*)和*T*[∞](*n*)。
- en: If *n* = 1, the matrices each contain a single element. Perform a single scalar
    multiplication and a single scalar addition, and return. Otherwise, partition
    the input matrices *A* and *B* and output matrix *C* into *n*/2 × *n*/2 submatrices,
    as in equation (4.2) on page 82\. This step takes Θ(1) work and Θ(1) span by index
    calculation.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果*n* = 1，则每个矩阵都包含一个元素。执行单个标量乘法和单个标量加法，然后返回。否则，将输入矩阵*A*和*B*以及输出矩阵*C*分区为*n*/2
    × *n*/2子矩阵，如第82页的方程(4.2)所示。通过索引计算，此步骤需要Θ(1)的工作量和Θ(1)的跨度。
- en: Create *n*/2 × *n*/2 matrices *S*[1], *S*[2], … , *S*[10], each of which is
    the sum or difference of two submatrices from step 1\. Create and zero the entries
    of seven *n*/2×*n*/2 matrices *P*[1], *P*[2], … , *P*[7] to hold seven *n*/2×*n*/2
    matrix products. All 17 matrices can be created, and the *P*[*i*] initialized,
    with doubly nested **parallel for** loops using Θ(*n*²) work and Θ(lg *n*) span.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建*n*/2 × *n*/2矩阵*S*[1]、*S*[2]、…、*S*[10]，每个矩阵是步骤1中两个子矩阵的和或差。创建并清零七个*n*/2×*n*/2矩阵*P*[1]、*P*[2]、…、*P*[7]以容纳七个*n*/2×*n*/2矩阵乘积。所有17个矩阵都可以使用双重嵌套**并行for**循环创建，并初始化*P*[*i*]，工作量为Θ(*n*²)，跨度为Θ(lg
    *n*)。
- en: Using the submatrices from step 1 and the matrices *S*[1], *S*[2], … , *S*[10]
    created in step 2, recursively spawn computations of each of the seven *n*/2 ×
    *n*/2 matrix products *P*[1], *P*[2], … , *P*[7], taking 7*T*[1](*n*/2) work and
    *T*[∞](*n*/2) span.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用步骤1中的子矩阵和步骤2中创建的矩阵*S*[1]、*S*[2]、…、*S*[10]，递归生成每个七个*n*/2 × *n*/2矩阵乘积*P*[1]、*P*[2]、…、*P*[7]的计算，需要7*T*[1](*n*/2)的工作量和*T*[∞](*n*/2)的跨度。
- en: Update the four submatrices *C*[11], *C*[12], *C*[21], *C*[22] of the result
    matrix *C* by adding or subtracting various *P*[*i*] matrices. Using doubly nested
    **parallel for** loops, computing all four submatrices takes Θ(*n*²) work and
    Θ(lg *n*) span.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过添加或减去各种*P*[*i*]矩阵，更新结果矩阵*C*的四个子矩阵*C*[11]、*C*[12]、*C*[21]、*C*[22]。使用双重嵌套**并行for**循环，计算所有四个子矩阵需要Θ(*n*²)的工作量和Θ(lg
    *n*)的跨度。
- en: Let’s analyze this algorithm. Since the serial projection is the same as the
    original serial algorithm, the work is just the running time of the serial projection,
    namely, Θ(*n*^(lg 7)). As we did with P-MATRIX-MULTIPLY-RECURSIVE, we can devise
    a recurrence for the span. In this case, seven recursive calls execute in parallel,
    but since they all operate on matrices of the same size, we obtain the same recurrence
    (26.6) as we did for P-MATRIX-MULTIPLY-RECURSIVE, with solution Θ(lg² *n*). Thus
    the parallel version of Strassen’s method has parallelism Θ(*n*^(lg 7)/lg² *n*),
    which is large. Although the parallelism is slightly less than that of P-MATRIX-MULTIPLY-RECURSIVE,
    that’s just because the work is also less.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析这个算法。由于串行投影与原始串行算法相同，工作量只是串行投影的运行时间，即 Θ(*n*^(lg 7))。就像我们对 P-MATRIX-MULTIPLY-RECURSIVE
    所做的那样，我们可以为跨度设计一个递归。在这种情况下，七个递归调用并行执行，但由于它们都在相同大小的矩阵上操作，我们得到了与 P-MATRIX-MULTIPLY-RECURSIVE
    相同的递归（26.6），其解为 Θ(lg² *n*)。因此，Strassen 方法的并行版本具有并行性 Θ(*n*^(lg 7)/lg² *n*)，这是很大的。尽管并行性略低于
    P-MATRIX-MULTIPLY-RECURSIVE，但这只是因为工作量也较低。
- en: '**Exercises**'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习**'
- en: '***26.2-1***'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.2-1***'
- en: Draw the trace for computing P-MATRIX-MULTIPLY on 2 × 2 matrices, labeling how
    the vertices in your diagram correspond to strands in the execution of the algorithm.
    Assuming that each strand executes in unit time, analyze the work, span, and parallelism
    of this computation.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制计算 P-MATRIX-MULTIPLY 在 2 × 2 矩阵上的跟踪，标记你的图中的顶点如何对应算法执行中的线程。假设每个线程在单位时间内执行，分析这个计算的工作量、跨度和并行性。
- en: '***26.2-2***'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.2-2***'
- en: Repeat Exercise 26.2-1 for P-MATRIX-MULTIPLY-RECURSIVE.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 重复练习 26.2-1 对于 P-MATRIX-MULTIPLY-RECURSIVE。
- en: '***26.2-3***'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.2-3***'
- en: Give pseudocode for a parallel algorithm that multiplies two *n* × *n* matrices
    with work Θ(*n*³) but span only Θ(lg *n*). Analyze your algorithm.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 给出一个并行算法的伪代码，用 Θ(*n*³) 的工作量乘以两个 *n* × *n* 矩阵，但跨度仅为 Θ(lg *n*)。分析你的算法。
- en: '***26.2-4***'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.2-4***'
- en: Give pseudocode for an efficient parallel algorithm that multiplies a *p* ×
    *q* matrix by a *q* × *r* matrix. Your algorithm should be highly parallel even
    if any of *p*, *q*, and *r* equal 1\. Analyze your algorithm.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 给出一个高效的并行算法的伪代码，将一个 *p* × *q* 矩阵乘以一个 *q* × *r* 矩阵。即使 *p*、*q* 和 *r* 中的任何一个等于
    1，你的算法也应该是高度并行的。分析你的算法。
- en: '***26.2-5***'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.2-5***'
- en: Give pseudocode for an efficient parallel version of the Floyd-Warshall algorithm
    (see [Section 23.2](chapter023.xhtml#Sec_23.2)), which computes shortest paths
    between all pairs of vertices in an edge-weighted graph. Analyze your algorithm.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 给出 Floyd-Warshall 算法的高效并行版本的伪代码（参见[第 23.2 节](chapter023.xhtml#Sec_23.2)），该算法计算加权图中所有顶点对之间的最短路径。分析你的算法。
- en: '[**26.3    Parallel merge sort**](toc.xhtml#Rh1-154)'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '[**26.3    并行归并排序**](toc.xhtml#Rh1-154)'
- en: We first saw serial merge sort in [Section 2.3.1](chapter002.xhtml#Sec_2.3.1),
    and in [Section 2.3.2](chapter002.xhtml#Sec_2.3.2) we analyzed its running time
    and showed it to be Θ(*n* lg *n*). Because merge sort already uses the divide-and-conquer
    method, it seems like a terrific candidate for implementing using fork-join parallelism.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首次在[第 2.3.1 节](chapter002.xhtml#Sec_2.3.1)中看到了串行归并排序，在[第 2.3.2 节](chapter002.xhtml#Sec_2.3.2)中分析了其运行时间，并表明其为
    Θ(*n* lg *n*)。因为归并排序已经使用了分治方法，似乎是一个很好的候选者来使用 fork-join 并行性来实现。
- en: 'The procedure P-MERGE-SORT modifies merge sort to spawn the first recursive
    call. Like its serial counterpart MERGE-SORT on page 39, the P-MERGE-SORT procedure
    sorts the subarray *A*[*p* : *r*]. After the **sync** statement in line 8 ensures
    that the two recursive spawns in lines 5 and 7 have finished, P-MERGE-SORT calls
    the P-MERGE procedure, a parallel merging algorithm, which is on page 779, but
    you don’t need to bother looking at it right now.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 'P-MERGE-SORT 程序修改了归并排序以生成第一个递归调用。与其在第39页上的串行对应物 MERGE-SORT 一样，P-MERGE-SORT
    程序对子数组 *A*[*p* : *r*] 进行排序。在第8行的 **sync** 语句确保第5行和第7行的两个递归生成已经完成后，P-MERGE-SORT
    调用 P-MERGE 程序，一个并行合并算法，位于第779页，但你现在不需要去看它。'
- en: P-MERGE-SORT (*A*, *p*, *r*)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: P-MERGE-SORT (*A*, *p*, *r*)
- en: '|   1 | **if** *p* ≥ *r* | **//** zero or one element? |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '|   1 | **if** *p* ≥ *r* | **//** 零个或一个元素？ |'
- en: '|   2 | **return** |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '|   2 | **return** |'
- en: '|   3 | *q* = ⌊(*p* + *r*)/2⌋ | **//** midpoint of *A*[*p* : *r*] |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '|   3 | *q* = ⌊(*p* + *r*)/2⌋ | **//** *A*[*p* : *r*] 的中点 |'
- en: '|   4 | **//** Recursively sort *A*[*p* : *q*] in parallel. |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '|   4 | **//** 并行递归排序 *A*[*p* : *q*]。'
- en: '|   5 | **spawn** P-MERGE-SORT (*A*, *p*, *q*) |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '|   5 | **spawn** P-MERGE-SORT (*A*, *p*, *q*) |'
- en: '|   6 | **//** Recursively sort *A*[*q* + 1 : *r*] in parallel. |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '|   6 | **//** 并行递归排序 *A*[*q* + 1 : *r*]。'
- en: '|   7 | **spawn** P-MERGE-SORT (*A*, *q* + 1, *r*) |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '|   7 | **spawn** P-MERGE-SORT (*A*, *q* + 1, *r*) |'
- en: '|   8 | **sync** | **//** wait for spawns |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '|   8 | **sync** | **//** 等待生成完成 |'
- en: '|   9 | **//** Merge *A*[*p* : *q*] and *A*[*q* + 1 : *r*] into *A*[*p* : *r*].
    |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '|   9 | **//** 合并 *A*[*p* : *q*] 和 *A*[*q* + 1 : *r*] 到 *A*[*p* : *r*]。'
- en: '| 10 | P-MERGE (*A*, *p*, *q*, *r*) |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 10 | P-MERGE (*A*, *p*, *q*, *r*) |'
- en: First, let’s use work/span analysis to get some intuition for why we need a
    parallel merge procedure. After all, it may seem as though there should be plenty
    of parallelism just by parallelizing MERGE-SORT without worrying about parallelizing
    the merge. But what would happen if the call to P-MERGE in line 10 of P-MERGE-SORT
    were replaced by a call to the serial MERGE procedure on page 36? Let’s call the
    pseudocode so modified P-NAIVE-MERGE-SORT.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用工作/跨度分析来直观地理解为什么我们需要一个并行合并过程。毕竟，通过并行化MERGE-SORT而不担心并行化合并，可能会觉得应该有足够的并行性。但是，如果在P-MERGE-SORT的第10行中调用P-MERGE的调用被替换为第36页上的串行MERGE过程会发生什么？让我们称修改后的伪代码为P-NAIVE-MERGE-SORT。
- en: 'Let *T*[1](*n*) be the (worst-case) work of P-NAIVE-MERGE-SORT on an *n*-element
    subarray, where *n* = *r* −*p* + 1 is the number of elements in *A*[*p* : *r*],
    and let *T*[∞](*n*) be the span. Because MERGE is serial with running time Θ(*n*),
    both its work and span are Θ(*n*). Since the serial projection of P-NAIVE-MERGE-SORT
    is exactly MERGE-SORT, its work is *T*[1](*n*) = Θ(*n* lg *n*). The two recursive
    calls in lines 5 and 7 run in parallel, and so its span is given by the recurrence'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '让*T*[1](*n*)表示P-NAIVE-MERGE-SORT在一个*n*元素子数组上的（最坏情况）工作量，其中*n* = *r* −*p* + 1是*A*[*p*
    : *r*]中元素的数量，并且让*T*[∞](*n*)表示跨度。因为MERGE是串行的，运行时间为Θ(*n*)，它的工作量和跨度都是Θ(*n*)。由于P-NAIVE-MERGE-SORT的串行投影恰好是MERGE-SORT，其工作量为*T*[1](*n*)
    = Θ(*n* lg *n*)。第5行和第7行中的两个递归调用并行运行，因此其跨度由递归给出'
- en: '| *T*[∞](*n*) | = | *T*[∞](*n*/2) + Θ(*n*) |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| *T*[∞](*n*) | = | *T*[∞](*n*/2) + Θ(*n*) |'
- en: '|  | = | Θ(*n*), |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '|  | = | Θ(*n*), |'
- en: by case 1 of the master theorem. Thus the parallelism of P-NAIVE-MERGE-SORT
    is *T*[1](*n*)/*T*[∞](*n*) = Θ(lg *n*), which is an unimpressive amount of parallelism.
    To sort a million elements, for example, since lg 10⁶ ≈ 20, it might achieve linear
    speedup on a few processors, but it would not scale up to dozens of processors.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 主定理的第1种情况。因此，P-NAIVE-MERGE-SORT的并行性为*T*[1](*n*)/*T*[∞](*n*) = Θ(lg *n*)，这是一种令人印象深刻的并行性。例如，要对一百万个元素进行排序，因为lg
    10⁶ ≈ 20，它可能在少数处理器上实现线性加速，但不会扩展到几十个处理器。
- en: The parallelism bottleneck in P-NAIVE-MERGE-SORT is plainly the MERGE procedure.
    If we asymptotically reduce the span of merging, the master theorem dictates that
    the span of parallel merge sort will also get smaller. When you look at the pseudocode
    for MERGE, it may seem that merging is inherently serial, but it’s not. We can
    fashion a parallel merging algorithm. The goal is to reduce the span of parallel
    merging asymptotically, but if we want an efficient parallel algorithm, we must
    ensure that the Θ(*n*) bound on work doesn’t increase.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: P-NAIVE-MERGE-SORT中的并行瓶颈显然是MERGE过程。如果我们在渐近意义上减少合并的跨度，主定理规定并行归并排序的跨度也会变小。当你看MERGE的伪代码时，可能会觉得合并本质上是串行的，但事实并非如此。我们可以设计一个并行合并算法。目标是在渐近意义上减少并行合并的跨度，但如果我们想要一个高效的并行算法，就必须确保工作量的Θ(*n*)上限不增加。
- en: '[Figure 26.6](chapter026.xhtml#Fig_26-6) depicts the divide-and-conquer strategy
    that we’ll use in P-MERGE. The heart of the algorithm is a recursive auxiliary
    procedure P-MERGE-AUX that merges two sorted subarrays of an array *A* into a
    subarray of another array *B* in parallel. Specifically, P-MERGE-AUX merges *A*[*p*[1]
    : *r*[1]] and *A*[*p*[2] : *r*[2]] into subarray *B*[*p*[3] : *r*[3]], where *r*[3]
    = *p*[3] + (*r*[1] − *p*[1] + 1) + (*r*[2] − *p*[2] + 1) − 1 = *p*[3] + (*r*[1]
    − *p*[1]) + (*r*[2] − *p*[2]) + 1.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '[图26.6](chapter026.xhtml#Fig_26-6) 描绘了我们在P-MERGE中将使用的分治策略。算法的核心是一个递归辅助过程P-MERGE-AUX，它并行地将数组*A*的两个排序子数组合并到另一个数组*B*的子数组中。具体来说，P-MERGE-AUX将*A*[*p*[1]
    : *r*[1]]和*A*[*p*[2] : *r*[2]]合并到子数组*B*[*p*[3] : *r*[3]]中，其中*r*[3] = *p*[3] +
    (*r*[1] − *p*[1] + 1) + (*r*[2] − *p*[2] + 1) − 1 = *p*[3] + (*r*[1] − *p*[1])
    + (*r*[2] − *p*[2]) + 1。'
- en: 'The key idea of the recursive merging algorithm in P-MERGE-AUX is to split
    each of the two sorted subarrays of *A* around a pivot *x*, such that all the
    elements in the lower part of each subarray are at most *x* and all the elements
    in the upper part of each subarray are at least *x*. The procedure can then recurse
    in parallel on two subtasks: merging the two lower parts, and merging the two
    upper parts. The trick is to find a pivot *x* so that the recursion is not too
    lopsided. We don’t want a situation such as that in QUICKSORT on page 183, where
    bad partitioning elements lead to a dramatic loss of asymptotic efficiency. We
    could opt to partition around a random element, as RANDOMIZED-QUICKSORT on page
    192 does, but because the input subarrays are sorted, P-MERGE-AUX can quickly
    determine a pivot that always works well.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: P-MERGE-AUX中递归合并算法的关键思想是围绕一个枢轴*x*分割*A*的两个排序子数组，使得每个子数组的较低部分的所有元素最多为*x*，而较高部分的所有元素至少为*x*。然后该过程可以并行递归处理两个子任务：合并两个较低部分和合并两个较高部分。关键是找到一个枢轴*x*，使得递归不会过于倾斜。我们不希望出现类似于第183页QUICKSORT中的情况，其中糟糕的分区元素导致渐近效率的显著损失。我们可以选择围绕一个随机元素进行分区，就像第192页的RANDOMIZED-QUICKSORT那样，但由于输入子数组已经排序，P-MERGE-AUX可以快速确定一个始终有效的枢轴。
- en: 'Specifically, the recursive merging algorithm picks the pivot *x* as the middle
    element of the larger of the two input subarrays, which we can assume without
    loss of generality is *A*[*p*[1] : *r*[1]], since otherwise, the two subarrays
    can just switch roles. That is, *x* = *A*[*q*[1]], where *q*[1] = ⌊(*p*[1] + *r*[1])/2⌋.
    Because *A*[*p*[1] : *r*[1]] is sorted, *x* is a median of the subarray elements:
    every element in *A*[*p*[1] : *q*[1] − 1] is no more than *x*, and every element
    in *A*[*q*[1] + 1 : *r*[1]] is no less than *x*. Then the algorithm finds the
    “split point” *q*[2] in the smaller subarray *A*[*p*[2] : *r*[2]] such that all
    the elements in *A*[*p*[2] : *q*[2]−1] (if any) are at most *x* and all the elements
    in *A*[*q*[2] : *r*[2]] (if any) are at least *x*. Intuitively, the subarray *A*[*p*[2]
    : *r*[2]] would still be sorted if *x* were inserted between *A*[*q*[2]−1] and
    *A*[*q*[2]] (although the algorithm doesn’t do that). Since *A*[*p*[2] : *r*[2]]
    is sorted, a minor variant of binary search (see Exercise 2.3-6) with *x* as the
    search key can find the split point *q*[2] in Θ(lg *n*) time in the worst case.
    As we’ll see when we get to the analysis, even if *x* splits *A*[*p*[2] : *r*[2]]
    badly—*x* is either smaller than all the subarray elements or larger—we’ll still
    have at least 1/4 of the elements in each of the two recursive merges. Thus the
    larger of the recursive merges operates on at most 3/4 elements, and the recursion
    is guaranteed to bottom out after Θ(lg *n*) recursive calls.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '具体来说，递归合并算法选择枢轴 *x* 作为两个输入子数组中较大的中间元素，我们可以假设这个子数组是 *A*[*p*[1] : *r*[1]]，否则，这两个子数组可以交换角色。也就是说，*x*
    = *A*[*q*[1]]，其中 *q*[1] = ⌊(*p*[1] + *r*[1])/2⌋。因为 *A*[*p*[1] : *r*[1]] 是有序的，*x*
    是子数组元素的中位数：*A*[*p*[1] : *q*[1] − 1] 中的每个元素都不超过 *x*，而 *A*[*q*[1] + 1 : *r*[1]]
    中的每个元素都不少于 *x*。然后算法在较小的子数组 *A*[*p*[2] : *r*[2]] 中找到“分割点” *q*[2]，使得 *A*[*p*[2]
    : *q*[2]−1]（如果有的话）中的所有元素至多为 *x*，而 *A*[*q*[2] : *r*[2]]（如果有的话）中的所有元素至少为 *x*。直观地说，如果在
    *A*[*q*[2]−1] 和 *A*[*q*[2]] 之间插入 *x*，子数组 *A*[*p*[2] : *r*[2]] 仍然是有序的（尽管算法并没有这样做）。由于
    *A*[*p*[2] : *r*[2]] 是有序的，带有 *x* 作为搜索关键字的二分搜索的一个小变种（参见练习 2.3-6）可以在最坏情况下在 Θ(lg
    *n*) 时间内找到分割点 *q*[2]。当我们进行分析时，即使 *x* 将 *A*[*p*[2] : *r*[2]] 分割得很糟糕——*x* 要么比所有子数组元素都小，要么比所有子数组元素都大——我们仍然至少有两个递归合并中每个的
    1/4 元素。因此，较大的递归合并在最多 3/4 元素上操作，并且递归保证在 Θ(lg *n*) 递归调用后结束。'
- en: '![art](images/Art_P838.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P838.jpg)'
- en: '**Figure 26.6** The idea behind P-MERGE-AUX, which merges two sorted subarrays
    *A*[*p*[1] : *r*[1]] and *A*[*p*[2] : *r*[2]] into the subarray *B*[*p*[3] : *r*[3]]
    in parallel. Letting *x* = *A*[*q*[1]] (shown in yellow) be a median of *A*[*p*[1]
    : *r*[1]] and *q*[2] be a place in *A*[*p*[2] : *r*[2]] such that *x* would fall
    between *A*[*q*[2] − 1] and *A*[*q*[2]], every element in the subarrays *A*[*p*[1]
    : *q*[1] − 1] and *A*[*p*[2] : *q*[2] − 1] (shown in orange) is at most *x*, and
    every element in the subarrays *A*[*q*[1] + 1 : *r*[1]] and *A*[*q*[2] + 1 : *r*[2]]
    (shown in blue) is at least *x*. To merge, compute the index *q*[3] where *x*
    belongs in *B*[*p*[3] : *r*[3]], copy *x* into *B*[*q*[3]], and then recursively
    merge *A*[*p*[1] : *q*[1] − 1] with *A*[*p*[2] : *q*[2] − 1] into *B*[*p*[3] :
    *q*[3] − 1] and *A*[*q*[1] + 1 : *r*[1]] with *A*[*q*[2] : *r*[2]] into *B*[*q*[3]
    + 1 : *r*[3]].'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 26.6** P-MERGE-AUX 背后的思想，将两个有序子数组 *A*[*p*[1] : *r*[1]] 和 *A*[*p*[2] : *r*[2]]
    并行合并为子数组 *B*[*p*[3] : *r*[3]]。令 *x* = *A*[*q*[1]]（显示为黄色）为 *A*[*p*[1] : *r*[1]]
    的中位数，*q*[2] 是 *A*[*p*[2] : *r*[2]] 中的一个位置，使得 *x* 会落在 *A*[*q*[2] − 1] 和 *A*[*q*[2]]
    之间，子数组 *A*[*p*[1] : *q*[1] − 1] 和 *A*[*p*[2] : *q*[2] − 1]（显示为橙色）中的每个元素至多为 *x*，而子数组
    *A*[*q*[1] + 1 : *r*[1]] 和 *A*[*q*[2] + 1 : *r*[2]]（显示为蓝色）中的每个元素至少为 *x*。为了合并，计算
    *x* 在 *B*[*p*[3] : *r*[3]] 中的位置 *q*[3]，将 *x* 复制到 *B*[*q*[3]]，然后递归地将 *A*[*p*[1]
    : *q*[1] − 1] 和 *A*[*p*[2] : *q*[2] − 1] 合并到 *B*[*p*[3] : *q*[3] − 1]，将 *A*[*q*[1]
    + 1 : *r*[1]] 和 *A*[*q*[2] : *r*[2]] 合并到 *B*[*q*[3] + 1 : *r*[3]]。'
- en: 'Now let’s put these ideas into pseudocode. We start with the serial procedure
    FIND-SPLIT-POINT (*A*, *p*, *r*, *x*) on the next page, which takes as input a
    sorted subarray *A*[*p* : *r*] and a key *x*. The procedure returns a split point
    of *A*[*p* : *r*]: an index *q* in the range *p* ≤ *q* ≤ *r* + 1 such that all
    the elements in *A*[*p* : *q* − 1] (if any) are at most *x* and all the elements
    in *A*[*q* : *r*] (if any) are at least *x*.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '现在让我们将这些想法转化为伪代码。我们从下一页开始，使用串行过程 FIND-SPLIT-POINT (*A*, *p*, *r*, *x*)，该过程接受一个有序子数组
    *A*[*p* : *r*] 和一个关键字 *x* 作为输入。该过程返回 *A*[*p* : *r*] 的一个分割点：一个索引 *q*，满足 *p* ≤ *q*
    ≤ *r* + 1，使得 *A*[*p* : *q* − 1]（如果有的话）中的所有元素至多为 *x*，而 *A*[*q* : *r*]（如果有的话）中的所有元素至少为
    *x*。'
- en: The FIND-SPLIT-POINT procedure uses binary search to find the split point. Lines
    1 and 2 establish the range of indices for the search. Each time through the **while**
    loop, line 5 compares the middle element of the range with the search key *x*,
    and lines 6 and 7 narrow the search range to either the lower half or the upper
    half of the subarray, depending on the result of the test. In the end, after the
    range has been narrowed to a single index, line 8 returns that index as the split
    point.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: FIND-SPLIT-POINT 过程使用二分搜索找到分割点。第 1 和第 2 行确定了搜索的索引范围。每次通过**while**循环，第 5 行将范围的中间元素与搜索关键字
    *x* 进行比较，第 6 和第 7 行根据测试结果将搜索范围缩小到子数组的下半部分或上半部分。最终，在范围被缩小到单个索引后，第 8 行将该索引作为分割点返回。
- en: FIND-SPLIT-POINT (*A*, *p*, *r*, *x*)
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: FIND-SPLIT-POINT (*A*, *p*, *r*, *x*)
- en: '| 1 | *low* = *p* | **//** low end of search range |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 1 | *low* = *p* | **//** 搜索范围的低端 |'
- en: '| 2 | *high* = *r* + 1 | **//** high end of search range |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *high* = *r* + 1 | **//** 搜索范围的高端 |'
- en: '| 3 | **while** *low* < *high* | **//** more than one element? |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **当** *low* < *high* **时** | **//** 多于一个元素？ |'
- en: '| 4 | *mid* = ⌊(*low* + *high*)/2⌋ | **//** midpoint of range |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 4 | *mid* = ⌊(*low* + *high*)/2⌋ | **//** 范围的中点 |'
- en: '| 5 | **if** *x* ≤ *A*[*mid*] | **//** is answer *q* ≤ *mid*? |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 5 | **如果** *x* ≤ *A*[*mid*] | **//** 答案 *q* ≤ *mid* 吗？ |'
- en: '| 6 | *high* = *mid* | **//** narrow search to *A*[*low* : *mid*] |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 6 | *high* = *mid* | **//** 缩小搜索范围至 *A*[*low* : *mid*] |'
- en: '| 7 | **else** *low* = *mid* + 1 | **//** narrow search to *A*[*mid* + 1 :
    *high*] |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 7 | **否则** *low* = *mid* + 1 | **//** 缩小搜索范围至 *A*[*mid* + 1 : *high*] |'
- en: '| 8 | **return** *low* |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 8 | **返回** *low* |'
- en: 'Because FIND-SPLIT-POINT contains no parallelism, its span is just its serial
    running time, which is also its work. On a subarray *A*[*p* : *r*] of size *n*
    = *r* − *p* + 1, each iteration of the **while** loop halves the search range,
    which means that the loop terminates after Θ(lg *n*) iterations. Since each iteration
    takes constant time, the algorithm runs in Θ(lg *n*) (worst-case) time. Thus the
    procedure has work and span Θ(lg *n*).'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '由于FIND-SPLIT-POINT不包含并行性，其跨度仅为其串行运行时间，这也是其工作量。在大小为*n* = *r* − *p* + 1的子数组*A*[*p*
    : *r*]上，**while**循环的每次迭代将搜索范围减半，这意味着循环在Θ(lg *n*)次迭代后终止。由于每次迭代都需要恒定时间，该算法的运行时间为Θ(lg
    *n*)（最坏情况）。因此，该过程的工作量和跨度为Θ(lg *n*)。'
- en: 'Let’s now look at the pseudocode for the parallel merging procedure P-MERGE
    on the next page. Most of the pseudocode is devoted to the recursive procedure
    P-MERGE-AUX. The procedure P-MERGE itself is just a “wrapper” that sets up for
    P-MERGE-AUX. It allocates a new array *B*[*p* : *r*] to hold the output of P-MERGE-AUX
    in line 1\. It then calls P-MERGE-AUX in line 2, passing the indices of the two
    subarrays to be merged and providing *B* as the output destination of the merged
    result, starting at index *p*. After P-MERGE-AUX returns, lines 3–4 perform a
    parallel copy of the output *B*[*p* : *r*] into the subarray *A*[*p* : *r*], which
    is where P-MERGE-SORT expects it.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '现在让我们看一下下一页上并行合并过程P-MERGE的伪代码。大部分伪代码都专注于递归过程P-MERGE-AUX。过程P-MERGE本身只是一个“包装器”，用于设置P-MERGE-AUX。它在第1行为P-MERGE-AUX分配一个新数组*B*[*p*
    : *r*]来保存合并结果的输出。然后在第2行调用P-MERGE-AUX，传递要合并的两个子数组的索引，并将*B*作为合并结果的输出目标，从索引*p*开始。在P-MERGE-AUX返回后，第3-4行执行将输出*B*[*p*
    : *r*]并行复制到子数组*A*[*p* : *r*]中，这是P-MERGE-SORT期望的位置。'
- en: 'The P-MERGE-AUX procedure is the interesting part of the algorithm. Let’s start
    by understanding the parameters of this recursive parallel procedure. The input
    array *A* and the four indices *p*[1], *r*[1], *p*[2], *r*[2] specify the subarrays
    *A*[*p*[1] : *r*[1]] and *A*[*p*[2] : *r*[2]] to be merged. The array *B* and
    the index *p*[3] indicate that the merged result should be stored into *B*[*p*[3]
    : *r*[3]], where *r*[3] = *p*[3] + (*r*[1] − *p*[1])+ (*r*[2] − *p*[2])+ 1, as
    we saw earlier. The end index *r*[3] of the output subarray is not needed by the
    pseudocode, but it helps conceptually to name the end index, as in the comment
    in line 13.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '算法中有趣的部分是P-MERGE-AUX过程。让我们从理解这个递归并行过程的参数开始。输入数组*A*和四个索引*p*[1]、*r*[1]、*p*[2]、*r*[2]指定要合并的子数组*A*[*p*[1]
    : *r*[1]]和*A*[*p*[2] : *r*[2]]。数组*B*和索引*p*[3]指示合并结果应存储在*B*[*p*[3] : *r*[3]]中，其中*r*[3]
    = *p*[3] + (*r*[1] − *p*[1])+ (*r*[2] − *p*[2])+ 1，正如我们之前看到的。输出子数组的结束索引*r*[3]在伪代码中不需要，但在第13行的注释中有助于概念上命名结束索引。'
- en: The procedure begins by checking the base case of the recursion and doing some
    bookkeeping to simplify the rest of the pseudocode. Lines 1 and 2 test whether
    the two subarrays are both empty, in which case the procedure returns. Line 3
    checks whether the first subarray contains fewer elements than the second subarray.
    Since the number of elements in the first subarray is *r*[1] − *p*[1] + 1 and
    the number in the second subarray is *r*[2] − *p*[2] + 1, the test omits the two
    “+1’s.” If the first subarray is the smaller of the two, lines 4 and 5 switch
    the roles of the subarrays so that *A*[*p*[1], *r*[1]] refers to the larger subarray
    for the balance of the procedure.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 过程从递归的基本情况开始检查，并进行一些簿记以简化伪代码的其余部分。第1和第2行测试两个子数组是否都为空，如果是，则���程返回。第3行检查第一个子数组是否包含的元素少于第二个子数组。由于第一个子数组中的元素数量为*r*[1]
    − *p*[1] + 1，第二个子数组中的元素数量为*r*[2] − *p*[2] + 1，测试省略了两个“+1”。如果第一个子数组是两者中较小的，则第4和第5行交换子数组的角色，以便在过程的余下部分中*A*[*p*[1],
    *r*[1]]指的是较大的子数组。
- en: P-MERGE (*A*, *p*, *q*, *r*)
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: P-MERGE (*A*, *p*, *q*, *r*)
- en: '|   1 | let *B*[*p* : *r*] be a new array | **//** allocate scratch array |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '|   1 | 让*B*[*p* : *r*]成为一个新数组 | **//** 分配临时数组 |'
- en: '|   2 | P-MERGE-AUX (*A*, *p*, *q*, *q* + 1, *r*, *B*, *p*) | **//** merge
    from *A* into *B* |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '|   2 | P-MERGE-AUX (*A*, *p*, *q*, *q* + 1, *r*, *B*, *p*) | **//** 从*A*合并到*B*
    |'
- en: '|   3 | **parallel for** *i* = *p* **to** *r* | **//** copy *B* back to *A*
    in parallel |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '|   3 | **parallel for** *i* = *p* **to** *r* | **//** 并行将*B*复制回*A* |'
- en: '|   4 | *A*[*i*] = *B*[*i*] |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '|   4 | *A*[*i*] = *B*[*i*] |'
- en: '| P-MERGE-AUX (*A*, *p*[1], *r*[1], *p*[2], *r*[2], *B*, *p*[3]) |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| P-MERGE-AUX (*A*, *p*[1], *r*[1], *p*[2], *r*[2], *B*, *p*[3]) |'
- en: '|   1 | **if** *p*[1] > *r*[1] and *p*[2] > *r*[2] | **//** are both subarrays
    empty? |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '|   1 | **if** *p*[1] > *r*[1] and *p*[2] > *r*[2] | **//** 两个子数组都为空吗？ |'
- en: '|   2 | **return** |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '|   2 | **return** |'
- en: '|   3 | **if** *r*[1] − *p*[1] < *r*[2] − *p*[2] | **//** second subarray bigger?
    |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '|   3 | **if** *r*[1] − *p*[1] < *r*[2] − *p*[2] | **//** 第二个子数组更大？ |'
- en: '|   4 | exchange *p*[1] with *p*[2] | **//** swap subarray roles |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '|   4 | 交换*p*[1]和*p*[2] | **//** 交换子数组角色 |'
- en: '|   5 | exchange *r*[1] with *r*[2] |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '|   5 | 交换*r*[1]和*r*[2] |'
- en: '|   6 | *q*[1] = ⌊(*p*[1] + *r*[1])/2⌋ | **//** midpoint of *A*[*p*[1] : *r*[1]]
    |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '|   6 | *q*[1] = ⌊(*p*[1] + *r*[1])/2⌋ | **//** *A*[*p*[1] : *r*[1]]的中点 |'
- en: '|   7 | *x* = *A*[*q*[1]] | **//** median of *A*[*p*[1] : *r*[1]] is pivot
    *x* |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '|   7 | *x* = *A*[*q*[1]] | **//** *A*[*p*[1] : *r*[1]]的中位数是枢轴*x* |'
- en: '|   8 | *q*[2] = FIND-SPLIT-POINT (*A*, *p*[2], *r*[2], *x*) | **//** split
    *A*[*p*[2] : *r*[2]] around *x* |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '|   8 | *q*[2] = FIND-SPLIT-POINT (*A*, *p*[2], *r*[2], *x*) | **//** 围绕*x*分割*A*[*p*[2]
    : *r*[2]] |'
- en: '|   9 | *q*[3] = *p*[3] + (*q*[1] − *p*[1]) + (*q*[2] − *p*[2]) | **//** where
    *x* belongs in *B* … |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '|   9 | *q*[3] = *p*[3] + (*q*[1] − *p*[1]) + (*q*[2] − *p*[2]) | **//** *x*在*B*中的位置…
    |'
- en: '| 10 | *B*[*q*[3]] = *x* | **//** … put it there |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 10 | *B*[*q*[3]] = *x* | **//** …将其放在那里 |'
- en: '| 11 | **//** Recursively merge *A*[*p*[1] : *q*[1] − 1] and *A*[*p*[2] : *q*[2]
    − 1] into *B*[*p*[3] : *q*[3] − 1]. |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 11 | **//** 递归地将*A*[*p*[1] : *q*[1] − 1]和*A*[*p*[2] : *q*[2] − 1]合并到*B*[*p*[3]
    : *q*[3] − 1]中。 |'
- en: '| 12 | **spawn** P-MERGE-AUX (*A*, *p*[1], *q*[1] − 1, *p*[2], *q*[2] − 1,
    *B*, *p*[3]) |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 12 | **spawn** P-MERGE-AUX (*A*, *p*[1], *q*[1] − 1, *p*[2], *q*[2] − 1,
    *B*, *p*[3]) |'
- en: '| 13 | **//** Recursively merge *A*[*q*[1] + 1 : *r*[1]] and *A*[*q*[2] : *r*[2]]
    into *B*[*q*[3] + 1 : *r*[3]]. |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 13 | **//** 递归地将*A*[*q*[1] + 1 : *r*[1]]和*A*[*q*[2] : *r*[2]]合并到*B*[*q*[3]
    + 1 : *r*[3]]中。 |'
- en: '| 14 | **spawn** P-MERGE-AUX (*A*, *q*[1] + 1, *r*[1], *q*[2], *r*[2], *B*,
    *q*[3] + 1) |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 14 | **spawn** P-MERGE-AUX (*A*, *q*[1] + 1, *r*[1], *q*[2], *r*[2], *B*,
    *q*[3] + 1) |'
- en: '| 15 | **sync** | **//** wait for spawns |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 15 | **同步** | **//** 等待生成 |'
- en: 'We’re now at the crux of P-MERGE-AUX: implementing the parallel divide-and-conquer
    strategy. As we continue our pseudocode walk, you may find it helpful to refer
    again to [Figure 26.6](chapter026.xhtml#Fig_26-6).'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来到P-MERGE-AUX的关键点：实现并行分治策略。当我们继续我们的伪代码漫步时，您可能会发现再次参考[图26.6](chapter026.xhtml#Fig_26-6)会很有帮助。
- en: 'First the divide step. Line 6 computes the midpoint *q*[1] of *A*[*p*[1] :
    *r*[1]], which indexes a median *x* = *A*[*q*[1]] of this subarray to be used
    as the pivot, and line 7 determines *x* itself. Next, line 8 uses the FIND-SPLIT-POINT
    procedure to find the index *q*[2] in *A*[*p*[2] : *r*[2]] such that all elements
    in *A*[*p*[2] : *q*[2] − 1] are at most *x* and all the elements in *A*[*q*[2]
    : *r*[2]] are at least *x*. Line 9 computes the index *q*[3] of the element that
    divides the output subarray *B*[*p*[3] : *r*[3]] into *B*[*p*[3] : *q*[3] − 1]
    and *B*[*q*[3] + 1 : *r*[3]], and then line 10 puts *x* directly into *B*[*q*[3]],
    which is where it belongs in the output.'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '首先是分割步骤。第6行计算了*A*[*p*[1] : *r*[1]]的中点*q*[1]，它索引了这个子数组的中位数*x* = *A*[*q*[1]]作为枢轴，并且第7行确定了*x*本身。接下来，第8行使用FIND-SPLIT-POINT过程在*A*[*p*[2]
    : *r*[2]]中找到索引*q*[2]，使得*A*[*p*[2] : *q*[2] − 1]中的所有元素至多为*x*，而*A*[*q*[2] : *r*[2]]中的所有元素至少为*x*。第9行计算了将输出子数组*B*[*p*[3]
    : *r*[3]]分成*B*[*p*[3] : *q*[3] − 1]和*B*[*q*[3] + 1 : *r*[3]]的元素的索引*q*[3]，然后第10行将*x*直接放入*B*[*q*[3]]中，这是它在输出中应该放置的位置。'
- en: Next is the conquer step, which is where the parallel recursion occurs. Lines
    12 and 14 each spawn P-MERGE-AUX to recursively merge from *A* into *B*, the first
    to merge the smaller elements and the second to merge the larger elements. The
    **sync** statement in line 15 ensures that the subproblems finish before the procedure
    returns.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是征服步骤，这是并行递归发生的地方。第12行和第14行各自生成P-MERGE-AUX，将从*A*合并到*B*，第一个合并较小的元素，第二个合并较大的元素。第15行的**同步**语句确保在过程返回之前子问题完成。
- en: 'There is no combine step, as *B*[*p* : *r*] already contains the correct sorted
    output.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '没有合并步骤，因为*B*[*p* : *r*]已经包含了正确的排序输出。'
- en: '**Work/span analysis of parallel merging**'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行合并的工作/跨度分析**'
- en: Let’s first analyze the worst-case span *T*[∞](*n*) of P-MERGE-AUX on input
    subarrays that together contain a total of *n* elements. The call to FIND-SPLIT-POINT
    in line 8 contributes Θ(lg *n*) to the span in the worst case, and the procedure
    performs at most a constant amount of additional serial work outside of the two
    recursive spawns in lines 12 and 14.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先分析P-MERGE-AUX在包含总共*n*个元素的输入子数组上的最坏情况跨度*T*[∞](*n*)。第8行中对FIND-SPLIT-POINT的调用在最坏情况下对跨度贡献Θ(lg
    *n*)，并且该过程在两个递归生成的行12和14之外执行最多一个常量数量的额外串行工作。
- en: 'Because the two recursive spawns operate logically in parallel, only one of
    them contributes to the overall worst-case span. We claimed earlier that neither
    recursive invocation ever operates on more than 3*n*/4 elements. Let’s see why.
    Let *n*[1] = *r*[1] − *p*[1] + 1 and *n*[2] = *r*[2] − *p*[2] + 1, where *n* =
    *n*[1] + *n*[2], be the sizes of the two subarrays when line 6 starts executing,
    that is, after we have established that *n*[2] ≤ *n*[1] by swapping the roles
    of the two subarrays, if necessary. Since the pivot *x* is a median of of *A*[*p*[1]
    : *r*[1]], in the worst case, a recursive merge involves at most *n*[1]/2 elements
    of *A*[*p*[1] : *r*[1]], but it might involve all *n*[2] of the elements of *A*[*p*[2]
    : *r*[2]]. Thus we can bound the number of elements involved in a recursive invocation
    of P-MERGE-AUX by'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '因为两个递归生成在逻辑上并行操作，只有其中一个对整体最坏情况跨度有贡献。我们之前声称，任何递归调用都不会操作超过3*n*/4个元素。让我们看看为什么。设*n*[1]
    = *r*[1] − *p*[1] + 1和*n*[2] = *r*[2] − *p*[2] + 1，其中*n* = *n*[1] + *n*[2]，是当第6行开始执行时两个子数组的大小，也就是在我们交换两个子数组的角色后，如果有必要的话，我们已经确定了*n*[2]
    ≤ *n*[1]。由于枢轴*x*是*A*[*p*[1] : *r*[1]]的中位数，在最坏情况下，递归合并最多涉及*A*[*p*[1] : *r*[1]]的*n*[1]/2个元素，但可能涉及*A*[*p*[2]
    : *r*[2]]的所有*n*[2]个元素。因此，我们可以通过以下方式限制递归调用P-MERGE-AUX中涉及的元素数量'
- en: '| *n*[1]/2 + *n*[2] | = | (2*n*[1] + 4*n*[2])/4 |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| *n*[1]/2 + *n*[2] | = | (2*n*[1] + 4*n*[2])/4 |'
- en: '|  | ≤ | (3*n*[1] + 3*n*[2])/4 (since *n*[2] ≤ *n*[1]) |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '|  | ≤ | (3*n*[1] + 3*n*[2])/4（因为*n*[2] ≤ *n*[1]） |'
- en: '|  | = | 3*n*/4, |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '|  | = | 3*n*/4, |'
- en: proving the claim.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 证明了这个声明。
- en: 'The worst-case span of P-MERGE-AUX can therefore be described by the following
    recurrence:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，P-MERGE-AUX的最坏情况跨度可以通过以下递归描述：
- en: '![art](images/Art_P839.jpg)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P839.jpg)'
- en: Because this recurrence falls under case 2 of the master theorem with *k* =
    1, its solution is *T*[∞](*n*) = Θ(lg ² *n*).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这个递归符合主定理的第2种情况，其解为*T*[∞](*n*) = Θ(lg ² *n*)。
- en: Now let’s verify that the work *T*[1](*n*) of P-MERGE-AUX on *n* elements is
    linear. A lower bound of Ω(*n*) is straightforward, since each of the *n* elements
    is copied from array *A* to array *B*. We’ll show that *T*[1](*n*) = *O*(*n*)
    by deriving a recurrence for the worst-case work. The binary search in line 8
    costs Θ(lg *n*) in the worst case, which dominates the other work outside of the
    recursive spawns. For the recursive spawns, observe that although lines 12 and
    14 might merge different numbers of elements, the two recursive spawns together
    merge at most *n* − 1 elements (since *x* = *A*[*q*] is not merged). Moreover,
    as we saw when analyzing the span, a recursive spawn operates on at most 3*n*/4
    elements. We therefore obtain the recurrence
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们验证P-MERGE-AUX在*n*个元素上的工作*T*[1](*n*)是线性的。Ω(*n*)的下界很明显，因为这*n*个元素中的每一个都从数组*A*复制到数组*B*。我们将展示*T*[1](*n*)
    = *O*(*n*)，通过为最坏情况工作推导出一个递归。在最坏情况下，第8行中的二分搜索在成本上占据Θ(lg *n*)，这在递归生成之外支配了其他工作。对于递归生成，注意虽然第12行和第14行可能合并不同数量的元素，但两个递归生成一起合并最多*n*
    − 1个元素（因为*x* = *A*[*q*]没有合并）。此外，正如我们在分析跨度时看到的，递归生成在最多3*n*/4个元素上操作。因此，我们得到递归关系
- en: '![art](images/Art_P840.jpg)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![艺术](images/Art_P840.jpg)'
- en: where *α* lies in the range 1/4 ≤ *α* ≤ 3/4\. The value of *α* can vary from
    one recursive invocation to another.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*α*位于范围1/4 ≤ *α* ≤ 3/4。*α*的值可能会从一个递归调用变化到另一个。
- en: We’ll use the substitution method (see [Section 4.3](chapter004.xhtml#Sec_4.3))
    to prove that the above recurrence (26.8) has solution *T*[1](*n*) = *O*(*n*).
    (You could also use the Akra-Bazzi method from [Section 4.7](chapter004.xhtml#Sec_4.7).)
    Assume that *T*[1](*n*) ≤ *c*[1]*n* − *c*[2] lg *n* for some positive constants
    *c*[1] and *c*[2]. Using the properties of logarithms on pages 66–67—in particular,
    to deduce that lg *α* + lg(1 − *α*) = −Θ(1)—substitution yields
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用替换法（参见 [第 4.3 节](chapter004.xhtml#Sec_4.3)）证明上述递归式（26.8）的解为 *T*[1](*n*)
    = *O*(*n*)。（您也可以使用 [第 4.7 节](chapter004.xhtml#Sec_4.7) 的 Akra-Bazzi 方法。）假设对于一些正常数
    *c*[1] 和 *c*[2]，*T*[1](*n*) ≤ *c*[1]*n* − *c*[2] lg *n*。使用页面 66-67 上对数的性质，特别是推导出
    lg *α* + lg(1 − *α*) = −Θ(1) 的性质，替换得到
- en: '| *T*[1](*n*) | ≤ | (*c*[1]*αn* − *c*[2] lg(*αn*)) + (*c*[1](1 − *α*)*n* −
    *c*[2] lg((1 − *α*)*n*)) + Θ(lg *n*) |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| *T*[1](*n*) | ≤ | (*c*[1]*αn* − *c*[2] lg(*αn*)) + (*c*[1](1 − *α*)*n* −
    *c*[2] lg((1 − *α*)*n*)) + Θ(lg *n*) |'
- en: '|  | = | *c*[1](*α* + (1 − *α*))*n* − *c*[2](lg(*αn*) + lg((1 − *α*)*n*)) +
    Θ(lg *n*) |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '|  | = | *c*[1](*α* + (1 − *α*))*n* − *c*[2](lg(*αn*) + lg((1 − *α*)*n*)) +
    Θ(lg *n*) |'
- en: '|  | = | *c*[1]*n* − *c*[2](lg *α* + lg *n* + lg(1 − *α*) + lg *n*) + Θ(lg
    *n*) |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '|  | = | *c*[1]*n* − *c*[2](lg *α* + lg *n* + lg(1 − *α*) + lg *n*) + Θ(lg
    *n*) |'
- en: '|  | = | *c*[1]*n* − *c*[2] lg *n* − *c*[2](lg *n* + lg *α* + lg(1 − *α*))
    + Θ(lg *n*) |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '|  | = | *c*[1]*n* − *c*[2] lg *n* − *c*[2](lg *n* + lg *α* + lg(1 − *α*))
    + Θ(lg *n*) |'
- en: '|  | = | *c*[1]*n* − *c*[2] lg *n* − *c*[2](lg *n* − Θ(1)) + Θ(lg *n*) |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '|  | = | *c*[1]*n* − *c*[2] lg *n* − *c*[2](lg *n* − Θ(1)) + Θ(lg *n*) |'
- en: '|  | ≤ | *c*[1]*n* − *c*[2] lg *n*, |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '|  | ≤ | *c*[1]*n* − *c*[2] lg *n*, |'
- en: if we choose *c*[2] large enough that the *c*[2](lg *n* − Θ(1)) term dominates
    the Θ(lg *n*) term for sufficiently large *n*. Furthermore, we can choose *c*[1]
    large enough to satisfy the implied Θ(1) base cases of the recurrence, completing
    the induction. The lower and upper bounds of Ω(*n*) and *O*(*n*) give *T*[1](*n*)
    = Θ(*n*), asymptotically the same work as for serial merging.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择足够大的 *c*[2]，使得 *c*[2](lg *n* − Θ(1)) 项在足够大的 *n* 下占主导地位于 Θ(lg *n*) 项。此外，我们可以选择足够大的
    *c*[1] 来满足递归的暗含 Θ(1) 基本情况，完成归纳。Ω(*n*) 和 *O*(*n*) 的下限和上限给出 *T*[1](*n*) = Θ(*n*)，与串行合并的工作量渐近相同。
- en: The execution of the pseudocode in the P-MERGE procedure itself does not add
    asymptotically to the work and span of P-MERGE-AUX. The **parallel for** loop
    in lines 3–4 has Θ(lg *n*) span due to the loop control, and each iteration runs
    in constant time. Thus the Θ(lg²*n*) span of P-MERGE-AUX dominates, yielding Θ(lg²*n*)
    span overall for P-MERGE. The **parallel for** loop contains Θ(*n*) work, matching
    the asymptotic work of P-MERGE-AUX and yielding Θ(*n*) work overall for P-MERGE.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: P-MERGE 过程中伪代码的执行本身对 P-MERGE-AUX 的工作和跨度没有渐近影响。第 3-4 行中的 **parallel for** 循环由于循环控制具有
    Θ(lg *n*) 的跨度，每次迭代在常数时间内运行。因此，P-MERGE-AUX 的 Θ(lg²*n*) 跨度占主导地位，从而为 P-MERGE 总体提供
    Θ(lg²*n*) 的跨度。**parallel for** 循环包含 Θ(*n*) 的工作量，与 P-MERGE-AUX 的渐近工作匹配，从而为 P-MERGE
    总体提供 Θ(*n*) 的工作量。
- en: '**Analysis of parallel merge sort**'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行归并排序的分析**'
- en: The “heavy lifting” is done. Now that we have determined the work and span of
    P-MERGE, we can analyze P-MERGE-SORT. Let *T*[1](*n*) and *T*[∞](*n*) be the work
    and span, respectively, of P-MERGE-SORT on an array of *n* elements. The call
    to P-MERGE in line 10 of P-MERGE-SORT dominates the costs of lines 1–3, for both
    work and span. Thus we obtain the recurrence
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: “重活”完成了。现在我们已经确定了 P-MERGE 的工作和跨度，我们可以分析 P-MERGE-SORT。设 *T*[1](*n*) 和 *T*[∞](*n*)
    分别为 *n* 个元素数组上 P-MERGE-SORT 的工作和跨度。P-MERGE-SORT 的第 10 行中对 P-MERGE 的调用主导了第 1-3
    行的成本，无论是工作还是跨度。因此，我们得到递归
- en: '*T*[1](*n*) = 2*T*[1](*n*/2) + Θ(*n*)'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '*T*[1](*n*) = 2*T*[1](*n*/2) + Θ(*n*)'
- en: for the work of P-MERGE-SORT, and we obtain the recurrence
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 P-MERGE-SORT 的工作，我们得到递归
- en: '*T*[∞](*n*) = *T*[∞](*n*/2) + Θ(lg² *n*)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '*T*[∞](*n*) = *T*[∞](*n*/2) + Θ(lg² *n*)'
- en: for its span. The work recurrence has solution *T*[1](*n*) = Θ(*n* lg *n*) by
    case 2 of the master theorem with *k* = 0\. The span recurrence has solution *T*[∞]
    (*n*) = Θ(lg³ *n*), also by case 2 of the master theorem, but with *k* = 2.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其跨度。通过主定理的情况 2，工作递归的解为 *T*[1](*n*) = Θ(*n* lg *n*）。跨度递归的解为 *T*[∞] (*n*) =
    Θ(lg³ *n*)，同样是通过主定理的情况 2，但是 *k* = 2。
- en: Parallel merging gives P-MERGE-SORT a parallelism advantage over P-NAIVE-MERGE-SORT.
    The parallelism of P-NAIVE-MERGE-SORT, which calls the serial MERGE procedure,
    is only Θ(lg *n*). For P-MERGE-SORT, the parallelism is
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 并行合并使得 P-MERGE-SORT 在 P-NAIVE-MERGE-SORT 上具有并行优势。调用串行 MERGE 过程的 P-NAIVE-MERGE-SORT
    的并行性仅为 Θ(lg *n*)。对于 P-MERGE-SORT，其并行性为
- en: '| *T*[1](*n*)/*T*[∞](*n*) | = | Θ(*n* lg *n*)/Θ(lg³ *n*) |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| *T*[1](*n*)/*T*[∞](*n*) | = | Θ(*n* lg *n*)/Θ(lg³ *n*) |'
- en: '|  | = | Θ(*n*/lg² *n*), |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '|  | = | Θ(*n*/lg² *n*), |'
- en: which is much better, both in theory and in practice. A good implementation
    in practice would sacrifice some parallelism by coarsening the base case in order
    to reduce the constants hidden by the asymptotic notation. For example, you could
    switch to an efficient serial sort, perhaps quicksort, when the number of elements
    to be sorted is sufficiently small.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是在理论上还是在实践中，这都要好得多。在实践中，一个良好的实现会通过增加基本情况的粗糙度来牺牲一些并行性，以减少渐近符号隐藏的常数。例如，当需要排序的元素数量足够小时，可以切换到高效的串行排序，例如快速排序。
- en: '**Exercises**'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习**'
- en: '***26.3-1***'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.3-1***'
- en: Explain how to coarsen the base case of P-MERGE.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 解释如何粗化 P-MERGE 的基本情况。
- en: '***26.3-2***'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.3-2***'
- en: Instead of finding a median element in the larger subarray, as P-MERGE does,
    suppose that the merge procedure finds a median of all the elements in the two
    sorted subarrays using the result of Exercise 9.3-10\. Give pseudocode for an
    efficient parallel merging procedure that uses this median-finding procedure.
    Analyze your algorithm.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于 P-MERGE 中找到较大子数组中的中位数，假设合并过程使用练习 9.3-10 的结果找到两个排序子数组中所有元素的中位数。给出一个使用这种中位数查找过程的高效并行合并过程的伪代码。分析你的算法。
- en: '***26.3-3***'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.3-3***'
- en: Give an efficient parallel algorithm for partitioning an array around a pivot,
    as is done by the PARTITION procedure on page 184\. You need not partition the
    array in place. Make your algorithm as parallel as possible. Analyze your algorithm.
    (*Hint:* You might need an auxiliary array and might need to make more than one
    pass over the input elements.)
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 给出一个围绕枢轴对数组进行分区的高效并行算法，就像第184页的 PARTITION 过程所做的那样。你不需要原地分区数组。尽可能使你的算法并行化。分析你的算法。（*提示：*
    你可能需要一个辅助数组，并且可能需要对输入元素进行多次遍历。）
- en: '***26.3-4***'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '***26.3-4***'
- en: Give a parallel version of FFT on page 890\. Make your implementation as parallel
    as possible. Analyze your algorithm.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 给出 FFT 的并行版本，位于第890页。使你的实现尽可能并行化。分析你的算法。
- en: ★ ***26.3-5***
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: ★ ***26.3-5***
- en: Show how to parallelize SELECT from [Section 9.3](chapter009.xhtml#Sec_9.3).
    Make your implementation as parallel as possible. Analyze your algorithm.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 展示如何并行化 [第9.3节](chapter009.xhtml#Sec_9.3) 中的 SELECT。使你的实现尽可能并行化。分析你的算法。
- en: '**Problems**'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**'
- en: '***26-1     Implementing parallel loops using recursive spawning***'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '***26-1     使用递归生成并行循环***'
- en: 'Consider the parallel procedure SUM-ARRAYS for performing pairwise addition
    on *n*-element arrays *A*[1 : *n*] and *B*[1 : *n*], storing the sums in *C* [1
    : *n*].'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '考虑用于对 *n* 元素数组 *A*[1 : *n*] 和 *B*[1 : *n*] 执行成对加法的并行过程 SUM-ARRAYS，将和存储在 *C*
    [1 : *n*] 中。'
- en: SUM-ARRAYS (*A*, *B*, *C*, *n*)
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: SUM-ARRAYS (*A*, *B*, *C*, *n*)
- en: '| 1 | **parallel for** *i* = 1 **to** *n* |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **parallel for** *i* = 1 **to** *n* |'
- en: '| 2 | *C* [*i*] = *A*[*i*] + *B*[*i*] |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *C* [*i*] = *A*[*i*] + *B*[*i*] |'
- en: '***a.*** Rewrite the parallel loop in SUM-ARRAYS using recursive spawning in
    the manner of P-MAT-VEC-RECURSIVE. Analyze the parallelism.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '***a.*** 重写使用递归生成的方式在 SUM-ARRAYS 中的并行循环，类似于 P-MAT-VEC-RECURSIVE。分析并行性。'
- en: Consider another implementation of the parallel loop in SUM-ARRAYS given by
    the procedure SUM-ARRAYS′, where the value *grain*-*size* must be specified.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑在 SUM-ARRAYS 中执行成对数组加法的并行过程，给出 SUM-ARRAYS′ 过程，其中必须指定值 *grain*-*size*。
- en: SUM-ARRAYS′(*A*, *B*, *C*, *n*)
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: SUM-ARRAYS′(*A*, *B*, *C*, *n*)
- en: '| 1 | *grain*-*size* = ? | **//** to be determined |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| 1 | *grain*-*size* = ? | **//** 待确定 |'
- en: '| 2 | *r* = ⌈*n*/*grain*-*size*⌉ |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *r* = ⌈*n*/*grain*-*size*⌉ |'
- en: '| 3 | **for** *k* = 0 **to** *r* − 1 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **for** *k* = 0 **to** *r* − 1 |'
- en: '| 4 | **spawn** ADD-SUBARRAY (*A*, *B*, *C*, *k* · *grain*-*size* + 1, |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 4 | **spawn** ADD-SUBARRAY (*A*, *B*, *C*, *k* · *grain*-*size* + 1, |'
- en: '|  | min {(*k* + 1) · *grain*-*size*, *n*}) |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '|  | min {(*k* + 1) · *grain*-*size*, *n*}) |'
- en: '| 5 | **sync** |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| 5 | **sync** |'
- en: '| ADD-SUBARRAY (*A*, *B*, *C*, *i*, *j*) |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| ADD-SUBARRAY (*A*, *B*, *C*, *i*, *j*) |'
- en: '| 1 | **for** *k* = *i* **to** *j* |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **for** *k* = *i* **to** *j* |'
- en: '| 2 | *C* [*k*] = *A*[*k*] + *B*[*k*] |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *C* [*k*] = *A*[*k*] + *B*[*k*] |'
- en: '***b.*** Suppose that you set *grain*-*size* = 1\. What is the resulting parallelism?'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '***b.*** 假设你设置 *grain*-*size* = 1\. 那么得到的并行性是多少？'
- en: '***c.*** Give a formula for the span of SUM-ARRAYS′ in terms of *n* and *grain*-*size*.
    Derive the best value for *grain*-*size* to maximize parallelism.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '***c.*** 给出 SUM-ARRAYS′ 的跨度公式，其中包含 *n* 和 *grain*-*size*。推导出最大化并行性的最佳 *grain*-*size*
    值。'
- en: '***26-2     Avoiding a temporary matrix in recursive matrix multiplication***'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '***26-2     在递归矩阵乘法中避免临时矩阵***'
- en: 'The P-MATRIX-MULTIPLY-RECURSIVE procedure on page 772 must allocate a temporary
    matrix *D* of size *n* × *n*, which can adversely affect the constants hidden
    by the Θ-notation. The procedure has high parallelism, however: Θ(*n*³/log² *n*).
    For example, ignoring the constants in the Θ-notation, the parallelism for multiplying
    1000 × 1000 matrices comes to approximately 1000³/10² = 10⁷, since lg 1000 ≈ 10\.
    Most parallel computers have far fewer than 10 million processors.'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 第772页的 P-MATRIX-MULTIPLY-RECURSIVE 过程必须分配一个大小为 *n* × *n* 的临时矩阵 *D*，这可能会影响Θ-符号隐藏的常数。然而，该过程具有很高的并行性：Θ(*n*³/log²
    *n*)。例如，忽略Θ-符号中的常数，对于乘法 1000 × 1000 矩阵的并行性大约为 1000³/10² = 10⁷，因为 lg 1000 ≈ 10\.
    大多数并行计算机的处理器远少于 1000 万个。
- en: '***a.*** Parallelize MATRIX-MULTIPLY-RECURSIVE without using temporary matrices
    so that it retains its Θ(*n*³) work. (*Hint:* Spawn the recursive calls, but insert
    a **sync** in a judicious location to avoid races.)'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '***a.*** 并行化 MATRIX-MULTIPLY-RECURSIVE，不使用临时矩阵，以保持其 Θ(*n*³) 的工作。(*提示：* 生成递归调用，但在适当的位置插入
    **sync** 以避免竞争。)'
- en: '***b.*** Give and solve recurrences for the work and span of your implementation.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '***b.*** 给出并解决你的实现的工作和跨度的递归关系。'
- en: '***c.*** Analyze the parallelism of your implementation. Ignoring the constants
    in the Θ-notation, estimate the parallelism on 1000 × 1000 matrices. Compare with
    the parallelism of P-MATRIX-MULTIPLY-RECURSIVE, and discuss whether the trade-off
    would be worthwhile.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '***c.*** 分析你的实现的并行性。忽略Θ-符号中的常数，估计在 1000 × 1000 矩阵上的并行性。与 P-MATRIX-MULTIPLY-RECURSIVE
    的并行性进行比较，并讨论这种权衡是否值得。'
- en: '***26-3     Parallel matrix algorithms***'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '***26-3     并行矩阵算法***'
- en: Before attempting this problem, it may be helpful to read [Chapter 28](chapter028.xhtml).
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试这个问题之前，阅读 [第28章](chapter028.xhtml) 可能会有所帮助。
- en: '***a.*** Parallelize the LU-DECOMPOSITION procedure on page 827 by giving pseudocode
    for a parallel version of this algorithm. Make your implementation as parallel
    as possible, and analyze its work, span, and parallelism.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '***a.*** 通过给出 LU-DECOMPOSITION 过��的伪代码，通过给出该算法的并行版本，使你的实现尽可能并行化，并分析其工作、跨度和并行性。'
- en: '***b.*** Do the same for LUP-DECOMPOSITION on page 830.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '***b.*** 对第830页的 LUP-DECOMPOSITION 做同样的事情。'
- en: '***c.*** Do the same for LUP-SOLVE on page 824.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '***c.*** 对第824页的 LUP-SOLVE 做同样的事情。'
- en: '***d.*** Using equation (28.14) on page 835, write pseudocode for a parallel
    algorithm to invert a symmetric positive-definite matrix. Make your implementation
    as parallel as possible, and analyze its work, span, and parallelism.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '***d.*** 使用第835页的方程（28.14），编写一个用于求逆对称正定矩阵的并行算法的伪代码。使你的实现尽可能并行化，并分析其工作、跨度和并行性。'
- en: '***26-4     Parallel reductions and scan (prefix) computations***'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '***26-4     并行约简和扫描（前缀）计算***'
- en: 'A **⊗-*reduction*** of an array *x*[1 : *n*], where ⊗ is an associative operator,
    is the value *y* = *x*[1] ⊗ *x*[2] ⊗ ⋯ ⊗ *x*[*n*]. The REDUCE procedure computes
    the ⊗-reduction of a subarray *x*[*i* : *j*] serially.'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '数组 *x*[1 : *n*] 的 **⊗-*reduction***，其中 ⊗ 是一个可结合的运算符，其值为 *y* = *x*[1] ⊗ *x*[2]
    ⊗ ⋯ ⊗ *x*[*n*]。REDUCE 过程以串行方式计算子数组 *x*[*i* : *j*] 的 ⊗-reduction。'
- en: REDUCE (*x*, *i*, *j*)
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: REDUCE (*x*, *i*, *j*)
- en: '| 1 | *y* = *x*[*i*] |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 1 | *y* = *x*[*i*] |'
- en: '| 2 | **for** *k* = *i* + 1 **to** *j* |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **for** *k* = *i* + 1 **to** *j* |'
- en: '| 3 | *y* = *y* ⊗ *x*[*k*] |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 3 | *y* = *y* ⊗ *x*[*k*] |'
- en: '| 4 | **return** *y* |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 4 | **return** *y* |'
- en: '***a.*** Design and analyze a parallel algorithm P-REDUCE that uses recursive
    spawning to perform the same function with Θ(*n*) work and Θ(lg *n*) span.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '***a.*** 设计并分析一个并行算法 P-REDUCE，使用递归生成来执行相同的功能，具有 Θ(*n*) 的工作量和 Θ(lg *n*) 的跨度。'
- en: 'A related problem is that of computing a **⊗*-scan***, sometimes called a **⊗*-prefix
    computation***, on an array *x*[1 : *n*], where ⊗ is once again an associative
    operator. The ⊗-scan, implemented by the serial procedure SCAN, produces the array
    *y*[1 : *n*] given by'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '一个相关问题是在数组 *x*[1 : *n*] 上计算 **⊗*-scan***，有时称为 **⊗*-prefix computation***，其中
    ⊗ 再次是一个可结合的运算符。 ⊗-scan 由串行过程 SCAN 实现，产生数组 *y*[1 : *n*]，其定义为'
- en: '| *y*[1] | = | *x*[1], |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| *y*[1] | = | *x*[1], |'
- en: '| *y*[2] | = | *x*[1] ⊗ *x*[2], |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| *y*[2] | = | *x*[1] ⊗ *x*[2], |'
- en: '| *y*[3] | = | *x*[1] ⊗ *x*[2] ⊗ *x*[3], |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| *y*[3] | = | *x*[1] ⊗ *x*[2] ⊗ *x*[3], |'
- en: '|  | ⋮ |  |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '|  | ⋮ |  |'
- en: '| *y*[*n*] | = | *x*[1] ⊗ *x*[2] ⊗ *x*[3] ⊗ ⋯ ⊗ *x*[*n*], |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| *y*[*n*] | = | *x*[1] ⊗ *x*[2] ⊗ *x*[3] ⊗ ⋯ ⊗ *x*[*n*], |'
- en: that is, all prefixes of the array *x* “summed” using the ⊗ operator.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 即，使用 ⊗ 运算符“求和”数组 *x* 的所有前缀。
- en: SCAN (*x*, *n*)
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: SCAN (*x*, *n*)
- en: '| 1 | let *y*[1 : *n*] be a new array |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 令 *y*[1 : *n*] 为一个新数组 |'
- en: '| 2 | *y*[1] = *x*[1] |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *y*[1] = *x*[1] |'
- en: '| 3 | **for** *i* = 2 **to** *n* |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **for** *i* = 2 **to** *n* |'
- en: '| 4 | *y*[*i*] = *y*[*i* − 1] ⊗ 1 ⊗ *x*[*i*] |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| 4 | *y*[*i*] = *y*[*i* − 1] ⊗ 1 ⊗ *x*[*i*] |'
- en: '| 5 | **return** *y* |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| 5 | **return** *y* |'
- en: Parallelizing SCAN is not straightforward. For example, simply changing the
    **for** loop to a **parallel for** loop would create races, since each iteration
    of the loop body depends on the previous iteration. The procedures P-SCAN-1 and
    P-SCAN-1-AUX perform the ⊗-scan in parallel, albeit inefficiently.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化 SCAN 并不直接。例如，仅仅将 **for** 循环更改为 **parallel for** 循环会导致竞争，因为每次循环体的迭代都依赖于前一次迭代。尽管效率低下，但过程
    P-SCAN-1 和 P-SCAN-1-AUX 以并行方式执行 ⊗-scan。
- en: P-SCAN-1(*x*, *n*)
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: P-SCAN-1(*x*, *n*)
- en: '| 1 | let *y*[1] : *n* be a new array |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 令 *y*[1] : *n* 为一个新数组 |'
- en: '| 2 | P-SCAN-1-AUX (*x*, *y*, 1, *n*) |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 2 | P-SCAN-1-AUX (*x*, *y*, 1, *n*) |'
- en: '| 3 | **return** *y* |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **return** *y* |'
- en: '| P-SCAN-1-AUX (*x*, *y*, *i*, *j*) |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| P-SCAN-1-AUX (*x*, *y*, *i*, *j*) |'
- en: '| 1 | **parallel for** *l* = *i* **to** *j* |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **parallel for** *l* = *i* **to** *j* |'
- en: '| 2 | *y*[*l*] = P-REDUCE (*x*, 1, *l*) |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *y*[*l*] = P-REDUCE (*x*, 1, *l*) |'
- en: '***b.*** Analyze the work, span, and parallelism of P-SCAN-1.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '***b.*** 分析 P-SCAN-1 的工作量、跨度和并行性。'
- en: The procedures P-SCAN-2 and P-SCAN-2-AUX use recursive spawning to perform a
    more efficient ⊗-scan.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: P-SCAN-2 和 P-SCAN-2-AUX 过程使用递归生成来执行更有效的 ⊗-scan。
- en: P-SCAN-2(*x*, *n*)
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: P-SCAN-2(*x*, *n*)
- en: '| 1 | let *y*[1] : *n* be a new array |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 令 *y*[1] : *n* 为一个新数组 |'
- en: '| 2 | P-SCAN-2-AUX (*x*, *y*, 1, *n*) |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 2 | P-SCAN-2-AUX (*x*, *y*, 1, *n*) |'
- en: '| 3 | **return** *y* |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **return** *y* |'
- en: '| P-SCAN-2-AUX (*x*, *y*, *i*, *j*) |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| P-SCAN-2-AUX (*x*, *y*, *i*, *j*) |'
- en: '| 1 | **if** *i* == *j* |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **if** *i* == *j* |'
- en: '| 2 | *y*[*i*] = *x*[*i*] |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *y*[*i*] = *x*[*i*] |'
- en: '| 3 | **else** *k* = ⌊(*i* + *j*)/2⌋ |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **else** *k* = ⌊(*i* + *j*)/2⌋ |'
- en: '| 4 | **spawn** P-SCAN-2-AUX (*x*, *y*, *i*, *k*) |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 4 | **spawn** P-SCAN-2-AUX (*x*, *y*, *i*, *k*) |'
- en: '| 5 | P-SCAN-2-AUX (*x*, *y*, *k* + 1, *j*) |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 5 | P-SCAN-2-AUX (*x*, *y*, *k* + 1, *j*) |'
- en: '| 6 | **sync** |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| 6 | **sync** |'
- en: '| 7 | **parallel for** *l* = *k* + 1 **to** *j* |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| 7 | **parallel for** *l* = *k* + 1 **to** *j* |'
- en: '| 8 | *y*[*l*] = *y*[*k*] ⊗ *y*[*l*] |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| 8 | *y*[*l*] = *y*[*k*] ⊗ *y*[*l*] |'
- en: '***c.*** Argue that P-SCAN-2 is correct, and analyze its work, span, and parallelism.'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '***c.*** 论证 P-SCAN-2 的正确性，并分析其工作量、跨度和并行性。'
- en: To improve on both P-SCAN-1 and P-SCAN-2, perform the ⊗-scan in two distinct
    passes over the data. The first pass gathers the terms for various contiguous
    subarrays of *x* into a temporary array *t*, and the second pass uses the terms
    in *t* to compute the final result *y*. The pseudocode in the procedures P-SCAN-3,
    P-SCAN-UP, and P-SCAN-DOWN on the facing page implements this strategy, but certain
    expressions have been omitted.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进 P-SCAN-1 和 P-SCAN-2，对数据进行两次不同的 ⊗-scan。第一次收集 *x* 的各个连续子数组的项到临时数组 *t* 中，第二次使用
    *t* 中的项计算最终结果 *y*。在面向页面的 P-SCAN-3、P-SCAN-UP 和 P-SCAN-DOWN 过程中实现了这种策略，但某些表达式被省略了。
- en: '***d.*** Fill in the three missing expressions in line 8 of P-SCAN-UP and lines
    5 and 6 of P-SCAN-DOWN. Argue that with the expressions you supplied, P-SCAN-3
    is correct. (*Hint:* Prove that the value *v* passed to P-SCAN-DOWN (*v*, *x*,
    *t*, *y*, *i*, *j*) satisfies *v* = *x*[1] ⊗ *x*[2] ⊗ ⋯ ⊗ *x*[*i* − 1].)'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '***d.*** 填写 P-SCAN-UP 的第 8 行和 P-SCAN-DOWN 的第 5 和第 6 行中的三个缺失表达式。证明你提供的表达式使得
    P-SCAN-3 正确。(*提示:* 证明传递给 P-SCAN-DOWN (*v*, *x*, *t*, *y*, *i*, *j*) 的值 *v* 满足
    *v* = *x*[1] ⊗ *x*[2] ⊗ ⋯ ⊗ *x*[*i* − 1]。)'
- en: '***e.*** Analyze the work, span, and parallelism of P-SCAN-3.'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '***e.*** 分析 P-SCAN-3 的工作量、跨度和并行性。'
- en: '***f.*** Describe how to rewrite P-SCAN-3 so that it doesn’t require the use
    of the temporary array *t*.'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '***f.*** 描述如何重写 P-SCAN-3，使其不需要使用临时数组 *t*。'
- en: '**★ *g.*** Give an algorithm P-SCAN-4(*x*, *n*) for a scan that operates in
    place. It should place its output in *x* and require only constant auxiliary storage.'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '**★ *g.*** 给出一个算法 P-SCAN-4(*x*, *n*)，用于在原地进行扫描。它应该将输出放在 *x* 中，并且只需要常数辅助存���。'
- en: '***h.*** Describe an efficient parallel algorithm that uses a +-scan to determine
    whether a string of parentheses is well formed. For example, the string ( ( )
    ( ) ) ( ) is well formed, but the string ( ( ) ) ) ( ( ) is not. (*Hint:* Interpret
    ( as a 1 and ) as a −1, and then perform a +-scan.)'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '***h.*** 描述一个有效的并行算法，使用 +-scan 来确定括号字符串是否格式正确。例如，字符串 ( ( ) ( ) ) ( ) 是格式正确的，但字符串
    ( ( ) ) ) ( ( ) 不是。(*提示:* 将 ( 解释为 1，) 解释为 −1，然后执行一个 +-scan。)'
- en: P-SCAN-3(*x*, *n*)
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: P-SCAN-3(*x*, *n*)
- en: '| 1 | let *y*[1] : *n* and *t*[1 : *n*] be new arrays |  |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 令 *y*[1] : *n* 和 *t*[1 : *n*] 为新数组 |  |'
- en: '| 2 | *y*[1] = *x*[1] |  |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *y*[1] = *x*[1] |  |'
- en: '| 3 | **if** *n* > 1 |  |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **if** *n* > 1 |  |'
- en: '| 4 | P-SCAN-UP (*x*, *t*, 2, *n*) |  |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| 4 | P-SCAN-UP（* x *，* t *，2，* n *） |  |'
- en: '| 5 | P-SCAN-DOWN (*x*[1], *x*, *t*, *y*, 2, *n*) |  |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| 5 | P-SCAN-DOWN（* x * [1]，* x *，* t *，* y *，2，* n *） |  |'
- en: '| 6 | **return** *y* |  |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| 6 | **return** * y * |  |'
- en: '| P-SCAN-UP (*x*, *t*, *i*, *j*) |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| P-SCAN-UP（* x *，* t *，* i *，* j *） |'
- en: '| 1 | **if** *i* == *j* |  |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **if** * i * == * j * |  |'
- en: '| 2 | **return** *x*[*i*] |  |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| 2 | **return** * x * [* i *] |  |'
- en: '| 3 | **else** |  |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **else** |  |'
- en: '| 4 | *k* = ⌊(*i* + *j*)/2⌋ |  |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| 4 | * k * = ⌊（* i * + * j *）/2⌋ |  |'
- en: '| 5 | *t*[*k*] = **spawn** P-SCAN-UP (*x*, *t*, *i*, *k*) |  |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| 5 | * t * [* k *] = **spawn** P-SCAN-UP（* x *，* t *，* i *，* k *） |  |'
- en: '| 6 | *right* = P-SCAN-UP (*x*, *t*, *k* + 1, *j*) |  |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| 6 | * right * = P-SCAN-UP（* x *，* t *，* k * + 1，* j *） |  |'
- en: '| 7 | **sync** |  |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| 7 | **sync** |  |'
- en: '| 8 | **return** ____ | **//** fill in the blank |  |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| 8 | **return** ____ | **//** 填空 |  |'
- en: '| P-SCAN-DOWN (*v*, *x*, *t*, *y*, *i*, *j*) |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| P-SCAN-DOWN（* v *，* x *，* t *，* y *，* i *，* j *） |'
- en: '| 1 | **if** *i* == *j* |  |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| 1 | **if** * i * == * j * |  |'
- en: '| 2 | *y*[*i*] = *v* ⊗ *x*[*i*] |  |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| 2 | * y * [* i *] = * v * ⊗ * x * [* i *] |  |'
- en: '| 3 | **else** |  |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| 3 | **else** |  |'
- en: '| 4 | *k* = ⌊(*i* + *j*)/2⌋ |  |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| 4 | * k * = ⌊（* i * + * j *）/2⌋ |  |'
- en: '| 5 | **spawn** P-SCAN-DOWN (____, *x*, *t*, *y*, *i*, *k*) | **//** fill in
    the blank |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| 5 | **spawn** P-SCAN-DOWN（____，* x *，* t *，* y *，* i *，* k *） | **//** 填空
    |'
- en: '| 6 | P-SCAN-DOWN (____, *x*, *t*, *y*, *k* + 1, *j*) | **//** fill in the
    blank |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| 6 | P-SCAN-DOWN（____，* x *，* t *，* y *，* k * + 1，* j *） | **//** 填空 |'
- en: '| 7 | **sync** |  |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '| 7 | **sync** |  |'
- en: '***26-5     Parallelizing a simple stencil calculation***'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '***26-5     并行化简单的模板计算***'
- en: Computational science is replete with algorithms that require the entries of
    an array to be filled in with values that depend on the values of certain already
    computed neighboring entries, along with other information that does not change
    over the course of the computation. The pattern of neighboring entries does not
    change during the computation and is called a ***stencil***. For example, [Section
    14.4](chapter014.xhtml#Sec_14.4) presents a stencil algorithm to compute a longest
    common subsequence, where the value in entry *c*[*i*, *j*] depends only on the
    values in *c*[*i* − 1, *j*], *c*[*i*, *j* − 1], and *c*[*i* − 1, *j* − 1], as
    well as the elements *x*[*i*] and *y*[*j*] within the two sequences given as inputs.
    The input sequences are fixed, but the algorithm fills in the two-dimensional
    array *c* so that it computes entry *c*[*i*, *j*] after computing all three entries
    *c*[*i* − 1, *j*], *c*[*i*, *j* − 1], and *c*[*i* − 1, *j* − 1].
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 计算科学中充斥着需要将数组的条目填充为依赖于某些已计算的相邻条目的值以及在计算过程中不会改变的其他信息的算法。相邻条目的模式在计算过程中不会改变，并称为***模板***。例如，[第14.4节](chapter014.xhtml#Sec_14.4)介绍了一种模板算法，用于计算最长公共子序列，其中条目*
    c * [* i *，* j *] 中的值仅取决于输入作为元素的两个序列中的元素* x * [* i *] 和* y * [* j *] 的值，以及* c
    * [* i * - 1，* j *]，* c * [* i *，* j * - 1] 和* c * [* i * - 1，* j * - 1] 中的值。输入序列是固定的，但算法填充二维数组*
    c *，以便在计算所有三个条目* c * [* i * - 1，* j *]，* c * [* i *，* j * - 1] 和* c * [* i * -
    1，* j * - 1] 之后计算条目* c * [* i *，* j *]。
- en: This problem examines how to use recursive spawning to parallelize a simple
    stencil calculation on an *n* × *n* array *A* in which the value placed into entry
    *A*[*i*, *j*] depends only on values in *A*[*i*′, *j*′], where *i*′ ≤ *i* and
    *j*′ ≤ *j* (and of course, *i*′ ≠ *i* or *j*′ ≠ *j*). In other words, the value
    in an entry depends only on values in entries that are above it and/or to its
    left, along with static information outside of the array. Furthermore, we assume
    throughout this problem that once the entries upon which *A*[*i*, *j*] depends
    have been filled in, the entry *A*[*i*, *j*] can be computed in Θ(1) time (as
    in the LCS-LENGTH procedure of [Section 14.4](chapter014.xhtml#Sec_14.4)).
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题考察了如何使用递归生成来并行化一个简单的* n *× * n *数组* A *上的一个简单的模板计算，其中放入条目* A * [* i *，*
    j *] 的值仅取决于* A * [* i *′，* j *′] 中的值，其中* i *′ ≤ * i *和* j *′ ≤ * j *（当然，* i *′
    ≠ * i *或* j *′ ≠ * j *）。换句话说，一个条目中的值仅取决于在其上方和/或左侧的条目中的值，以及数组外的静态信息。此外，在整个问题中，我们假设一旦填入了*
    A * [* i *，* j *] 依赖的条目，条目* A * [* i *，* j *] 可以在Θ（1）时间内计算出来（就像[第14.4节](chapter014.xhtml#Sec_14.4)中的LCS-LENGTH过程一样）。
- en: 'Partition the *n* × *n* array *A* into four *n*/2 × *n*/2 subarrays as follows:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 将* n *× * n *数组* A *分成四个* n */2 × * n */2子数组，如下所示：
- en: '![art](images/Art_P841.jpg)'
  id: totrans-482
  prefs: []
  type: TYPE_IMG
  zh: '![art](images/Art_P841.jpg)'
- en: You can immediately fill in subarray *A*[11] recursively, since it does not
    depend on the entries in the other three subarrays. Once the computation of *A*[11]
    finishes, you can fill in *A*[12] and *A*[21] recursively in parallel, because
    although they both depend on *A*[11], they do not depend on each other. Finally,
    you can fill in *A*[22] recursively.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以立即递归填充子数组* A * [11]，因为它不依赖于其他三个子数组中的条目。一旦计算* A * [11] 完成，你可以并行递归填充* A * [12]
    和* A * [21]，因为虽然它们都依赖于* A * [11]，但它们彼此之间不依赖。最后，你可以递归填充* A * [22]。
- en: '***a.*** Give parallel pseudocode that performs this simple stencil calculation
    using a divide-and-conquer algorithm SIMPLE-STENCIL based on the decomposition
    (26.9) and the discussion above. (Don’t worry about the details of the base case,
    which depends on the specific stencil.) Give and solve recurrences for the work
    and span of this algorithm in terms of *n*. What is the parallelism?'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '***a.*** 给���使用基于分解（26.9）和上述讨论的分治算法SIMPLE-STENCIL执行这个简单模板计算的并行伪代码。（不用担心基本情况的细节，这取决于特定的模板。）根据*
    n *的工作量和跨度给出并解决这个算法的递归。并行度是多少？'
- en: '***b.*** Modify your solution to part (a) to divide an *n* × *n* array into
    nine *n*/3 × *n*/3 subarrays, again recursing with as much parallelism as possible.
    Analyze this algorithm. How much more or less parallelism does this algorithm
    have compared with the algorithm from part (a)?'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '***b.*** 修改你在第（a）部分的解决方案，将一个* n *× * n *数组分成九个* n */3 × * n */3子数组，再次尽可能并行地进行递归。分析这个算法。与第（a）部分的算法相比，这个算法有多少更多或更少的并行性？'
- en: '***c.*** Generalize your solutions to parts (a) and (b) as follows. Choose
    an integer *b* ≥ 2\. Divide an *n* × *n* array into *b*² subarrays, each of size
    *n*/*b* × *n*/*b*, recursing with as much parallelism as possible. In terms of
    *n* and *b*, what are the work, span, and parallelism of your algorithm? Argue
    that, using this approach, the parallelism must be *o*(*n*) for any choice of
    *b* ≥ 2\. (*Hint:* For this argument, show that the exponent of *n* in the parallelism
    is strictly less than 1 for any choice of *b* ≥ 2.)'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '***c.*** 将你在(a)和(b)部分的解决方案推广如下。选择一个整数 *b* ≥ 2。将一个 *n* × *n* 数组分成 *b*² 个子数组，每个大小为
    *n*/*b* × *n*/*b*，尽可能递归地实现并行性。根据 *n* 和 *b*，你的算法的工作量、跨度和并行性是多少？论证，使用这种方法，对于任何选择的
    *b* ≥ 2，并行性必须是 *o*(*n*)。(*提示:* 对于这个论证，证明并行性中 *n* 的指数对于任何选择的 *b* ≥ 2 都严格小于 1。)'
- en: '***d.*** Give pseudocode for a parallel algorithm for this simple stencil calculation
    that achieves Θ(*n*/lg *n*) parallelism. Argue using notions of work and span
    that the problem has Θ(*n*) inherent parallelism. Unfortunately, simple fork-join
    parallelism does not let you achieve this maximal parallelism.'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: '***d.*** 给出一个简单的模板计算的并行算法的伪代码，实现 Θ(*n*/lg *n*) 的并行性。使用工作和跨度的概念来论证问题具有 Θ(*n*)
    的固有并行性。不幸的是，简单的分叉-加入并行性无法实现这种最大并行性。'
- en: '***26-6     Randomized parallel algorithms***'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '***26-6     随机并行算法***'
- en: Like serial algorithms, parallel algorithms can employ random-number generators.
    This problem explores how to adapt the measures of work, span, and parallelism
    to handle the expected behavior of randomized task-parallel algorithms. It also
    asks you to design and analyze a parallel algorithm for randomized quicksort.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 像串行算法一样，并行算法可以使用随机数生成器。这个问题探讨了如何调整工作、跨度和并行性的度量，以处理随机任务并行算法的预期行为。它还要求你设计和分析一个随机快速排序的并行算法。
- en: '***a.*** Explain how to modify the work law (26.2), span law (26.3), and greedy
    scheduler bound (26.4) to work with expectations when *T*[*P*], *T*[1], and *T*[∞]are
    all random variables.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '***a.*** 解释如何修改工作定律（26.2）、跨度定律（26.3）和贪婪调度器界限（26.4），以处理当 *T*[*P*]、*T*[1] 和 *T*[∞]
    都是随机变量时的期望。'
- en: '***b.*** Consider a randomized parallel algorithm for which 1% of the time,
    *T*[1] = 10⁴ and *T*[10,000] = 1, but for the remaining 99% of the time, *T*[1]
    = *T*[10,000] = 10⁹. Argue that the ***speedup*** of a randomized parallel algorithm
    should be defined as *E*[*T*[1]]/*E*[*T*[*P*]], rather than *E*[*T*[1]/*T*[*P*]].'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: '***b.*** 考虑一个随机并行算法，其中 1% 的时间，*T*[1] = 10⁴，*T*[10,000] = 1，但在剩下的 99% 的时间里，*T*[1]
    = *T*[10,000] = 10⁹。论证随机并行算法的***加速比***应该定义为 *E*[*T*[1]]/*E*[*T*[*P*]]，而不是 *E*[*T*[1]/*T*[*P*]]。'
- en: '***c.*** Argue that the ***parallelism*** of a randomized task-parallel algorithm
    should be defined as the ratio *E*[*T*[1]]/*E*[*T*[∞]].'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '***c.*** 论证随机任务并行算法的***并行性***应该定义为比率 *E*[*T*[1]]/*E*[*T*[∞]]。'
- en: '***d.*** Parallelize the RANDOMIZED-QUICKSORT algorithm on page 192 by using
    recursive spawning to produce P-RANDOMIZED-QUICKSORT. (Do not parallelize RANDOMIZED-PARTITION.)'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: '***d.*** 使用递归生成来并行化第192页上的 RANDOMIZED-QUICKSORT 算法，得到 P-RANDOMIZED-QUICKSORT。（不要并行化
    RANDOMIZED-PARTITION。）'
- en: '***e.*** Analyze your parallel algorithm for randomized quicksort. (*Hint:*
    Review the analysis of RANDOMIZED-SELECT on page 230.)'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: '***e.*** 分析你的随机快速排序的并行算法。（*提示:* 回顾第230页上 RANDOMIZED-SELECT 的分析。）'
- en: '***f.*** Parallelize RANDOMIZED-SELECT on page 230\. Make your implementation
    as parallel as possible. Analyze your algorithm. (*Hint:* Use the partitioning
    algorithm from Exercise 26.3-3.)'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '***f.*** 并行化第230页上的 RANDOMIZED-SELECT。尽可能使你的实现并行化。分析你的算法。（*提示:* 使用练习 26.3-3
    中的分区算法。）'
- en: '**Chapter notes**'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '**章节注释**'
- en: Parallel computers and algorithmic models for parallel programming have been
    around in various forms for years. Prior editions of this book included material
    on sorting networks and the PRAM (Parallel Random-Access Machine) model. The data-parallel
    model [[58](bibliography001.xhtml#endnote_58), [217](bibliography001.xhtml#endnote_217)]
    is another popular algorithmic programming model, which features operations on
    vectors and matrices as primitives. The notion of sequential consistency is due
    to Lamport [[275](bibliography001.xhtml#endnote_275)].
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 并行计算机和并行编程的算法模型已经以各种形式存在多年。本书的先前版本包括关于排序网络和 PRAM（并行随机访问机器）模型的材料。数据并行模型[[58](bibliography001.xhtml#endnote_58),
    [217](bibliography001.xhtml#endnote_217)]是另一个流行的算法编程模型，其特点是向量和矩阵上的操作作为原语。顺序一致性的概念归功于
    Lamport[[275](bibliography001.xhtml#endnote_275)]。
- en: Graham [[197](bibliography001.xhtml#endnote_197)] and Brent [[71](bibliography001.xhtml#endnote_71)]
    showed that there exist schedulers achieving the bound of Theorem 26.1\. Eager,
    Zahorjan, and Lazowska [[129](bibliography001.xhtml#endnote_129)] showed that
    any greedy scheduler achieves this bound and proposed the methodology of using
    work and span (although not by those names) to analyze parallel algorithms. Blelloch
    [[57](bibliography001.xhtml#endnote_57)] developed an algorithmic programming
    model based on work and span (which he called “depth”) for data-parallel programming.
    Blumofe and Leiserson [[63](bibliography001.xhtml#endnote_63)] gave a distributed
    scheduling algorithm for task-parallel computations based on randomized “work-stealing”
    and showed that it achieves the bound *E*[*T*[*P*]] ≤ *T*[1]/*P* + *O*(*T*[∞]).
    Arora, Blumofe, and Plaxton [[20](bibliography001.xhtml#endnote_20)] and Blelloch,
    Gibbons, and Matias [[61](bibliography001.xhtml#endnote_61)] also provided provably
    good algorithms for scheduling task-parallel computations. The recent literature
    contains many algorithms and strategies for scheduling parallel programs.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: Graham[[197](bibliography001.xhtml#endnote_197)]和Brent[[71](bibliography001.xhtml#endnote_71)]表明存在可以实现定理26.1界限的调度程序。Eager、Zahorjan和Lazowska[[129](bibliography001.xhtml#endnote_129)]表明，任何贪婪调度程序都可以实现这个界限，并提出了使用工作量和跨度（尽管不是这些名称）来分析并行算法的方法。Blelloch[[57](bibliography001.xhtml#endnote_57)]基于工作量和跨度（他称之为“深度”）开发了一种数据并行编程的算法编程模型。Blumofe和Leiserson[[63](bibliography001.xhtml#endnote_63)]提供了一种基于随机“工作窃取”的分布式调度算法，用于基于任务的并��计算，并表明它实现了界限*E*[*T*[*P*]]
    ≤ *T*[1]/*P* + *O*(*T*[∞])。Arora、Blumofe和Plaxton[[20](bibliography001.xhtml#endnote_20)]和Blelloch、Gibbons和Matias[[61](bibliography001.xhtml#endnote_61)]还为调度任务并行计算提供了可证明良好的算法。最近的文献包含许多调度并行程序的算法和策略。
- en: The parallel pseudocode and programming model were influenced by Cilk [[290](bibliography001.xhtml#endnote_290),
    [291](bibliography001.xhtml#endnote_291), [383](bibliography001.xhtml#endnote_383),
    [396](bibliography001.xhtml#endnote_396)]. The open-source project OpenCilk ([www.opencilk.org](http://www.opencilk.org))
    provides Cilk programming as an extension to the C and C++ programming languages.
    All of the parallel algorithms in this chapter can be coded straightforwardly
    in Cilk.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 并行伪代码和编程模型受到Cilk的影响[[290](bibliography001.xhtml#endnote_290), [291](bibliography001.xhtml#endnote_291),
    [383](bibliography001.xhtml#endnote_383), [396](bibliography001.xhtml#endnote_396)]。开源项目OpenCilk
    ([www.opencilk.org](http://www.opencilk.org))将Cilk编程作为C和C++编程语言的扩展提供。本章中的所有并行算法都可以直接在Cilk中编码。
- en: Concerns about nondeterministic parallel programs were expressed by Lee [[281](bibliography001.xhtml#endnote_281)]
    and Bocchino, Adve, Adve, and Snir [[64](bibliography001.xhtml#endnote_64)]. The
    algorithms literature contains many algorithmic strategies (see, for example,
    [[60](bibliography001.xhtml#endnote_60), [85](bibliography001.xhtml#endnote_85),
    [118](bibliography001.xhtml#endnote_118), [140](bibliography001.xhtml#endnote_140),
    [160](bibliography001.xhtml#endnote_160), [282](bibliography001.xhtml#endnote_282),
    [283](bibliography001.xhtml#endnote_283), [412](bibliography001.xhtml#endnote_412),
    [461](bibliography001.xhtml#endnote_461)]) for detecting races and extending the
    fork-join model to avoid or safely embrace various kinds of nondeterminism. Blelloch,
    Fineman, Gibbons, and Shun [[59](bibliography001.xhtml#endnote_59)] showed that
    deterministic parallel algorithms can often be as fast as, or even faster than,
    their nondeterministic counterparts.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: Lee[[281](bibliography001.xhtml#endnote_281)]和Bocchino、Adve、Adve和Snir[[64](bibliography001.xhtml#endnote_64)]对于非确定性并行程序的担忧。算法文献中包含许多算法策略（参见，例如，[[60](bibliography001.xhtml#endnote_60),
    [85](bibliography001.xhtml#endnote_85), [118](bibliography001.xhtml#endnote_118),
    [140](bibliography001.xhtml#endnote_140), [160](bibliography001.xhtml#endnote_160),
    [282](bibliography001.xhtml#endnote_282), [283](bibliography001.xhtml#endnote_283),
    [412](bibliography001.xhtml#endnote_412), [461](bibliography001.xhtml#endnote_461)])用于检测竞争和扩展叉分模型以避免或安全地接受各种类型的非确定性。Blelloch、Fineman、Gibbons和Shun[[59](bibliography001.xhtml#endnote_59)]表明，确定性并行算法通常可以与其非确定性对应物一样快，甚至更快。
- en: Several of the parallel algorithms in this chapter appeared in unpublished lecture
    notes by C. E. Leiserson and H. Prokop and were originally implemented in Cilk.
    The parallel merge-sorting algorithm was inspired by an algorithm due to Akl [[12](bibliography001.xhtml#endnote_12)].
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的几个并行算法出现在C. E. Leiserson和H. Prokop的未发表讲义中，并最初在Cilk中实现。并行归并排序算法受到Akl的算法的启发[[12](bibliography001.xhtml#endnote_12)]。
- en: '[¹](#footnote_ref_1) In mathematics, a projection is an idempotent function,
    that is, a function *f* such that *f* ○ *f* = *f*. In this case, the function
    *f* maps the set P of fork-join programs to the set P[*S*] ⊂ P of serial programs,
    which are themselves fork-join programs with no parallelism. For a fork-join program
    *x* ∈ P, since we have *f* (*f* (*x*)) = *f* (*x*), the serial projection, as
    we have defined it, is indeed a mathematical projection.'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '[¹](#footnote_ref_1) 在数学中，投影是一个幂等函数，即一个函数*f*，使得*f* ○ *f* = *f*。在这种情况下，函数*f*将叉分程序集P映射到串行程序集P[*S*]
    ⊂ P，这些串行程序本身是没有并行性的叉分程序。对于叉分程序*x* ∈ P，由于我们有*f* (*f* (*x*)) = *f* (*x*)，因此，正如我们所定义的，串行投影确实是一个数学投影。'
- en: '[²](#footnote_ref_2) Also called a ***computation dag*** in the literature.'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '[²](#footnote_ref_2) 文献中也称为***计算dag***。'
