- en: '[**3          Characterizing Running Times**](toc.xhtml#chap-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The order of growth of the running time of an algorithm, defined in [Chapter
    2](chapter002.xhtml), gives a simple way to characterize the algorithm’s efficiency
    and also allows us to compare it with alternative algorithms. Once the input size
    *n* becomes large enough, merge sort, with its Θ(*n* lg *n*) worst-case running
    time, beats insertion sort, whose worst-case running time is Θ(*n*²). Although
    we can sometimes determine the exact running time of an algorithm, as we did for
    insertion sort in [Chapter 2](chapter002.xhtml), the extra precision is rarely
    worth the effort of computing it. For large enough inputs, the multiplicative
    constants and lower-order terms of an exact running time are dominated by the
    effects of the input size itself.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at input sizes large enough to make relevant only the order of
    growth of the running time, we are studying the ***asymptotic*** efficiency of
    algorithms. That is, we are concerned with how the running time of an algorithm
    increases with the size of the input *in the limit*, as the size of the input
    increases without bound. Usually, an algorithm that is asymptotically more efficient
    is the best choice for all but very small inputs.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter gives several standard methods for simplifying the asymptotic analysis
    of algorithms. The next section presents informally the three most commonly used
    types of “asymptotic notation,” of which we have already seen an example in Θ-notation.
    It also shows one way to use these asymptotic notations to reason about the worst-case
    running time of insertion sort. Then we look at asymptotic notations more formally
    and present several notational conventions used throughout this book. The last
    section reviews the behavior of functions that commonly arise when analyzing algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '[**3.1      *O*-notation, Ω-notation, and Θ-notation**](toc.xhtml#Rh1-11)'
  prefs: []
  type: TYPE_NORMAL
- en: When we analyzed the worst-case running time of insertion sort in [Chapter 2](chapter002.xhtml),
    we started with the complicated expression
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We then discarded the lower-order terms (*c*[1] + *c*[2] + *c*[4] + *c*[5]/2
    – *c*[6]/2 – *c*[7]/2 + *c*[8])*n* and *c*[2] + *c*[4] + *c*[5] + *c*[8], and
    we also ignored the coefficient *c*[5]/2 + *c*[6]/2 + *c*[7]/2 of *n*². That left
    just the factor *n*², which we put into Θ-notation as Θ(*n*²). We use this style
    to characterize running times of algorithms: discard the lower-order terms and
    the coefficient of the leading term, and use a notation that focuses on the rate
    of growth of the running time.'
  prefs: []
  type: TYPE_NORMAL
- en: Θ-notation is not the only such “asymptotic notation.” In this section, we’ll
    see other forms of asymptotic notation as well. We start with intuitive looks
    at these notations, revisiting insertion sort to see how we can apply them. In
    the next section, we’ll see the formal definitions of our asymptotic notations,
    along with conventions for using them.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get into specifics, bear in mind that the asymptotic notations we’ll
    see are designed so that they characterize functions in general. It so happens
    that the functions we are most interested in denote the running times of algorithms.
    But asymptotic notation can apply to functions that characterize some other aspect
    of algorithms (the amount of space they use, for example), or even to functions
    that have nothing whatsoever to do with algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '***O*-notation**'
  prefs: []
  type: TYPE_NORMAL
- en: '*O*-notation characterizes an *upper bound* on the asymptotic behavior of a
    function. In other words, it says that a function grows *no faster* than a certain
    rate, based on the highest-order term. Consider, for example, the function 7*n*³
    + 100*n*² – 20*n* + 6\. Its highest-order term is 7*n*³, and so we say that this
    function’s rate of growth is *n*³. Because this function grows no faster than
    *n*³, we can write that it is *O*(*n*³). You might be surprised that we can also
    write that the function 7*n*³ + 100*n*² – 20*n* + 6 is *O*(*n*⁴). Why? Because
    the function grows more slowly than *n*⁴, we are correct in saying that it grows
    no faster. As you might have guessed, this function is also *O*(*n*⁵), *O*(*n*⁶),
    and so on. More generally, it is *O*(*n^c*) for any constant *c* ≥ 3.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ω-notation**'
  prefs: []
  type: TYPE_NORMAL
- en: Ω-notation characterizes a *lower bound* on the asymptotic behavior of a function.
    In other words, it says that a function grows *at least as fast* as a certain
    rate, based — as in *O*-notation—on the highest-order term. Because the highest-order
    term in the function 7*n*³ + 100*n*² – 20*n* + 6 grows at least as fast as *n*³,
    this function is Ω(*n*³). This function is also Ω(*n*²) and Ω(*n*). More generally,
    it is Ω(*n^c*) for any constant *c* ≤ 3.
  prefs: []
  type: TYPE_NORMAL
- en: '**Θ-notation**'
  prefs: []
  type: TYPE_NORMAL
- en: Θ-notation characterizes a *tight bound* on the asymptotic behavior of a function.
    It says that a function grows *precisely* at a certain rate, based—once again—on
    the highest-order term. Put another way, Θ-notation characterizes the rate of
    growth of the function to within a constant factor from above and to within a
    constant factor from below. These two constant factors need not be equal.
  prefs: []
  type: TYPE_NORMAL
- en: If you can show that a function is both *O*(*f* (*n*)) and Ω(*f* (*n*)) for
    some function *f* (*n*), then you have shown that the function is Θ(*f* (*n*)).
    (The next section states this fact as a theorem.) For example, since the function
    7*n*³ + 100*n*² – 20*n* + 6 is both *O*(*n*³) and Ω(*n*³), it is also Θ(*n*³).
  prefs: []
  type: TYPE_NORMAL
- en: '**Example: Insertion sort**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s revisit insertion sort and see how to work with asymptotic notation to
    characterize its Θ(*n*²) worst-case running time without evaluating summations
    as we did in [Chapter 2](chapter002.xhtml). Here is the INSERTION-SORT procedure
    once again:'
  prefs: []
  type: TYPE_NORMAL
- en: INSERTION-SORT(*A*, *n*)
  prefs: []
  type: TYPE_NORMAL
- en: '| 1 | **for** *i* = 2 **to** *n* |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | *key* = *A*[*i*] |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | **//** Insert *A*[*i*] into the sorted subarray *A*[1 : *i* – 1]. |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | *j* = *i* – 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | **while** *j* > 0 and *A*[*j*] > *key* |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | *A*[*j* + 1] = *A*[*j*] |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | *j* = *j* – 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | *A*[*j* + 1] = *key* |'
  prefs: []
  type: TYPE_TB
- en: What can we observe about how the pseudocode operates? The procedure has nested
    loops. The outer loop is a **for** loop that runs *n* – 1 times, regardless of
    the values being sorted. The inner loop is a **while** loop, but the number of
    iterations it makes depends on the values being sorted. The loop variable *j*
    starts at *i* – 1 and decreases by 1 in each iteration until either it reaches
    0 or *A*[*j*] ≤ *key*. For a given value of *i*, the **while** loop might iterate
    0 times, *i* – 1 times, or anywhere in between. The body of the **while** loop
    (lines 6–7) takes constant time per iteration of the **while** loop.
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 3.1** The Ω(*n*²) lower bound for insertion sort. If the first *n*/3
    positions contain the *n*/3 largest values, each of these values must move through
    each of the middle *n*/3 positions, one position at a time, to end up somewhere
    in the last *n*/3 positions. Since each of *n*/3 values moves through at least
    each of *n*/3 positions, the time taken in this case is at least proportional
    to (*n*/3)(*n*/3) = *n*²/9, or Ω(*n*²).'
  prefs: []
  type: TYPE_NORMAL
- en: These observations suffice to deduce an *O*(*n*²) running time for any case
    of INSERTION-SORT, giving us a blanket statement that covers all inputs. The running
    time is dominated by the inner loop. Because each of the *n* – 1 iterations of
    the outer loop causes the inner loop to iterate at most *i* – 1 times, and because
    *i* is at most *n*, the total number of iterations of the inner loop is at most
    (*n* – 1)(*n* – 1), which is less than *n*². Since each iteration of the inner
    loop takes constant time, the total time spent in the inner loop is at most a
    constant times *n*², or *O*(*n*²).
  prefs: []
  type: TYPE_NORMAL
- en: With a little creativity, we can also see that the worst-case running time of
    INSERTION-SORT is Ω(*n*²). By saying that the worst-case running time of an algorithm
    is Ω(*n*²), we mean that for every input size *n* above a certain threshold, there
    is at least one input of size *n* for which the algorithm takes at least *cn*²
    time, for some positive constant *c*. It does not necessarily mean that the algorithm
    takes at least *cn*² time for all inputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now see why the worst-case running time of INSERTION-SORT is Ω(*n*²).
    For a value to end up to the right of where it started, it must have been moved
    in line 6\. In fact, for a value to end up *k* positions to the right of where
    it started, line 6 must have executed *k* times. As [Figure 3.1](chapter003.xhtml#Fig_3-1)
    shows, let’s assume that *n* is a multiple of 3 so that we can divide the array
    *A* into groups of *n*/3 positions. Suppose that in the input to INSERTION-SORT,
    the *n*/3 largest values occupy the first *n*/3 array positions *A*[1 : *n*/3].
    (It does not matter what relative order they have within the first *n*/3 positions.)
    Once the array has been sorted, each of these *n*/3 values ends up somewhere in
    the last *n*/3 positions *A*[2*n*/3 + 1 : *n*]. For that to happen, each of these
    *n*/3 values must pass through each of the middle *n*/3 positions *A*[*n*/3 +
    1 : 2*n*/3]. Each of these *n*/3 values passes through these middle *n*/3 positions
    one position at a time, by at least *n*/3 executions of line 6\. Because at least
    *n*/3 values have to pass through at least *n*/3 positions, the time taken by
    INSERTION-SORT in the worst case is at least proportional to (*n*/3)(*n*/3) =
    *n*²/9, which is Ω(*n*²).'
  prefs: []
  type: TYPE_NORMAL
- en: Because we have shown that INSERTION-SORT runs in *O*(*n*²) time in all cases
    and that there is an input that makes it take Ω(*n*²) time, we can conclude that
    the worst-case running time of INSERTION-SORT is Θ(*n*²). It does not matter that
    the constant factors for upper and lower bounds might differ. What matters is
    that we have characterized the worst-case running time to within constant factors
    (discounting lower-order terms). This argument does not show that INSERTION-SORT
    runs in Θ(*n*²) time in *all* cases. Indeed, we saw in [Chapter 2](chapter002.xhtml)
    that the best-case running time is Θ(*n*).
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs: []
  type: TYPE_NORMAL
- en: '***3.1-1***'
  prefs: []
  type: TYPE_NORMAL
- en: Modify the lower-bound argument for insertion sort to handle input sizes that
    are not necessarily a multiple of 3.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.1-2***'
  prefs: []
  type: TYPE_NORMAL
- en: Using reasoning similar to what we used for insertion sort, analyze the running
    time of the selection sort algorithm from Exercise 2.2-2.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.1-3***'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that *α* is a fraction in the range 0 < *α* < 1\. Show how to generalize
    the lower-bound argument for insertion sort to consider an input in which the
    *αn* largest values start in the first *αn* positions. What additional restriction
    do you need to put on *α*? What value of *α* maximizes the number of times that
    the *αn* largest values must pass through each of the middle (1 – 2*α*)*n* array
    positions?
  prefs: []
  type: TYPE_NORMAL
- en: '[**3.2      Asymptotic notation: formal definitions**](toc.xhtml#Rh1-12)'
  prefs: []
  type: TYPE_NORMAL
- en: Having seen asymptotic notation informally, let’s get more formal. The notations
    we use to describe the asymptotic running time of an algorithm are defined in
    terms of functions whose domains are typically the set N of natural numbers or
    the set R of real numbers. Such notations are convenient for describing a running-time
    function *T* (*n*). This section defines the basic asymptotic notations and also
    introduces some common “proper” notational abuses.
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 3.2** Graphic examples of the *O*, Ω, and Θ notations. In each part,
    the value of *n*[0] shown is the minimum possible value, but any greater value
    also works. **(a)** *O*-notation gives an upper bound for a function to within
    a constant factor. We write *f* (*n*) = *O*(*g*(*n*)) if there are positive constants
    *n*[0] and *c* such that at and to the right of *n*[0], the value of *f* (*n*)
    always lies on or below *cg*(*n*). **(b)** Ω-notation gives a lower bound for
    a function to within a constant factor. We write *f* (*n*) = Ω(*g*(*n*)) if there
    are positive constants *n*[0] and *c* such that at and to the right of *n*[0],
    the value of *f* (*n*) always lies on or above *cg*(*n*). **(c)** Θ-notation bounds
    a function to within constant factors. We write *f* (*n*) = Θ(*g*(*n*)) if there
    exist positive constants *n*[0], *c*[1], and *c*[2] such that at and to the right
    of *n*[0], the value of *f* (*n*) always lies between *c*[1]*g*(*n*) and *c*[2]*g*(*n*)
    inclusive.'
  prefs: []
  type: TYPE_NORMAL
- en: '***O*-notation**'
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in [Section 3.1](chapter003.xhtml#Sec_3.1), *O*-notation describes
    an ***asymptotic upper bound***. We use *O*-notation to give an upper bound on
    a function, to within a constant factor.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the formal definition of *O*-notation. For a given function *g*(*n*),
    we denote by *O*(*g*(*n*)) (pronounced “big-oh of *g* of *n*” or sometimes just
    “oh of *g* of *n*”) the *set of functions*
  prefs: []
  type: TYPE_NORMAL
- en: '| *O*(*g*(*n*)) = {*f* (*n*) |  :  | there exist positive constants *c* and
    *n*[0] such that 0 ≤ *f* (*n*) ≤ *cg*(*n*) for all *n* ≥ *n*[0]}.^([1](#footnote_1))
    |'
  prefs: []
  type: TYPE_TB
- en: A function *f* (*n*) belongs to the set *O*(*g*(*n*)) if there exists a positive
    constant *c* such that *f* (*n*) ≤ *cg*(*n*) for sufficiently large *n*. [Figure
    3.2(a)](chapter003.xhtml#Fig_3-2) shows the intuition behind *O*-notation. For
    all values *n* at and to the right of *n*[0], the value of the function *f* (*n*)
    is on or below *cg*(*n*).
  prefs: []
  type: TYPE_NORMAL
- en: 'The definition of *O*(*g*(*n*)) requires that every function *f* (*n*) in the
    set *O*(*g*(*n*)) be ***asymptotically nonnegative***: *f* (*n*) must be nonnegative
    whenever *n* is sufficiently large. (An ***asymptotically positive*** function
    is one that is positive for all sufficiently large *n*.) Consequently, the function
    *g*(*n*) itself must be asymptotically nonnegative, or else the set *O*(*g*(*n*))
    is empty. We therefore assume that every function used within *O*-notation is
    asymptotically nonnegative. This assumption holds for the other asymptotic notations
    defined in this chapter as well.'
  prefs: []
  type: TYPE_NORMAL
- en: You might be surprised that we define *O*-notation in terms of sets. Indeed,
    you might expect that we would write “*f* (*n*) ∈ *O*(*g*(*n*))” to indicate that
    *f* (*n*) belongs to the set *O*(*g*(*n*)). Instead, we usually write “*f* (*n*)
    = *O*(*g*(*n*))” and say “*f* (*n*) is big-oh of *g*(*n*)” to express the same
    notion. Although it may seem confusing at first to abuse equality in this way,
    we’ll see later in this section that doing so has its advantages.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore an example of how to use the formal definition of *O*-notation
    to justify our practice of discarding lower-order terms and ignoring the constant
    coefficient of the highest-order term. We’ll show that 4*n*² + 100*n* + 500 =
    *O*(*n*²), even though the lower-order terms have much larger coefficients than
    the leading term. We need to find positive constants *c* and *n*[0] such that
    4*n*² + 100*n* + 500 ≤ *cn*² for all *n* ≥ *n*[0]. Dividing both sides by *n*²
    gives 4 + 100/*n* + 500/*n*² ≤ *c*. This inequality is satisfied for many choices
    of *c* and *n*[0]. For example, if we choose *n*[0] = 1, then this inequality
    holds for *c* = 604\. If we choose *n*[0] = 10, then *c* = 19 works, and choosing
    *n*[0] = 100 allows us to use *c* = 5.05.
  prefs: []
  type: TYPE_NORMAL
- en: We can also use the formal definition of *O*-notation to show that the function
    *n*³ – 100*n*² does not belong to the set *O*(*n*²), even though the coefficient
    of *n*² is a large negative number. If we had *n*³ – 100*n*² = *O*(*n*²), then
    there would be positive constants *c* and *n*[0] such that *n*³ –100*n*² ≤ *cn*²
    for all *n* ≥ *n*[0]. Again, we divide both sides by *n*², giving *n* – 100 ≤
    *c*. Regardless of what value we choose for the constant *c*, this inequality
    does not hold for any value of *n* > *c* + 100.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ω-notation**'
  prefs: []
  type: TYPE_NORMAL
- en: Just as *O*-notation provides an asymptotic *upper* bound on a function, Ω-notation
    provides an ***asymptotic lower bound***. For a given function *g*(*n*), we denote
    by Ω(*g*(*n*)) (pronounced “big-omega of *g* of *n*” or sometimes just “omega
    of *g* of *n*”) the set of functions
  prefs: []
  type: TYPE_NORMAL
- en: '| Ω(*g*(*n*)) = {*f* (*n*) |  :  | there exist positive constants *c* and *n*[0]
    such that 0 ≤ *cg*(*n*) ≤ *f* (*n*) for all *n* ≥ *n*[0]}. |'
  prefs: []
  type: TYPE_TB
- en: '[Figure 3.2(b)](chapter003.xhtml#Fig_3-2) shows the intuition behind Ω-notation.
    For all values *n* at or to the right of *n*[0], the value of *f* (*n*) is on
    or above *cg*(*n*).'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve already shown that 4*n*² + 100*n* + 500 = *O*(*n*²). Now let’s show that
    4*n*² + 100*n* + 500 = Ω(*n*²). We need to find positive constants *c* and *n*[0]
    such that 4*n*² + 100*n* + 500 ≥ *cn*² for all *n* ≥ *n*[0]. As before, we divide
    both sides by *n*², giving 4 + 100/*n* + 500/*n*² ≥ *c*. This inequality holds
    when *n*[0] is any positive integer and *c* = 4.
  prefs: []
  type: TYPE_NORMAL
- en: What if we had subtracted the lower-order terms from the 4*n*² term instead
    of adding them? What if we had a small coefficient for the *n*² term? The function
    would still be Ω(*n*²). For example, let’s show that *n*²/100 – 100*n* – 500 =
    Ω(*n*²). Dividing by *n*² gives 1/100 – 100/*n* – 500/*n*² ≥ *c*. We can choose
    any value for *n*[0] that is at least 10,005 and find a positive value for *c*.
    For example, when *n*[0] = 10,005, we can choose *c* = 2.49 × 10^(–9). Yes, that’s
    a tiny value for *c*, but it is positive. If we select a larger value for *n*[0],
    we can also increase *c*. For example, if *n*[0] = 100,000, then we can choose
    *c* = 0.0089\. The higher the value of *n*[0], the closer to the coefficient 1/100
    we can choose *c*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Θ-notation**'
  prefs: []
  type: TYPE_NORMAL
- en: We use Θ-notation for ***asymptotically tight bounds***. For a given function
    *g*(*n*), we denote by Θ(*g*(*n*)) (“theta of *g* of *n*”) the set of functions
  prefs: []
  type: TYPE_NORMAL
- en: '| Θ(*g*(*n*)) = {*f* (*n*) |  :  | there exist positive constants *c*[1], *c*[2],
    and *n*[0] such that 0 ≤ *c*[1]*g*(*n*) ≤ *f* (*n*) ≤ *c*[2]*g*(*n*) for all *n*
    ≥ *n*[0]}. |'
  prefs: []
  type: TYPE_TB
- en: '[Figure 3.2(c)](chapter003.xhtml#Fig_3-2) shows the intuition behind Θ-notation.
    For all values of *n* at and to the right of *n*[0], the value of *f* (*n*) lies
    at or above *c*[1]*g*(*n*) and at or below *c*[2]*g*(*n*). In other words, for
    all *n* ≥ *n*[0], the function *f* (*n*) is equal to *g*(*n*) to within constant
    factors.'
  prefs: []
  type: TYPE_NORMAL
- en: The definitions of *O*-, Ω-, and Θ-notations lead to the following theorem,
    whose proof we leave as Exercise 3.2-4.
  prefs: []
  type: TYPE_NORMAL
- en: '***Theorem 3.1***'
  prefs: []
  type: TYPE_NORMAL
- en: For any two functions *f* (*n*) and *g*(*n*), we have *f* (*n*) = Θ(*g*(*n*))
    if and only if *f* (*n*) = *O*(*g*(*n*)) and *f* (*n*) = Ω(*g*(*n*)).
  prefs: []
  type: TYPE_NORMAL
- en: ▪
  prefs: []
  type: TYPE_NORMAL
- en: We typically apply Theorem 3.1 to prove asymptotically tight bounds from asymptotic
    upper and lower bounds.
  prefs: []
  type: TYPE_NORMAL
- en: '**Asymptotic notation and running times**'
  prefs: []
  type: TYPE_NORMAL
- en: When you use asymptotic notation to characterize an algorithm’s running time,
    make sure that the asymptotic notation you use is as precise as possible without
    overstating which running time it applies to. Here are some examples of using
    asymptotic notation properly and improperly to characterize running times.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with insertion sort. We can correctly say that insertion sort’s
    worst-case running time is *O*(*n*²), Ω(*n*²), and—due to Theorem 3.1—Θ(*n*²).
    Although all three ways to characterize the worst-case running times are correct,
    the Θ(*n*²) bound is the most precise and hence the most preferred. We can also
    correctly say that insertion sort’s best-case running time is *O*(*n*), Ω(*n*),
    and Θ(*n*), again with Θ(*n*) the most precise and therefore the most preferred.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what we *cannot* correctly say: insertion sort’s running time is Θ(*n*²).
    That is an overstatement because by omitting “worst-case” from the statement,
    we’re left with a blanket statement covering all cases. The error here is that
    insertion sort does not run in Θ(*n*²) time in all cases since, as we’ve seen,
    it runs in Θ(*n*) time in the best case. We can correctly say that insertion sort’s
    running time is *O*(*n*²), however, because in all cases, its running time grows
    no faster than *n*². When we say *O*(*n*²) instead of Θ(*n*²), there is no problem
    in having cases whose running time grows more slowly than *n*². Likewise, we cannot
    correctly say that insertion sort’s running time is Θ(*n*), but we can say that
    its running time is Ω(*n*).'
  prefs: []
  type: TYPE_NORMAL
- en: How about merge sort? Since merge sort runs in Θ(*n* lg *n*) time in all cases,
    we can just say that its running time is Θ(*n* lg *n*) without specifying worst-case,
    best-case, or any other case.
  prefs: []
  type: TYPE_NORMAL
- en: People occasionally conflate *O*-notation with Θ-notation by mistakenly using
    *O*-notation to indicate an asymptotically tight bound. They say things like “an
    *O*(*n* lg *n*)-time algorithm runs faster than an *O*(*n*²)-time algorithm.”
    Maybe it does, maybe it doesn’t. Since *O*-notation denotes only an asymptotic
    upper bound, that so-called *O*(*n*²)-time algorithm might actually run in Θ(*n*)
    time. You should be careful to choose the appropriate asymptotic notation. If
    you want to indicate an asymptotically tight bound, use Θ-notation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We typically use asymptotic notation to provide the simplest and most precise
    bounds possible. For example, if an algorithm has a running time of 3*n*² + 20*n*
    in all cases, we use asymptotic notation to write that its running time is Θ(*n*²).
    Strictly speaking, we are also correct in writing that the running time is *O*(*n*³)
    or Θ(3*n*² + 20*n*). Neither of these expressions is as useful as writing Θ(*n*²)
    in this case, however: *O*(*n*³) is less precise than Θ(*n*²) if the running time
    is 3*n*² + 20*n*, and Θ(3*n*² + 20*n*) introduces complexity that obscures the
    order of growth. By writing the simplest and most precise bound, such as Θ(*n*²),
    we can categorize and compare different algorithms. Throughout the book, you will
    see asymptotic running times that are almost always based on polynomials and logarithms:
    functions such as *n*, *n* lg² *n*, *n*² lg *n*, or *n*^(1/2). You will also see
    some other functions, such as exponentials, lg lg *n*, and lg^**n* (see [Section
    3.3](chapter003.xhtml#Sec_3.3)). It is usually fairly easy to compare the rates
    of growth of these functions. Problem 3-3 gives you good practice.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Asymptotic notation in equations and inequalities**'
  prefs: []
  type: TYPE_NORMAL
- en: Although we formally define asymptotic notation in terms of sets, we use the
    equal sign (=) instead of the set membership sign (∈) within formulas. For example,
    we wrote that 4*n*² + 100*n* + 500 = *O*(*n*²). We might also write 2*n*² + 3*n*
    + 1 = 2*n*² + Θ(*n*). How do we interpret such formulas?
  prefs: []
  type: TYPE_NORMAL
- en: 'When the asymptotic notation stands alone (that is, not within a larger formula)
    on the right-hand side of an equation (or inequality), as in 4*n*² + 100*n* +
    500 = *O*(*n*²), the equal sign means set membership: 4*n*² + 100*n* + 500 ∈ *O*(*n*²).
    In general, however, when asymptotic notation appears in a formula, we interpret
    it as standing for some anonymous function that we do not care to name. For example,
    the formula 2*n*² + 3*n* + 1 = 2*n*² + Θ(*n*) means that 2*n*² + 3*n* + 1 = 2*n*²
    + *f* (*n*), where *f* (*n*) ∈ Θ(*n*). In this case, we let *f* (*n*) = 3*n* +
    1, which indeed belongs to Θ(*n*).'
  prefs: []
  type: TYPE_NORMAL
- en: Using asymptotic notation in this manner can help eliminate inessential detail
    and clutter in an equation. For example, in [Chapter 2](chapter002.xhtml) we expressed
    the worst-case running time of merge sort as the recurrence
  prefs: []
  type: TYPE_NORMAL
- en: '*T* (*n*) = 2*T* (*n*/2) + Θ(*n*).'
  prefs: []
  type: TYPE_NORMAL
- en: If we are interested only in the asymptotic behavior of *T* (*n*), there is
    no point in specifying all the lower-order terms exactly, because they are all
    understood to be included in the anonymous function denoted by the term Θ(*n*).
  prefs: []
  type: TYPE_NORMAL
- en: The number of anonymous functions in an expression is understood to be equal
    to the number of times the asymptotic notation appears. For example, in the expression
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: there is only a single anonymous function (a function of *i*). This expression
    is thus *not* the same as *O*(1) + *O*(2) + ⋯ + *O*(*n*), which doesn’t really
    have a clean interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, asymptotic notation appears on the left-hand side of an equation,
    as in
  prefs: []
  type: TYPE_NORMAL
- en: 2*n*² + Θ(*n*) = Θ(*n*²).
  prefs: []
  type: TYPE_NORMAL
- en: 'Interpret such equations using the following rule: *No matter how the anonymous
    functions are chosen on the left of the equal sign, there is a way to choose the
    anonymous functions on the right of the equal sign to make the equation valid*.
    Thus, our example means that for *any* function *f* (*n*) ∈ Θ(*n*), there is *some*
    function *g*(*n*) ∈ Θ(*n*²) such that 2*n*² + *f* (*n*) = *g*(*n*) for all *n*.
    In other words, the right-hand side of an equation provides a coarser level of
    detail than the left-hand side.'
  prefs: []
  type: TYPE_NORMAL
- en: We can chain together a number of such relationships, as in
  prefs: []
  type: TYPE_NORMAL
- en: '| 2*n*² + 3*n* + 1 |  =  | 2*n*² + Θ(*n*) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  =  | Θ(*n*²). |'
  prefs: []
  type: TYPE_TB
- en: By the rules above, interpret each equation separately. The first equation says
    that there is *some* function *f* (*n*) ∈ Θ(*n*) such that 2*n*² + 3*n* + 1 =
    2*n*² + *f* (*n*) for all *n*. The second equation says that for *any* function
    *g*(*n*) ∈ Θ(*n*) (such as the *f* (*n*) just mentioned), there is *some* function
    *h*(*n*) ∈ Θ(*n*²) such that 2*n*² + *g*(*n*) = *h*(*n*) for all *n*. This interpretation
    implies that 2*n*² + 3*n* + 1 = Θ(*n*²), which is what the chaining of equations
    intuitively says.
  prefs: []
  type: TYPE_NORMAL
- en: '**Proper abuses of asymptotic notation**'
  prefs: []
  type: TYPE_NORMAL
- en: Besides the abuse of equality to mean set membership, which we now see has a
    precise mathematical interpretation, another abuse of asymptotic notation occurs
    when the variable tending toward ∞ must be inferred from context. For example,
    when we say *O*(*g*(*n*)), we can assume that we’re interested in the growth of
    *g*(*n*) as *n* grows, and if we say *O*(*g*(*m*)) we’re talking about the growth
    of *g*(*m*) as *m* grows. The free variable in the expression indicates what variable
    is going to ∞.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most common situation requiring contextual knowledge of which variable
    tends to ∞ occurs when the function inside the asymptotic notation is a constant,
    as in the expression *O*(1). We cannot infer from the expression which variable
    is going to ∞, because no variable appears there. The context must disambiguate.
    For example, if the equation using asymptotic notation is *f* (*n*) = *O*(1),
    it’s apparent that the variable we’re interested in is *n*. Knowing from context
    that the variable of interest is *n*, however, allows us to make perfect sense
    of the expression by using the formal definition of *O*-notation: the expression
    *f* (*n*) = *O*(1) means that the function *f* (*n*) is bounded from above by
    a constant as *n* goes to ∞. Technically, it might be less ambiguous if we explicitly
    indicated the variable tending to ∞ in the asymptotic notation itself, but that
    would clutter the notation. Instead, we simply ensure that the context makes it
    clear which variable (or variables) tend to ∞.'
  prefs: []
  type: TYPE_NORMAL
- en: When the function inside the asymptotic notation is bounded by a positive constant,
    as in *T* (*n*) = *O*(1), we often abuse asymptotic notation in yet another way,
    especially when stating recurrences. We may write something like *T* (*n*) = *O*(1)
    for *n* < 3\. According to the formal definition of *O*-notation, this statement
    is meaningless, because the definition only says that *T* (*n*) is bounded above
    by a positive constant *c* for *n* ≥ *n*[0] for some *n*[0] > 0\. The value of
    *T* (*n*) for *n* < *n*[0] need not be so bounded. Thus, in the example *T* (*n*)
    = *O*(1) for *n* < 3, we cannot infer any constraint on *T* (*n*) when *n* < 3,
    because it might be that *n*[0] > 3.
  prefs: []
  type: TYPE_NORMAL
- en: What is conventionally meant when we say *T* (*n*) = *O*(1) for *n* < 3 is that
    there exists a positive constant *c* such that *T* (*n*) ≤ *c* for *n* < 3\. This
    convention saves us the trouble of naming the bounding constant, allowing it to
    remain anonymous while we focus on more important variables in an analysis. Similar
    abuses occur with the other asymptotic notations. For example, *T* (*n*) = Θ(1)
    for *n* < 3 means that *T* (*n*) is bounded above and below by positive constants
    when *n* < 3.
  prefs: []
  type: TYPE_NORMAL
- en: Occasionally, the function describing an algorithm’s running time may not be
    defined for certain input sizes, for example, when an algorithm assumes that the
    input size is an exact power of 2\. We still use asymptotic notation to describe
    the growth of the running time, understanding that any constraints apply only
    when the function is defined. For example, suppose that *f* (*n*) is defined only
    on a subset of the natural or nonnegative real numbers. Then *f* (*n*) = *O*(*g*(*n*))
    means that the bound 0 ≤ *T* (*n*) ≤ *cg*(*n*) in the definition of *O*-notation
    holds for all *n* ≥ *n*[0] over the domain of *f* (*n*), that is, where *f* (*n*)
    is defined. This abuse is rarely pointed out, since what is meant is generally
    clear from context.
  prefs: []
  type: TYPE_NORMAL
- en: In mathematics, it’s okay — and often desirable — to abuse a notation, as long
    as we don’t misuse it. If we understand precisely what is meant by the abuse and
    don’t draw incorrect conclusions, it can simplify our mathematical language, contribute
    to our higher-level understanding, and help us focus on what really matters.
  prefs: []
  type: TYPE_NORMAL
- en: '***o*-notation**'
  prefs: []
  type: TYPE_NORMAL
- en: The asymptotic upper bound provided by *O*-notation may or may not be asymptotically
    tight. The bound 2*n*² = *O*(*n*²) is asymptotically tight, but the bound 2*n*
    = *O*(*n*²) is not. We use *o*-notation to denote an upper bound that is not asymptotically
    tight. We formally define *o*(*g*(*n*)) (“little-oh of *g* of *n*”) as the set
  prefs: []
  type: TYPE_NORMAL
- en: '| *o*(*g*(*n*)) = {*f* (*n*) |  :  | for any positive constant *c* > 0, there
    exists a constant *n*[0] > 0 such that 0 ≤ *f* (*n*) < *cg*(*n*) for all *n* ≥
    *n*[0]}. |'
  prefs: []
  type: TYPE_TB
- en: For example, 2*n* = *o*(*n*²), but 2*n*² ≠ *o*(*n*²).
  prefs: []
  type: TYPE_NORMAL
- en: 'The definitions of *O*-notation and *o*-notation are similar. The main difference
    is that in *f* (*n*) = *O*(*g*(*n*)), the bound 0 ≤ *f* (*n*) ≤ *cg*(*n*) holds
    for *some* constant *c* > 0, but in *f* (*n*) = *o*(*g*(*n*)), the bound 0 ≤ *f*
    (*n*) < *cg*(*n*) holds for *all* constants *c* > 0\. Intuitively, in *o*-notation,
    the function *f* (*n*) becomes insignificant relative to *g*(*n*) as *n* gets
    large:'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Some authors use this limit as a definition of the *o*-notation, but the definition
    in this book also restricts the anonymous functions to be asymptotically nonnegative.
  prefs: []
  type: TYPE_NORMAL
- en: '***ω*-notation**'
  prefs: []
  type: TYPE_NORMAL
- en: By analogy, *ω*-notation is to Ω-notation as *o*-notation is to *O*-notation.
    We use *ω*-notation to denote a lower bound that is not asymptotically tight.
    One way to define it is by
  prefs: []
  type: TYPE_NORMAL
- en: '*f* (*n*) ∈ *ω*(*g*(*n*)) if and only if *g*(*n*) ∈ *o*(*f* (*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: Formally, however, we define *ω*(*g*(*n*)) (“little-omega of *g* of *n*”) as
    the set
  prefs: []
  type: TYPE_NORMAL
- en: '| *ω*(*g*(*n*)) = {*f* (*n*) |  :  | for any positive constant *c* > 0, there
    exists a constant *n*[0] > 0 such that 0 ≤ *cg*(*n*) < *f* (*n*) for all *n* ≥
    *n*[0]}. |'
  prefs: []
  type: TYPE_TB
- en: 'Where the definition of *o*-notation says that *f* (*n*) < *cg*(*n*), the definition
    of *ω*-notation says the opposite: that *cg*(*n*) < *f* (*n*). For examples of
    *ω*-notation, we have *n*²/2 = *ω*(*n*), but *n*²/2 ≠ *ω*(*n*²). The relation
    *f* (*n*) = *ω*(*g*(*n*)) implies that'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: if the limit exists. That is, *f* (*n*) becomes arbitrarily large relative to
    *g*(*n*) as *n* gets large.
  prefs: []
  type: TYPE_NORMAL
- en: '**Comparing functions**'
  prefs: []
  type: TYPE_NORMAL
- en: Many of the relational properties of real numbers apply to asymptotic comparisons
    as well. For the following, assume that *f* (*n*) and *g*(*n*) are asymptotically
    positive.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transitivity:**'
  prefs: []
  type: TYPE_NORMAL
- en: '| *f* (*n*) = Θ(*g*(*n*)) | and | *g*(*n*) = Θ(*h*(*n*)) | imply | *f* (*n*)
    = Θ(*h*(*n*)), |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = *O*(*g*(*n*)) | and | *g*(*n*) = *O*(*h*(*n*)) | imply | *f*
    (*n*) = *O*(*h*(*n*)), |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = Ω(*g*(*n*)) | and | *g*(*n*) = Ω(*h*(*n*)) | imply | *f* (*n*)
    = Ω(*h*(*n*)), |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = *o*(*g*(*n*)) | and | *g*(*n*) = *o*(*h*(*n*)) | imply | *f*
    (*n*) = *o*(*h*(*n*)), |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = *ω*(*g*(*n*)) | and | *g*(*n*) = *ω*(*h*(*n*)) | imply | *f*
    (*n*) = *ω*(*h*(*n*)). |'
  prefs: []
  type: TYPE_TB
- en: '**Reflexivity:**'
  prefs: []
  type: TYPE_NORMAL
- en: '| *f* (*n*) = Θ(*f* (*n*)), |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = *O*(*f* (*n*)), |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = Ω(*f* (*n*)). |'
  prefs: []
  type: TYPE_TB
- en: '**Symmetry:**'
  prefs: []
  type: TYPE_NORMAL
- en: '*f* (*n*) = Θ(*g*(*n*)) if and only if *g*(*n*) = Θ(*f* (*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transpose symmetry:**'
  prefs: []
  type: TYPE_NORMAL
- en: '| *f* (*n*) = *O*(*g*(*n*)) | if and only if | *g*(*n*) = Ω(*f* (*n*)), |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = *o*(*g*(*n*)) | if and only if | *g*(*n*) = *ω*(*f* (*n*)). |'
  prefs: []
  type: TYPE_TB
- en: 'Because these properties hold for asymptotic notations, we can draw an analogy
    between the asymptotic comparison of two functions *f* and *g* and the comparison
    of two real numbers *a* and *b*:'
  prefs: []
  type: TYPE_NORMAL
- en: '| *f* (*n*) = *O*(*g*(*n*)) | is like | *a* ≤ *b*, |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = Ω(*g*(*n*)) | is like | *a* ≥ *b*, |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = Θ(*g*(*n*)) | is like | *a* = *b*, |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = *o*(*g*(*n*)) | is like | *a* < *b*, |'
  prefs: []
  type: TYPE_TB
- en: '| *f* (*n*) = *ω*(*g*(*n*)) | is like | *a* > *b*. |'
  prefs: []
  type: TYPE_TB
- en: We say that *f* (*n*) is ***asymptotically smaller*** than *g*(*n*) if *f* (*n*)
    = *o*(*g*(*n*)), and *f* (*n*) is ***asymptotically larger*** than *g*(*n*) if
    *f* (*n*) = *ω*(*g*(*n*)).
  prefs: []
  type: TYPE_NORMAL
- en: 'One property of real numbers, however, does not carry over to asymptotic notation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trichotomy:** For any two real numbers *a* and *b*, exactly one of the following
    must hold: *a* < *b*, *a* = *b*, or *a* > *b*.'
  prefs: []
  type: TYPE_NORMAL
- en: Although any two real numbers can be compared, not all functions are asymptotically
    comparable. That is, for two functions *f* (*n*) and *g*(*n*), it may be the case
    that neither *f* (*n*) = *O*(*g*(*n*)) nor *f* (*n*) = Ω(*g*(*n*)) holds. For
    example, we cannot compare the functions *n* and *n*^(1 + sin *n*) using asymptotic
    notation, since the value of the exponent in *n*^(1 + sin *n*) oscillates between
    0 and 2, taking on all values in between.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2-1***'
  prefs: []
  type: TYPE_NORMAL
- en: Let *f* (*n*) and *g*(*n*) be asymptotically nonnegative functions. Using the
    basic definition of Θ-notation, prove that max {*f* (*n*), *g*(*n*)} = Θ(*f* (*n*)
    + *g*(*n*)).
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2-2***'
  prefs: []
  type: TYPE_NORMAL
- en: Explain why the statement, “The running time of algorithm *A* is at least *O*(*n*²),”
    is meaningless.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2-3***'
  prefs: []
  type: TYPE_NORMAL
- en: Is 2^(*n* + 1) = *O*(2*^n*)? Is 2^(2*n*) = *O*(2*^n*)?
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2-4***'
  prefs: []
  type: TYPE_NORMAL
- en: Prove Theorem 3.1.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2-5***'
  prefs: []
  type: TYPE_NORMAL
- en: Prove that the running time of an algorithm is Θ(*g*(*n*)) if and only if its
    worst-case running time is *O*(*g*(*n*)) and its best-case running time is Ω(*g*(*n*)).
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2-6***'
  prefs: []
  type: TYPE_NORMAL
- en: Prove that *o*(*g*(*n*)) ∩ *ω*(*g*(*n*)) is the empty set.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.2-7***'
  prefs: []
  type: TYPE_NORMAL
- en: We can extend our notation to the case of two parameters *n* and *m* that can
    go to ∞ independently at different rates. For a given function *g*(*n*, *m*),
    we denote by *O*(*g*(*n*, *m*)) the set of functions
  prefs: []
  type: TYPE_NORMAL
- en: '| *O*(*g*(*n*, *m*)) = {*f* (*n*, *m*) |  :  | there exist positive constants
    *c*, *n*[0], and *m*[0] such that 0 ≤ *f* (*n*, *m*) ≤ *cg*(*n*, *m*) for all
    *n* ≥ *n*[0] or *m* ≥ *m*[0]}. |'
  prefs: []
  type: TYPE_TB
- en: Give corresponding definitions for Ω(*g*(*n*, *m*)) and Θ(*g*(*n*, *m*)).
  prefs: []
  type: TYPE_NORMAL
- en: '[**3.3      Standard notations and common functions**](toc.xhtml#Rh1-13)'
  prefs: []
  type: TYPE_NORMAL
- en: This section reviews some standard mathematical functions and notations and
    explores the relationships among them. It also illustrates the use of the asymptotic
    notations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Monotonicity**'
  prefs: []
  type: TYPE_NORMAL
- en: A function *f* (*n*) is ***monotonically increasing*** if *m* ≤ *n* implies
    *f* (*m*) ≤ *f* (*n*). Similarly, it is ***monotonically decreasing*** if *m*
    ≤ *n* implies *f* (*m*) ≥ *f* (*n*). A function *f* (*n*) is ***strictly increasing***
    if *m* < *n* implies *f* (*m*) < *f* (*n*) and ***strictly decreasing*** if *m*
    < *n* implies *f* (*m*) > *f* (*n*).
  prefs: []
  type: TYPE_NORMAL
- en: '**Floors and ceilings**'
  prefs: []
  type: TYPE_NORMAL
- en: For any real number *x*, we denote the greatest integer less than or equal to
    *x* by ⌊*x*⌋ (read “the floor of *x*”) and the least integer greater than or equal
    to *x* by ⌈*x*⌉ (read “the ceiling of *x*”). The floor function is monotonically
    increasing, as is the ceiling function.
  prefs: []
  type: TYPE_NORMAL
- en: Floors and ceilings obey the following properties. For any integer *n*, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For all real *x*, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We also have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: or equivalently,
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For any real number *x* ≥ 0 and integers *a*, *b* > 0, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For any integer *n* and real number *x*, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Modular arithmetic**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For any integer *a* and any positive integer *n*, the value *a* mod *n* is
    the ***remainder*** (or ***residue***) of the quotient *a*/*n*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It follows that
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P46.jpg)'
  prefs: []
  type: TYPE_IMG
- en: even when *a* is negative.
  prefs: []
  type: TYPE_NORMAL
- en: Given a well-defined notion of the remainder of one integer when divided by
    another, it is convenient to provide special notation to indicate equality of
    remainders. If (*a* mod *n*) = (*b* mod *n*), we write *a* = *b* (mod *n*) and
    say that *a* is ***equivalent*** to *b*, modulo *n*. In other words, *a* = *b*
    (mod *n*) if *a* and *b* have the same remainder when divided by *n*. Equivalently,
    *a* = *b* (mod *n*) if and only if *n* is a divisor of *b* – *a*. We write *a*
    ≠ *b* (mod *n*) if *a* is not equivalent to *b*, modulo *n*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Polynomials**'
  prefs: []
  type: TYPE_NORMAL
- en: Given a nonnegative integer *d*, a ***polynomial in n of degree d*** is a function
    *p*(*n*) of the form
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where the constants *a*[0], *a*[1], … , *a[d]* are the ***coefficients*** of
    the polynomial and *a[d]* ≠ 0\. A polynomial is asymptotically positive if and
    only if *a[d]* > 0\. For an asymptotically positive polynomial *p*(*n*) of degree
    *d*, we have *p*(*n*) = Θ(*n^d*). For any real constant *a* ≥ 0, the function
    *n^a* is monotonically increasing, and for any real constant *a* ≤ 0, the function
    *n^a* is monotonically decreasing. We say that a function *f* (*n*) is ***polynomially
    bounded*** if *f* (*n*) = *O*(*n^k*) for some constant *k*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exponentials**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For all real *a* > 0, *m*, and *n*, we have the following identities:'
  prefs: []
  type: TYPE_NORMAL
- en: '| *a*⁰ | = | 1, |'
  prefs: []
  type: TYPE_TB
- en: '| *a*¹ | = | *a*, |'
  prefs: []
  type: TYPE_TB
- en: '| *a*^(–1) | = | 1/*a*, |'
  prefs: []
  type: TYPE_TB
- en: '| (*a^m*)^(*n*) | = | *a^(mn)*, |'
  prefs: []
  type: TYPE_TB
- en: '| (*a^m*)^(*n*) | = | (*a^n*)*^m*, |'
  prefs: []
  type: TYPE_TB
- en: '| *a^ma^n* | = | *a*^(*m*+*n*). |'
  prefs: []
  type: TYPE_TB
- en: For all *n* and *a* ≥ 1, the function *a^n* is monotonically increasing in *n*.
    When convenient, we assume that 0⁰ = 1.
  prefs: []
  type: TYPE_NORMAL
- en: We can relate the rates of growth of polynomials and exponentials by the following
    fact. For all real constants *a* > 1 and *b*, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P48.jpg)'
  prefs: []
  type: TYPE_IMG
- en: from which we can conclude that
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P49.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, any exponential function with a base strictly greater than 1 grows faster
    than any polynomial function.
  prefs: []
  type: TYPE_NORMAL
- en: Using *e* to denote 2.71828 …, the base of the natural-logarithm function, we
    have for all real *x*,
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P50.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where “!” denotes the factorial function defined later in this section. For
    all real *x*, we have the inequality
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P51.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where equality holds only when *x* = 0\. When |*x*| ≤ 1, we have the approximation
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P52.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When *x* → 0, the approximation of *e^x* by 1 + *x* is quite good:'
  prefs: []
  type: TYPE_NORMAL
- en: '*e^x* = 1 + *x* + Θ(*x*²).'
  prefs: []
  type: TYPE_NORMAL
- en: (In this equation, the asymptotic notation is used to describe the limiting
    behavior as *x* → 0 rather than as *x* → ∞.) We have for all *x*,
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P53.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Logarithms**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the following notations:'
  prefs: []
  type: TYPE_NORMAL
- en: '| lg *n* | = | log[2] *n* | (binary logarithm), |'
  prefs: []
  type: TYPE_TB
- en: '| ln *n* | = | log[*e*] *n* | (natural logarithm), |'
  prefs: []
  type: TYPE_TB
- en: '| lg^(*k*) *n* | = | (lg *n*)*^k* | (exponentiation), |'
  prefs: []
  type: TYPE_TB
- en: '| lg lg *n* | = | lg(lg *n*) | (composition). |'
  prefs: []
  type: TYPE_TB
- en: 'We adopt the following notational convention: in the absence of parentheses,
    *a logarithm function applies only to the next term in the formula*, so that lg
    *n* + 1 means (lg *n*) + 1 and not lg(*n* + 1).'
  prefs: []
  type: TYPE_NORMAL
- en: For any constant *b* > 1, the function log*[b] n* is undefined if *n* ≤ 0, strictly
    increasing if *n* > 0, negative if 0 < *n* < 1, positive if *n* > 1, and 0 if
    *n* = 1\. For all real *a* > 0, *b* > 0, *c* > 0, and *n*, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P54.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where, in each equation above, logarithm bases are not 1.
  prefs: []
  type: TYPE_NORMAL
- en: By equation (3.19), changing the base of a logarithm from one constant to another
    changes the value of the logarithm by only a constant factor. Consequently, we
    often use the notation “lg *n*” when we don’t care about constant factors, such
    as in *O*-notation. Computer scientists find 2 to be the most natural base for
    logarithms because so many algorithms and data structures involve splitting a
    problem into two parts.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a simple series expansion for ln(1 + *x*) when |*x*| < 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P55.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We also have the following inequalities for *x* > – 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P56.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where equality holds only for *x* = 0.
  prefs: []
  type: TYPE_NORMAL
- en: We say that a function *f* (*n*) is ***polylogarithmically bounded*** if *f*
    (*n*) = *O*(lg*^k n*) for some constant *k*. We can relate the growth of polynomials
    and polylogarithms by substituting lg *n* for *n* and 2*^a* for *a* in equation
    (3.13). For all real constants *a* > 0 and *b*, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P57.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, any positive polynomial function grows faster than any polylogarithmic
    function.
  prefs: []
  type: TYPE_NORMAL
- en: '**Factorials**'
  prefs: []
  type: TYPE_NORMAL
- en: The notation *n*! (read “*n* factorial”) is defined for integers *n* ≥ 0 as
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P58.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, *n*! = 1 · 2 · 3 ⋯ *n*.
  prefs: []
  type: TYPE_NORMAL
- en: A weak upper bound on the factorial function is *n*! ≤ *n^n*, since each of
    the *n* terms in the factorial product is at most *n*. ***Stirling’s approximation***,
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P59.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *e* is the base of the natural logarithm, gives us a tighter upper bound,
    and a lower bound as well. Exercise 3.3-4 asks you to prove the three facts
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P60.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'where Stirling’s approximation is helpful in proving equation (3.28). The following
    equation also holds for all *n* ≥ 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P61.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P62.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**Functional iteration**'
  prefs: []
  type: TYPE_NORMAL
- en: We use the notation *f*^((*i*)) (*n*) to denote the function *f* (*n*) iteratively
    applied *i* times to an initial value of *n*. Formally, let *f* (*n*) be a function
    over the reals. For nonnegative integers *i*, we recursively define
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P63.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For example, if *f* (*n*) = 2*n*, then *f*^((*i*)) (*n*) = 2*^in*.
  prefs: []
  type: TYPE_NORMAL
- en: '**The iterated logarithm function**'
  prefs: []
  type: TYPE_NORMAL
- en: We use the notation lg^**n* (read “log star of *n*”) to denote the iterated
    logarithm, defined as follows. Let lg^((*i*)) *n* be as defined above, with *f*
    (*n*) = lg *n*. Because the logarithm of a nonpositive number is undefined, lg*^((i))
    n* is defined only if lg^((*i*–1)) *n* > 0\. Be sure to distinguish lg^((*i*)) *n*
    (the logarithm function applied *i* times in succession, starting with argument
    *n*) from lg*^i n* (the logarithm of *n* raised to the *i*th power). Then we define
    the iterated logarithm function as
  prefs: []
  type: TYPE_NORMAL
- en: 'lg^**n* = min {*i* ≥ 0 : lg^((*i*)) *n* ≤ 1}.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The iterated logarithm is a *very* slowly growing function:'
  prefs: []
  type: TYPE_NORMAL
- en: '| lg^* 2 | = | 1, |'
  prefs: []
  type: TYPE_TB
- en: '| lg^* 4 | = | 2, |'
  prefs: []
  type: TYPE_TB
- en: '| lg^* 16 | = | 3, |'
  prefs: []
  type: TYPE_TB
- en: '| lg^* 65536 | = | 4, |'
  prefs: []
  type: TYPE_TB
- en: '| lg^* (2^(65536)) | = | 5. |'
  prefs: []
  type: TYPE_TB
- en: Since the number of atoms in the observable universe is estimated to be about
    10^(80), which is much less than 2^(65536) = 10^(65536/lg 10) ≈ 10^(19,728), we
    rarely encounter an input size *n* for which lg^* *n* > 5.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fibonacci numbers**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the ***Fibonacci numbers*** *F[i]*, for *i* ≥ 0, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P64.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, after the first two, each Fibonacci number is the sum of the two previous
    ones, yielding the sequence
  prefs: []
  type: TYPE_NORMAL
- en: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, ….
  prefs: []
  type: TYPE_NORMAL
- en: Fibonacci numbers are related to the ***golden ratio*** *ϕ* and its conjugate
    ![art](images/phic.jpg), which are the two roots of the equation
  prefs: []
  type: TYPE_NORMAL
- en: '*x*² = *x* + 1.'
  prefs: []
  type: TYPE_NORMAL
- en: As Exercise 3.3-7 asks you to prove, the golden ratio is given by
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P65.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and its conjugate, by
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P66.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Specifically, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P67.jpg)'
  prefs: []
  type: TYPE_IMG
- en: which can be proved by induction (Exercise 3.3-8). Since ![art](images/Art_P68.jpg),
    we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P69.jpg)'
  prefs: []
  type: TYPE_IMG
- en: which implies that
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P70.jpg)'
  prefs: []
  type: TYPE_IMG
- en: which is to say that the *i*th Fibonacci number *F[i]* is equal to ![art](images/Art_P71.jpg)
    rounded to the nearest integer. Thus, Fibonacci numbers grow exponentially.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs: []
  type: TYPE_NORMAL
- en: '***3.3-1***'
  prefs: []
  type: TYPE_NORMAL
- en: Show that if *f* (*n*) and *g*(*n*) are monotonically increasing functions,
    then so are the functions *f* (*n*) + *g*(*n*) and *f* (*g*(*n*)), and if *f*
    (*n*) and *g*(*n*) are in addition nonnegative, then *f* (*n*) · *g*(*n*) is monotonically
    increasing.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.3-2***'
  prefs: []
  type: TYPE_NORMAL
- en: Prove that ⌊*αn*⌋ + ⌈(1 – *α*)*n*⌉ = *n* for any integer *n* and real number
    *α* in the range 0 ≤ *α* ≤ 1.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.3-3***'
  prefs: []
  type: TYPE_NORMAL
- en: Use equation (3.14) or other means to show that (*n* + *o*(*n*))*^k* = Θ(*n^k*)
    for any real constant *k*. Conclude that ⌈*n*⌉*^k* = Θ(*n^k*) and ⌊*n*⌋*^k* =
    Θ(*n^k*).
  prefs: []
  type: TYPE_NORMAL
- en: '***3.3-4***'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prove the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '***a.*** Equation (3.21).'
  prefs: []
  type: TYPE_NORMAL
- en: '***b.*** Equations (3.26)–(3.28).'
  prefs: []
  type: TYPE_NORMAL
- en: '***c.*** lg(Θ(*n*)) = Θ(lg *n*).'
  prefs: []
  type: TYPE_NORMAL
- en: ★ ***3.3-5***
  prefs: []
  type: TYPE_NORMAL
- en: Is the function ⌈lg *n*⌉! polynomially bounded? Is the function ⌈lg lg *n*⌉!
    polynomially bounded?
  prefs: []
  type: TYPE_NORMAL
- en: ★ ***3.3-6***
  prefs: []
  type: TYPE_NORMAL
- en: 'Which is asymptotically larger: lg(lg^* *n*) or lg^*(lg *n*)?'
  prefs: []
  type: TYPE_NORMAL
- en: '***3.3-7***'
  prefs: []
  type: TYPE_NORMAL
- en: Show that the golden ratio *ϕ* and its conjugate ![art](images/phic.jpg) both
    satisfy the equation *x*² = *x* + 1.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.3-8***'
  prefs: []
  type: TYPE_NORMAL
- en: Prove by induction that the *i*th Fibonacci number satisfies the equation
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P72.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *ϕ* is the golden ratio and ![art](images/phic.jpg) is its conjugate.
  prefs: []
  type: TYPE_NORMAL
- en: '***3.3-9***'
  prefs: []
  type: TYPE_NORMAL
- en: Show that *k* lg *k* = Θ(*n*) implies *k* = Θ(*n*/lg *n*).
  prefs: []
  type: TYPE_NORMAL
- en: '**Problems**'
  prefs: []
  type: TYPE_NORMAL
- en: '***3-1     Asymptotic behavior of polynomials***'
  prefs: []
  type: TYPE_NORMAL
- en: Let
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P73.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *a[d]* > 0, be a degree-*d* polynomial in *n*, and let *k* be a constant.
    Use the definitions of the asymptotic notations to prove the following properties.
  prefs: []
  type: TYPE_NORMAL
- en: '***a.*** If *k* ≥ *d*, then *p*(*n*) = *O*(*n^k*).'
  prefs: []
  type: TYPE_NORMAL
- en: '***b.*** If *k* ≤ *d*, then *p*(*n*) = Ω(*n^k*).'
  prefs: []
  type: TYPE_NORMAL
- en: '***c.*** If *k* = *d*, then *p*(*n*) = Θ(*n^k*).'
  prefs: []
  type: TYPE_NORMAL
- en: '***d.*** If *k* > *d*, then *p*(*n*) = *o*(*n^k*).'
  prefs: []
  type: TYPE_NORMAL
- en: '***e.*** If *k* < *d*, then *p*(*n*) = *ω*(*n^k*).'
  prefs: []
  type: TYPE_NORMAL
- en: '***3-2     Relative asymptotic growths***'
  prefs: []
  type: TYPE_NORMAL
- en: Indicate, for each pair of expressions (*A*, *B*) in the table below whether
    *A* is *O*, *o*, Ω, *ω*, or Θ of *B*. Assume that *k* ≥ 1, *ϵ* > 0, and *c* >
    1 are constants. Write your answer in the form of the table with “yes” or “no”
    written in each box.
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P74.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '***3-3     Ordering by asymptotic growth rates***'
  prefs: []
  type: TYPE_NORMAL
- en: '***a.*** Rank the following functions by order of growth. That is, find an
    arrangement *g*[1], *g*[2], … , *g*[30] of the functions satisfying *g*[1] = Ω(*g*[2]),
    *g*[2] = Ω(*g*[3]), … , *g*[29] = Ω(*g*[30]). Partition your list into equivalence
    classes such that functions *f* (*n*) and *g*(*n*) belong to the same class if
    and only if *f* (*n*) = Θ(*g*(*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '| lg(lg^* *n*) | 2^(lg* *n*) | ![art](images/Art_P75.jpg) | *n*² | *n*! | (lg
    *n*)! |'
  prefs: []
  type: TYPE_TB
- en: '| (3/2)*^n* | *n*³ | lg² *n* | lg(*n*!) | ![art](images/Art_P76.jpg) | *n*^(1/lg
    *n*) |'
  prefs: []
  type: TYPE_TB
- en: '| ln ln *n* | lg^* *n* | *n* · 2*^n* | *n*^(lg lg *n*) | ln *n* | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2^(lg *n*) | (lg *n*)^(lg *n*) | *e^n* | 4^(lg *n*) | (*n* + 1)! | ![art](images/Art_P77.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: '| lg^*(lg *n*) | ![art](images/Art_P78.jpg) | *n* | 2*^n* | *n* lg *n* | ![art](images/Art_P79.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: '***b.*** Give an example of a single nonnegative function *f* (*n*) such that
    for all functions *g[i]*(*n*) in part (a), *f* (*n*) is neither *O*(*g[i]*(*n*))
    nor Ω(*g[i]*(*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***3-4     Asymptotic notation properties***'
  prefs: []
  type: TYPE_NORMAL
- en: Let *f* (*n*) and *g*(*n*) be asymptotically positive functions. Prove or disprove
    each of the following conjectures.
  prefs: []
  type: TYPE_NORMAL
- en: '***a.*** *f* (*n*) = *O*(*g*(*n*)) implies *g*(*n*) = *O*(*f* (*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***b.*** *f* (*n*) + *g*(*n*) = Θ(min {*f* (*n*), *g*(*n*)}).'
  prefs: []
  type: TYPE_NORMAL
- en: '***c.*** *f* (*n*) = *O*(*g*(*n*)) implies lg *f* (*n*) = *O*(lg *g*(*n*)),
    where lg *g*(*n*) ≥ 1 and *f* (*n*) ≥ 1 for all sufficiently large *n*.'
  prefs: []
  type: TYPE_NORMAL
- en: '***d.*** *f* (*n*) = *O*(*g*(*n*)) implies 2^(*f*(*n*)) = *O* (2^(*g*(*n*))).'
  prefs: []
  type: TYPE_NORMAL
- en: '***e.*** *f* (*n*) = *O* ((*f* (*n*))²).'
  prefs: []
  type: TYPE_NORMAL
- en: '***f.*** *f* (*n*) = *O*(*g*(*n*)) implies *g*(*n*) = Ω(*f* (*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***g.*** *f* (*n*) = Θ(*f* (*n*/2)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***h.*** *f* (*n*) + *o*(*f* (*n*)) = Θ(*f* (*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***3-5     Manipulating asymptotic notation***'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let *f* (*n*) and *g*(*n*) be asymptotically positive functions. Prove the
    following identities:'
  prefs: []
  type: TYPE_NORMAL
- en: '***a.*** Θ(Θ(*f* (*n*))) = Θ(*f* (*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***b.*** Θ(*f* (*n*)) + *O*(*f* (*n*)) = Θ(*f* (*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***c.*** Θ(*f* (*n*)) + Θ(*g*(*n*)) = Θ(*f* (*n*) + *g*(*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***d.*** Θ(*f* (*n*)) · Θ(*g*(*n*)) = Θ(*f* (*n*) · *g*(*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***e.*** Argue that for any real constants *a*[1], *b*[1] > 0 and integer constants
    *k*[1], *k*[2], the following asymptotic bound holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P80.jpg)'
  prefs: []
  type: TYPE_IMG
- en: ★ ***f.*** Prove that for *S* ⊆ Z, we have
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P81.jpg)'
  prefs: []
  type: TYPE_IMG
- en: assuming that both sums converge.
  prefs: []
  type: TYPE_NORMAL
- en: '★ ***g.*** Show that for *S* ⊆ Z, the following asymptotic bound does not necessarily
    hold, even assuming that both products converge, by giving a counterexample:'
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P82.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '***3-6     Variations on O and Ω***'
  prefs: []
  type: TYPE_NORMAL
- en: Some authors define Ω-notation in a slightly different way than this textbook
    does. We’ll use the nomenclature ![art](images/Art_P83.jpg) (read “omega infinity”)
    for this alternative definition. We say that ![art](images/Art_P84.jpg) if there
    exists a positive constant *c* such that *f* (*n*) ≥ *cg*(*n*) ≥ 0 for infinitely
    many integers *n*.
  prefs: []
  type: TYPE_NORMAL
- en: '***a.*** Show that for any two asymptotically nonnegative functions *f* (*n*)
    and *g*(*n*), we have *f* (*n*) = *O*(*g*(*n*)) or ![art](images/Art_P85.jpg)
    (or both).'
  prefs: []
  type: TYPE_NORMAL
- en: '***b.*** Show that there exist two asymptotically nonnegative functions *f*
    (*n*) and *g*(*n*) for which neither *f* (*n*) = *O*(*g*(*n*)) nor *f* (*n*) =
    Ω(*g*(*n*)) holds.'
  prefs: []
  type: TYPE_NORMAL
- en: '***c.*** Describe the potential advantages and disadvantages of using ![art](images/Art_P86.jpg)-notation
    instead of Ω-notation to characterize the running times of programs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some authors also define *O* in a slightly different manner. We’ll use *O*^′
    for the alternative definition: *f* (*n*) = *O*^′(*g*(*n*)) if and only if |*f*
    (*n*)| = *O*(*g*(*n*)).'
  prefs: []
  type: TYPE_NORMAL
- en: '***d.*** What happens to each direction of the “if and only if” in Theorem
    3.1 on page 56 if we substitute *O*^′ for *O* but still use Ω?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some authors define ![art](images/Otilde.jpg) (read “soft-oh”) to mean *O*
    with logarithmic factors ignored:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![art](images/Art_P87.jpg) |  :  | there exist positive constants *c*, *k*,
    and *n*[0] such that 0 ≤ *f* (*n*) ≤ *cg*(*n*) lg*^k*(*n*) for all *n* ≥ *n*[0]}.
    |'
  prefs: []
  type: TYPE_TB
- en: '***e.*** Define ![art](images/Art_P88.jpg) and ![art](images/Art_P89.jpg) in
    a similar manner. Prove the corresponding analog to Theorem 3.1.'
  prefs: []
  type: TYPE_NORMAL
- en: '***3-7     Iterated functions***'
  prefs: []
  type: TYPE_NORMAL
- en: We can apply the iteration operator ^* used in the lg^* function to any monotonically
    increasing function *f* (*n*) over the reals. For a given constant *c* ∈ R, we
    define the iterated function ![art](images/Art_P90.jpg) by
  prefs: []
  type: TYPE_NORMAL
- en: '![art](images/Art_P91.jpg)'
  prefs: []
  type: TYPE_IMG
- en: which need not be well defined in all cases. In other words, the quantity ![art](images/Art_P92.jpg)
    is the minimum number of iterated applications of the function *f* required to
    reduce its argument down to *c* or less.
  prefs: []
  type: TYPE_NORMAL
- en: For each of the functions *f* (*n*) and constants *c* in the table below, give
    as tight a bound as possible on ![art](images/Art_P93.jpg). If there is no *i*
    such that *f*^((*i*))(*n*) ≤ *c*, write “undefined” as your answer.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | *f* (*n*) | *c* | ![art](images/Art_P94.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '| ***a.*** | *n* – 1 | 0 |  |'
  prefs: []
  type: TYPE_TB
- en: '| ***b.*** | lg *n* | 1 |  |'
  prefs: []
  type: TYPE_TB
- en: '| ***c.*** | *n*/2 | 1 |  |'
  prefs: []
  type: TYPE_TB
- en: '| ***d.*** | *n*/2 | 2 |  |'
  prefs: []
  type: TYPE_TB
- en: '| ***e.*** | ![art](images/Art_P95.jpg) | 2 |  |'
  prefs: []
  type: TYPE_TB
- en: '| ***f.*** | ![art](images/Art_P96.jpg) | 1 |  |'
  prefs: []
  type: TYPE_TB
- en: '| ***g.*** | *n*^(1/3) | 2 |  |'
  prefs: []
  type: TYPE_TB
- en: '**Chapter notes**'
  prefs: []
  type: TYPE_NORMAL
- en: Knuth [[259](bibliography001.xhtml#endnote_259)] traces the origin of the *O*-notation
    to a number-theory text by P. Bachmann in 1892\. The *o*-notation was invented
    by E. Landau in 1909 for his discussion of the distribution of prime numbers.
    The Ω and Θ notations were advocated by Knuth [[265](bibliography001.xhtml#endnote_265)]
    to correct the popular, but technically sloppy, practice in the literature of
    using *O*-notation for both upper and lower bounds. As noted earlier in this chapter,
    many people continue to use the *O*-notation where the Θ-notation is more technically
    precise. The soft-oh notation ![art](images/Otilde.jpg) in Problem 3-6 was introduced
    by Babai, Luks, and Seress [[31](bibliography001.xhtml#endnote_31)], although
    it was originally written as *O*~. Some authors now define ![art](images/Art_P97.jpg)
    as ignoring factors that are logarithmic in *g*(*n*), rather than in *n*. With
    this definition, we can say that ![art](images/Art_P98.jpg), but with the definition
    in Problem 3-6, this statement is not true. Further discussion of the history
    and development of asymptotic notations appears in works by Knuth [[259](bibliography001.xhtml#endnote_259),
    [265](bibliography001.xhtml#endnote_265)] and Brassard and Bratley [[70](bibliography001.xhtml#endnote_70)].
  prefs: []
  type: TYPE_NORMAL
- en: Not all authors define the asymptotic notations in the same way, although the
    various definitions agree in most common situations. Some of the alternative definitions
    encompass functions that are not asymptotically nonnegative, as long as their
    absolute values are appropriately bounded.
  prefs: []
  type: TYPE_NORMAL
- en: Equation (3.29) is due to Robbins [[381](bibliography001.xhtml#endnote_381)].
    Other properties of elementary mathematical functions can be found in any good
    mathematical reference, such as Abramowitz and Stegun [[1](bibliography001.xhtml#endnote_1)]
    or Zwillinger [[468](bibliography001.xhtml#endnote_468)], or in a calculus book,
    such as Apostol [[19](bibliography001.xhtml#endnote_19)] or Thomas et al. [[433](bibliography001.xhtml#endnote_433)].
    Knuth [[259](bibliography001.xhtml#endnote_259)] and Graham, Knuth, and Patashnik
    [[199](bibliography001.xhtml#endnote_199)] contain a wealth of material on discrete
    mathematics as used in computer science.
  prefs: []
  type: TYPE_NORMAL
- en: '[¹](#footnote_ref_1) Within set notation, a colon means “such that.”'
  prefs: []
  type: TYPE_NORMAL
